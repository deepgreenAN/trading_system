{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行位置の調整 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:00.637732Z",
     "start_time": "2021-01-02T17:46:00.589861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\システムトレード入門\\trade_system_git_workspace\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インポート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:44:22.563499Z",
     "start_time": "2021-01-01T19:44:21.986046Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:44:24.565145Z",
     "start_time": "2021-01-01T19:44:22.578462Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import YahooFinanceStockLoaderMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:44:24.576115Z",
     "start_time": "2021-01-01T19:44:24.569134Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import StockDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T17:46:06.482246Z",
     "start_time": "2021-01-02T17:46:03.141044Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import py_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:44:27.572100Z",
     "start_time": "2021-01-01T19:44:27.566115Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自作tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tqdmを使っていてなぜか止まることがあったので，こちらで行うことにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:44:30.364626Z",
     "start_time": "2021-01-01T19:44:30.350665Z"
    }
   },
   "outputs": [],
   "source": [
    "def mytqdm(an_iter):\n",
    "    \"\"\"\n",
    "    tqdmを模したジェネレータ．イテレーション可能なオブジェクトを引数とする．\n",
    "    an_iter: any of iterable\n",
    "        進捗度を出力するイテレータ\n",
    "    \"\"\"\n",
    "    length = len(an_iter)\n",
    "    my_iter = iter(an_iter)\n",
    "    counter = 0\n",
    "    start_time = time.time()\n",
    "    old_start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            new_start_time = time.time()\n",
    "            next_iter = next(my_iter)  # 終了時はここでエラーが出る\n",
    "            counter += 1\n",
    "            one_take_time = new_start_time - old_start_time\n",
    "            print(\"\\r{}/{}, [{:.3f} sec]\".format(counter,length ,one_take_time), end=\"\")\n",
    "            old_start_time = new_start_time\n",
    "            yield next_iter\n",
    "            \n",
    "        except StopIteration as e:  # StopIterationErrorのみ通す\n",
    "            counter += 1\n",
    "            end_time = time.time()\n",
    "            all_take_time = end_time - start_time\n",
    "            print(\"\\r{}/{}, mean [{:.3f} sec]\".format(length, length, all_take_time/counter))\n",
    "            return None  # StopIterationErrorを起こす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:46:11.232365Z",
     "start_time": "2021-01-01T19:44:31.056776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100, mean [0.992 sec]\n"
     ]
    }
   ],
   "source": [
    "for i in mytqdm(range(100)):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 個別株のインサートを行うクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリの点から，一つ一つの銘柄ごとにデータベースにインサートしている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:48:21.570640Z",
     "start_time": "2021-01-01T19:48:21.484857Z"
    }
   },
   "outputs": [],
   "source": [
    "class CsvKobetsuInsert():\n",
    "    \"\"\"\n",
    "    csvファイルで読み込んだ銘柄のリストをもとに，StockDataBaseにデータをインサートしていく．メモリの点から，一つ一つの銘柄ごとにインサートする．\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, stock_loader, stock_db, stock_group=\"nikkei_255\", use_tempfile=False):\n",
    "        \"\"\"\n",
    "        csv_path: pathlib.Path\n",
    "            csvファイルのパス(内容は銘柄コード，銘柄名)\n",
    "        stock_loader: YahooFinanceStockLoaderMin\n",
    "            データローダ．今のところYahooFinanceを利用したもののみ\n",
    "        stock_db: StockDataBase\n",
    "            データベース\n",
    "        stock_group: str\n",
    "            銘柄グループの名前．csvファイルに対応させる\n",
    "        use_tempfile: bool\n",
    "            tempfileを利用するかどうか．tempfileを利用すると，プログラムが途中で終了した場合そこからスタートできる．\n",
    "        \"\"\"\n",
    "        self.csv_path = Path(csv_path)\n",
    "        self.stock_loader = stock_loader\n",
    "        self.stock_db = stock_db\n",
    "        self.stock_codes = pd.read_csv(self.csv_path, header=0)  # 自分で作成\n",
    "        \n",
    "        self.stock_group = stock_group\n",
    "        if len(self.stock_codes) < 1:\n",
    "            print(\"csv cannot read\")\n",
    "        self.use_tempfile = use_tempfile\n",
    "\n",
    "\n",
    "    def __call__(self):\n",
    "        print(\"[{}] {}_kobetsu_insert start\".format(str(datetime.datetime.now()), self.stock_group))\n",
    "\n",
    "        stock_codes_array = self.stock_codes.loc[:,\"code\"].values.astype(\"str\")\n",
    "\n",
    "        tempfile_path = self.csv_path.parent / Path(self.stock_group+\".tmp\")\n",
    "        with py_restart.enable_counter(tempfile_path) as counter:\n",
    "            for stock_code in counter(mytqdm(stock_codes_array)):\n",
    "                stock_name = str(stock_code) + \".T\"  # これはyahooが前提\n",
    "                self.stock_loader.set_stock_names(stock_name)\n",
    "\n",
    "                df = stock_loader.load()\n",
    "                if df is not None:\n",
    "                    self.stock_db.upsert(df, item_replace_type=\"replace_null\")\n",
    "                else:\n",
    "                    print(\"\\n[{}] cannot get {}\".format(str(datetime.datetime.now()), stock_code))\n",
    "\n",
    "        print(\"[{}] {}_kobetsu_insert end\".format(str(datetime.datetime.now()), self.stock_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:48:31.481116Z",
     "start_time": "2021-01-01T19:48:31.449209Z"
    }
   },
   "outputs": [],
   "source": [
    "class FunctionComposer():\n",
    "    \"\"\"\n",
    "    callableなオブジェクトをまとめてcallする．closeメソッドも考慮できる．\n",
    "    \"\"\"\n",
    "    def __init__(self, function_list):\n",
    "        \"\"\"\n",
    "        function_list: list of function\n",
    "            関数のリスト\n",
    "        \"\"\"\n",
    "        self.function_list = function_list\n",
    "        \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        全ての関数の実行\n",
    "        \"\"\"\n",
    "        with py_restart.multi_count():\n",
    "            for func in self.function_list:\n",
    "                func()  # 関数の実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T19:49:16.136787Z",
     "start_time": "2021-01-01T19:49:13.114717Z"
    }
   },
   "outputs": [],
   "source": [
    "#db_path = Path(\"db/big_sample_db/\") / Path(\"stock.db\")\n",
    "db_path = Path(\"db/stock_db\") / Path(\"stock.db\")\n",
    "\n",
    "stock_db = StockDatabase(db_path, column_upper_limit=1000, table_name_base=\"table\", database_frequency=\"T\")\n",
    "nikkei_code_file_path = Path(\"get_stock_price/nikkei225.csv\")\n",
    "tosho_code_file_path = Path(\"get_stock_price/tosho.csv\")\n",
    "\n",
    "stock_loader = YahooFinanceStockLoaderMin(None, past_day=5, stop_time_span=2.0, is_use_stop=True)  #一つ一つストップしながら\n",
    "\n",
    "nikkei_kobetsu_insert = CsvKobetsuInsert(nikkei_code_file_path, stock_loader, stock_db, stock_group=\"nikkei_255\", use_tempfile=True)\n",
    "tosho_kobetsu_insert = CsvKobetsuInsert(tosho_code_file_path, stock_loader, stock_db, stock_group=\"tosho_1\", use_tempfile=True)\n",
    "\n",
    "# func_composer = FunctionComposer([nikkei_kobetsu_insert, tosho_kobetsu_insert])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日経255銘柄の株価データをデータベースにインサート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T20:02:10.678269Z",
     "start_time": "2021-01-01T19:49:24.637888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-01-02 04:49:24.645880] nikkei_255_kobetsu_insert start\n",
      "150/219, [2.810 sec]\n",
      "[2021-01-02 04:57:43.623121] cannot get 8028\n",
      "199/219, [2.651 sec]\n",
      "[2021-01-02 05:00:56.631385] cannot get 9437\n",
      "219/219, mean [3.482 sec]\n",
      "[2021-01-02 05:02:10.669290] nikkei_255_kobetsu_insert end\n"
     ]
    }
   ],
   "source": [
    "nikkei_kobetsu_insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 東証一部上場銘柄の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T23:22:08.301539Z",
     "start_time": "2021-01-01T20:57:44.779874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-01-02 05:57:44.901545] tosho_1_kobetsu_insert start\n",
      "1026/4044, [2.855 sec]Not Found: No data found, symbol may be delisted\n",
      "\n",
      "[2021-01-02 05:59:19.241142] cannot get 34091\n",
      "1049/4044, [3.716 sec]\n",
      "[2021-01-02 06:00:27.204295] cannot get 3448\n",
      "1056/4044, [3.520 sec]\n",
      "[2021-01-02 06:00:46.490693] cannot get 3456\n",
      "1081/4044, [4.889 sec]\n",
      "[2021-01-02 06:02:07.399836] cannot get 3483\n",
      "1129/4044, [2.939 sec]\n",
      "[2021-01-02 06:04:42.829975] cannot get 3564\n",
      "1206/4044, [3.526 sec]\n",
      "[2021-01-02 06:08:49.022863] cannot get 3693\n",
      "1481/4044, [2.749 sec]\n",
      "[2021-01-02 06:23:58.700774] cannot get 4250\n",
      "1541/4044, [3.561 sec]\n",
      "[2021-01-02 06:27:35.992396] cannot get 4383\n",
      "1570/4044, [4.833 sec]\n",
      "[2021-01-02 06:29:21.310615] cannot get 4426\n",
      "2045/4044, [2.426 sec]\n",
      "[2021-01-02 06:51:11.022400] cannot get 5858\n",
      "2152/4044, [2.464 sec]\n",
      "[2021-01-02 06:55:37.233144] cannot get 6066\n",
      "2216/4044, [2.396 sec]\n",
      "[2021-01-02 06:58:17.502379] cannot get 6174\n",
      "2484/4044, [2.773 sec]\n",
      "[2021-01-02 07:10:35.623046] cannot get 6576\n",
      "2544/4044, [2.637 sec]\n",
      "[2021-01-02 07:13:25.025807] cannot get 6695\n",
      "2688/4044, [2.455 sec]\n",
      "[2021-01-02 07:20:16.771901] cannot get 6945\n",
      "2750/4044, [2.898 sec]\n",
      "[2021-01-02 07:23:14.385650] cannot get 7056\n",
      "2769/4044, [2.722 sec]\n",
      "[2021-01-02 07:24:07.560413] cannot get 7075\n",
      "2788/4044, [2.669 sec]\n",
      "[2021-01-02 07:24:58.882111] cannot get 7098\n",
      "2800/4044, [2.603 sec]\n",
      "[2021-01-02 07:25:30.173879] cannot get 7170\n",
      "2804/4044, [2.591 sec]\n",
      "[2021-01-02 07:25:38.859688] cannot get 7176\n",
      "2840/4044, [2.764 sec]\n",
      "[2021-01-02 07:27:19.127303] cannot get 7230\n",
      "2854/4044, [2.718 sec]\n",
      "[2021-01-02 07:27:55.952741] cannot get 7251\n",
      "2870/4044, [1.698 sec]\n",
      "[2021-01-02 07:28:38.307421] cannot get 7274\n",
      "2914/4044, [2.602 sec]\n",
      "[2021-01-02 07:30:40.131580] cannot get 7426\n",
      "2965/4044, [2.827 sec]\n",
      "[2021-01-02 07:32:58.108739] cannot get 7515\n",
      "3021/4044, [2.669 sec]\n",
      "[2021-01-02 07:35:29.857449] cannot get 7612\n",
      "3046/4044, [2.673 sec]\n",
      "[2021-01-02 07:36:36.878072] cannot get 7672\n",
      "3053/4044, [3.733 sec]\n",
      "[2021-01-02 07:36:55.640875] cannot get 7680\n",
      "3062/4044, [2.647 sec]\n",
      "[2021-01-02 07:37:17.327890] cannot get 7690\n",
      "3063/4044, [0.181 sec]\n",
      "[2021-01-02 07:37:17.533344] cannot get 7691\n",
      "3066/4044, [2.693 sec]\n",
      "[2021-01-02 07:37:23.561213] cannot get 7703\n",
      "3271/4044, [2.639 sec]\n",
      "[2021-01-02 07:46:43.553922] cannot get 8028\n",
      "3299/4044, [2.730 sec]\n",
      "[2021-01-02 07:47:59.163645] cannot get 8072\n",
      "3501/4044, [2.625 sec]\n",
      "[2021-01-02 07:57:20.715066] cannot get 8589\n",
      "3661/4044, [2.906 sec]\n",
      "[2021-01-02 08:04:47.876654] cannot get 9049\n",
      "3712/4044, [3.964 sec]\n",
      "[2021-01-02 08:07:07.132020] cannot get 9261\n",
      "3726/4044, [3.211 sec]\n",
      "[2021-01-02 08:07:42.124441] cannot get 9276\n",
      "3745/4044, [2.684 sec]\n",
      "[2021-01-02 08:08:32.279828] cannot get 9311\n",
      "3776/4044, [2.777 sec]\n",
      "[2021-01-02 08:09:53.800767] cannot get 9388\n",
      "3801/4044, [2.564 sec]\n",
      "[2021-01-02 08:11:01.824759] cannot get 9437\n",
      "3810/4044, [2.842 sec]\n",
      "[2021-01-02 08:11:24.502071] cannot get 9465\n",
      "3946/4044, [2.563 sec]\n",
      "[2021-01-02 08:17:34.821277] cannot get 9792\n",
      "4044/4044, mean [2.142 sec]\n",
      "[2021-01-02 08:22:08.283580] tosho_1_kobetsu_insert end\n"
     ]
    }
   ],
   "source": [
    "stock_loader = YahooFinanceStockLoaderMin(None, past_day=5, stop_time_span=2.0, is_use_stop=False)  #一つ一つストップする\n",
    "tosho_kobetsu_insert = CsvKobetsuInsert(tosho_code_file_path, stock_loader, stock_db, stock_group=\"tosho_1\")\n",
    "tosho_kobetsu_insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データベースのバックアップクラス "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:07:17.831921Z",
     "start_time": "2020-11-30T13:07:16.347867Z"
    }
   },
   "outputs": [],
   "source": [
    "class PyBackUp():\n",
    "    \"\"\"\n",
    "    指定したファイル・フォルダをバックアップする．保存形式は元と同じあるいはzip形式．\n",
    "    zip形式にはLZMA形式を利用する\n",
    "    \"\"\"\n",
    "    def __init__(self, source_path, backup_path, back_number=6, is_use_text=True, to_zip=False):\n",
    "        \"\"\"\n",
    "        source_path: str or pathlib.Path\n",
    "            バックアップしたいソースのパス．ファイルでもディレクトリでも良い．\n",
    "        backup_path: str or pathlib.Path\n",
    "            バックアップ先のディレクトリのパス．そのディレクトリにsource_pathに対応したフォルダを作成する．\n",
    "        back_number: int\n",
    "            バックアップファイルの個数．\n",
    "        is_use_text: bool\n",
    "            バックアップファイルの管理にcsvを使うかどうか\n",
    "        to_zip: bool\n",
    "            zip形式で保存するかどうか\n",
    "        \"\"\"\n",
    "        source_path = Path(source_path)\n",
    "        if not source_path.exists():\n",
    "            raise ValueError(\"This path does not exists\")\n",
    "        self.source_path = source_path\n",
    "        self.source_name = source_path.name  # ファイル名\n",
    "        self.source_stem = source_path.stem  # 拡張子を除いたファイル名\n",
    "\n",
    "        backup_path = Path(backup_path)\n",
    "        if not backup_path.exists():\n",
    "            backup_path.mkdir()\n",
    "\n",
    "        self.backup_path = backup_path\n",
    "\n",
    "        self.back_number = back_number\n",
    "        self.backup_counter = -1  # 0からスタートするように\n",
    "        \n",
    "        self.to_zip = to_zip\n",
    "        if is_use_text:\n",
    "            self.read_backup_data()\n",
    "\n",
    "    def back_up(self):\n",
    "        print(\"[{}] backup start.\".format(str(datetime.datetime.now())))\n",
    "        self.backup_counter += 1\n",
    "        \n",
    "        backup_number = int((self.backup_counter)%self.back_number)  # 保存するディレクトリに対応\n",
    "        backup_dir_name = \"back_up_\" + str(backup_number)\n",
    "\n",
    "        backup_dir_path = self.backup_path / Path(backup_dir_name)\n",
    "        backup_dst_path = backup_dir_path / Path(self.source_name)  # 実際に保存するパス\n",
    "\n",
    "        if not backup_dir_path.exists():  # バックアップファイルのディレクトリが存在しない場合\n",
    "            backup_dir_path.mkdir(parents=True)  # ディレクトリを作成\n",
    "            \n",
    "        if backup_dst_path.exists():  # すでにバックアップファイルが存在する場合\n",
    "            if backup_dst_path.is_file():  # ファイルの場合\n",
    "                backup_dst_path.unlink()  # 削除\n",
    "            elif backup_dst_path.is_dir():  # ディレクトリの場合\n",
    "                shutil.rmtree(backup_dst_path)\n",
    "\n",
    "        # バックアップファイルのコピー\n",
    "        if self.to_zip:  # zip\n",
    "            backup_dst_path = backup_dst_path.with_suffix(\".zip\")  # zipとつける\n",
    "            make_zip(source_path=self.source_path, zip_path=backup_dst_path)\n",
    "            \n",
    "        else: #zipでなくコピー\n",
    "            if self.source_path.is_file():\n",
    "                shutil.copyfile(src=self.source_path, dst=backup_dst_path)\n",
    "            elif self.source_path.is_dir():\n",
    "                shutil.copytree(src=self.source_path, dst=backup_dst_path)\n",
    "        \n",
    "        backup_data_text_path = backup_dir_path / Path(\"data.csv\")\n",
    "        if not backup_data_text_path.exists():  # バックアップデータの詳細を書いたテキストファイル\n",
    "            backup_data_text_path.touch(exist_ok=True)\n",
    "\n",
    "        # バックアップデータの書き込み・書き換え\n",
    "        with open(backup_data_text_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            backup_time = datetime.datetime.now()\n",
    "            writer.writerow([\"date\", backup_time.strftime(\"%Y-%m-%d %H:%M:%S\")])\n",
    "            writer.writerow([\"dir_number\", backup_number])\n",
    "            writer.writerow([\"backup_count\", self.backup_counter])\n",
    "\n",
    "\n",
    "        print(\"[{}] back up db_file {}\".format(str(backup_time),str(backup_number)))\n",
    "        print(\"[{}] backup end.\".format(str(datetime.datetime.now())))\n",
    "        return backup_dst_path\n",
    "\n",
    "    def read_backup_data(self):\n",
    "        backup_datetime_list = []\n",
    "        backup_counter_list = []\n",
    "\n",
    "        for backup_dir in self.backup_path.iterdir():\n",
    "            # バックアップファイルの存在確認\n",
    "            if self.to_zip: #Zipの場合\n",
    "                backup_file_path = backup_dir / Path(self.source_stem).with_suffix(\".zip\")  # xz.tarを前提\n",
    "            else:\n",
    "                backup_file_path = backup_dir / Path(self.source_name)  \n",
    "                \n",
    "            if backup_file_path.exists():  # バックアップファイルが存在する場合\n",
    "                backup_data_text_path = backup_dir / Path(\"data.csv\")\n",
    "                if backup_data_text_path.exists():\n",
    "                    # バックアップデータの読み込み\n",
    "                    with open(backup_data_text_path, \"r\") as f:\n",
    "                        reader = csv.reader(f)\n",
    "                        \n",
    "                        datetime_list = next(reader)\n",
    "                        backup_datetime = datetime.datetime.strptime(datetime_list[1],\"%Y-%m-%d %H:%M:%S\")\n",
    "                        \n",
    "                        next(reader)  # この行はいらなかったかも\n",
    "\n",
    "                        counter_list = next(reader)\n",
    "                        backup_counter_list.append(counter_list[1])\n",
    "\n",
    "                        backup_datetime_list.append(backup_datetime)\n",
    "\n",
    "        # バックアップデータが存在する場合\n",
    "        if len(backup_datetime_list) > 0:\n",
    "            # 最近のインデックスを求める, maxカウンターでもいいけど念のため\n",
    "            def get_timestamp(datetime):\n",
    "                return datetime.timestamp()\n",
    "            max_date = max(backup_datetime_list, key=get_timestamp)\n",
    "            max_date_index = backup_datetime_list.index(max_date)\n",
    "            \n",
    "            self.backup_counter = int(backup_counter_list[max_date_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データベースのバックアップ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:49:21.200529Z",
     "start_time": "2020-11-30T13:49:21.164623Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = Path(\"db/big_sample_db\") / Path(\"stock.db\")\n",
    "backup_path = Path(\"db/backup\")\n",
    "db_backup = PyBackUp(source_path=db_path, backup_path=backup_path, back_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:49:30.122646Z",
     "start_time": "2020-11-30T13:49:23.104429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-30 22:49:23.125374] backup start.\n",
      "[2020-11-30 22:49:29.972103] back up db_file 3\n",
      "[2020-11-30 22:49:30.002994] backup end.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('db/backup/back_up_3/stock.db')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_backup.back_up()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py37",
   "language": "python",
   "name": "torch_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
