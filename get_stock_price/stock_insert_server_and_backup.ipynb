{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行位置の調整 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:29:17.336688Z",
     "start_time": "2020-11-30T06:29:17.257846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\システムトレード入門\\predict_git_workspace\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インポート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T08:01:12.575523Z",
     "start_time": "2020-11-30T08:01:12.475791Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:29:26.614739Z",
     "start_time": "2020-11-30T06:29:19.711930Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import YahooFinanceStockLoaderMin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:29:26.647497Z",
     "start_time": "2020-11-30T06:29:26.625557Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import StockDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T06:29:26.680409Z",
     "start_time": "2020-11-30T06:29:26.664451Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自作tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tqdmを使っていてなぜか止まることがあったので，こちらで行うことにする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:39:53.582628Z",
     "start_time": "2020-11-30T15:39:53.532768Z"
    }
   },
   "outputs": [],
   "source": [
    "def mytqdm(an_iter):\n",
    "    \"\"\"\n",
    "    tqdmを模したジェネレータ．イテレーション可能なオブジェクトを引数とする．\n",
    "    an_iter: any of iterable\n",
    "        進捗度を出力するイテレータ\n",
    "    \"\"\"\n",
    "    length = len(an_iter)\n",
    "    my_iter = iter(an_iter)\n",
    "    counter = 0\n",
    "    start_time = time.time()\n",
    "    old_start_time = time.time()\n",
    "    while True:\n",
    "        try:\n",
    "            new_start_time = time.time()\n",
    "            next_iter = next(my_iter)  # 終了時はここでエラーが出る\n",
    "            counter += 1\n",
    "            one_take_time = new_start_time - old_start_time\n",
    "            print(\"\\r{}/{}, [{:.3f} sec]\".format(counter,length ,one_take_time), end=\"\")\n",
    "            old_start_time = new_start_time\n",
    "            yield next_iter\n",
    "            \n",
    "        except StopIteration as e:  # StopIterationErrorのみ通す\n",
    "            counter += 1\n",
    "            end_time = time.time()\n",
    "            all_take_time = end_time - start_time\n",
    "            print(\"\\r{}/{}, mean [{:.3f} sec]\".format(length, length, all_take_time/counter))\n",
    "            return None  # StopIterationErrorを起こす"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:41:34.428774Z",
     "start_time": "2020-11-30T15:39:54.362548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100, mean [0.991 sec]\n"
     ]
    }
   ],
   "source": [
    "for i in mytqdm(range(100)):\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 個別株のインサートを行うクラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メモリの点から，一つ一つの銘柄ごとにデータベースにインサートしている．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:52:10.013649Z",
     "start_time": "2020-11-30T15:52:09.791242Z"
    }
   },
   "outputs": [],
   "source": [
    "class CsvKobetsuInsert():\n",
    "    \"\"\"\n",
    "    csvファイルで読み込んだ銘柄のリストをもとに，StockDataBaseにデータをインサートしていく．メモリの点から，一つ一つの銘柄ごとにインサートする．\n",
    "    \"\"\"\n",
    "    def __init__(self, csv_path, stock_loader, stock_db, stock_group=\"nikkei_255\", use_tempfile=False):\n",
    "        \"\"\"\n",
    "        csv_path: pathlib.Path\n",
    "            csvファイルのパス(内容は銘柄コード，銘柄名)\n",
    "        stock_loader: YahooFinanceStockLoaderMin\n",
    "            データローダ．今のところYahooFinanceを利用したもののみ\n",
    "        stock_db: StockDataBase\n",
    "            データベース\n",
    "        stock_group: str\n",
    "            銘柄グループの名前．csvファイルに対応させる\n",
    "        use_tempfile: bool\n",
    "            tempfileを利用するかどうか．tempfileを利用すると，プログラムが途中で終了した場合そこからスタートできる．\n",
    "        \"\"\"\n",
    "        self.csv_path = Path(csv_path)\n",
    "        self.stock_loader = stock_loader\n",
    "        self.stock_db = stock_db\n",
    "        self.stock_codes = pd.read_csv(self.csv_path, header=0)  # 自分で作成\n",
    "        \n",
    "        self.stock_group = stock_group\n",
    "        if len(self.stock_codes) < 1:\n",
    "            print(\"csv cannot read\")\n",
    "        self.use_tempfile = use_tempfile\n",
    "        self.complete_stock_name = None\n",
    "\n",
    "    def tempfile_check(self):\n",
    "        # 以下，処理が停止してしまった際に，作業の完了位置を読み込む\n",
    "        csv_path_file_name = self.csv_path.stem\n",
    "        tempfile_path = self.csv_path.parent / Path(\"{}_tempfile.tmp\".format(csv_path_file_name))\n",
    "        if tempfile_path.exists():\n",
    "            with open(tempfile_path, \"r\") as f:\n",
    "                reader = csv.reader(f)\n",
    "\n",
    "                #dateについて取得, 現在時間との差が一日以内かどうか判定\n",
    "                datetime_list = next(reader)  # [datetime,実際の日時の文字列]\n",
    "                tempfile_date = datetime.datetime.strptime(datetime_list[1], \"%Y-%m-%d %H:%M:%S\")\n",
    "                if datetime.datetime.now() - tempfile_date >= datetime.timedelta(days=1):\n",
    "                    print(\"tempfile is not recent date, please check tempfile\")\n",
    "\n",
    "                complete_stock_name_list = next(reader)  # [complete_stock_name, 実際に終了した銘柄コード]\n",
    "                self.complete_stock_name = complete_stock_name_list[1]\n",
    "            \n",
    "            # tempfileの削除\n",
    "            tempfile_path.unlink()\n",
    "            \n",
    "        else:\n",
    "            self.complete_stock_name = None\n",
    "            print(\"cannot read tempfile\")\n",
    "            \n",
    "\n",
    "    def __call__(self):\n",
    "        print(\"[{}] {}_kobetsu_insert start\".format(str(datetime.datetime.now()), self.stock_group))\n",
    "\n",
    "        stock_codes_array = self.stock_codes.loc[:,\"code\"].values.astype(\"str\")\n",
    "        if self.use_tempfile:\n",
    "            # テンプファイルの読み込み\n",
    "            self.tempfile_check()\n",
    "            if self.complete_stock_name is not None:\n",
    "                # self.complete_stock_nameよりインデックスの大きい部分array\n",
    "                complete_index = np.where(stock_codes_array==self.complete_stock_name)[0].item()\n",
    "                if complete_index != len(stock_codes_array)-1:  # complete_indexが最後のインデックスでない場合\n",
    "                    stock_codes_array = stock_codes_array[complete_index+1:]  # スライシングはintegerでないといけないため，item\n",
    "                    pre_stock_code = None  # 完了した最後のstock_code\n",
    "                else:\n",
    "                    stock_codes_array = []  # 空リスト\n",
    "                    pre_stock_code = self.complete_stock_name  # 最後の銘柄コード\n",
    "                # 途中から始まることを明示\n",
    "                print(\"[{}] already {} item inserted, start from {}\".format(str(datetime.datetime.now()), complete_index+1, self.complete_stock_name))  # indexは0スタートであるため，+1\n",
    "        \n",
    "        \n",
    "        #for stock_code in tqdm(self.stock_codes.loc[:,\"code\"].values):\n",
    "        for stock_code in mytqdm(stock_codes_array):\n",
    "            stock_name = str(stock_code) + \".T\"  # これはyahooが前提\n",
    "            self.stock_loader.set_stock_names(stock_name)\n",
    "            # エラー処理\n",
    "            try:\n",
    "                df = stock_loader.load()\n",
    "                if df is not None:\n",
    "                    self.stock_db.upsert(df, item_replace_type=\"replace_null\")\n",
    "                else:\n",
    "                    print(\"\\n[{}] cannot get {}\".format(str(datetime.datetime.now()), stock_code))\n",
    "                \n",
    "            except BaseException as e:  # おそらく強制終了か通信のエラー\n",
    "                # tempfileの作成\n",
    "                csv_path_file_name = self.csv_path.stem\n",
    "                self.tempfile_path = self.csv_path.parent / Path(\"{}_tempfile.tmp\".format(csv_path_file_name))\n",
    "                with open(self.tempfile_path, \"w\", newline=\"\") as f:\n",
    "                    writer = csv.writer(f)\n",
    "                    writer.writerow([\"datetime\", datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")])  # 現在時刻を記述\n",
    "                    writer.writerow([\"complete_stock_name\", pre_stock_code])  # 完了した銘柄コードを記述\n",
    "                    \n",
    "                raise e  # エラーが分かるようにraiseしておく\n",
    "            # pre_stock_nameを更新\n",
    "            pre_stock_code = stock_code\n",
    "\n",
    "        print(\"[{}] {}_kobetsu_insert end\".format(str(datetime.datetime.now()), self.stock_group))\n",
    "        \n",
    "        # 終了時にテンプファイルを作成\n",
    "        csv_path_file_name = self.csv_path.stem\n",
    "        self.tempfile_path = self.csv_path.parent / Path(\"{}_tempfile.tmp\".format(csv_path_file_name))\n",
    "        with open(self.tempfile_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"datetime\", datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")])  # 現在時刻を記述\n",
    "            writer.writerow([\"complete_stock_name\", pre_stock_code])  # 完了した銘柄コードを記述\n",
    "    \n",
    "    def close(self):\n",
    "        # 全ての__call__が終了したとき,これでtempfileが残らなくなる\n",
    "        self.tempfile_path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:52:10.951135Z",
     "start_time": "2020-11-30T15:52:10.897278Z"
    }
   },
   "outputs": [],
   "source": [
    "class FunctionComposer():\n",
    "    \"\"\"\n",
    "    callableなオブジェクトをまとめてcallする．closeメソッドも考慮できる．\n",
    "    \"\"\"\n",
    "    def __init__(self, function_list, use_close=False):\n",
    "        \"\"\"\n",
    "        function_list: list of function\n",
    "            関数のリスト\n",
    "        use_close: bool\n",
    "            closeメソッドを適用するかどうか\n",
    "        \"\"\"\n",
    "        self.function_list = function_list\n",
    "        self.use_close = use_close\n",
    "        \n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        全ての関数の実行\n",
    "        \"\"\"\n",
    "        for func in self.function_list:\n",
    "            func()  # 関数の実行\n",
    "        if self.use_close:\n",
    "            self.close()\n",
    "            \n",
    "    def close(self):\n",
    "        \"\"\"\n",
    "        closeを実行する．hasattrで確認すべき？\n",
    "        \"\"\"\n",
    "        [func.close() in self.function_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T15:52:18.299625Z",
     "start_time": "2020-11-30T15:52:15.475039Z"
    }
   },
   "outputs": [],
   "source": [
    "#db_path = Path(\"db/big_sample_db/\") / Path(\"stock.db\")\n",
    "db_path = Path(\"db/stock_db\") / Path(\"stock.db\")\n",
    "\n",
    "stock_db = StockDatabase(db_path, column_upper_limit=1000, table_name_base=\"table\", database_frequency=\"T\")\n",
    "nikkei_code_file_path = Path(\"get_stock_price/nikkei225.csv\")\n",
    "tosho_code_file_path = Path(\"get_stock_price/tosho.csv\")\n",
    "\n",
    "stock_loader = YahooFinanceStockLoaderMin(None, past_day=5, stop_time_span=2.0, is_use_stop=True)  #一つ一つストップしながら\n",
    "\n",
    "nikkei_kobetsu_insert = CsvKobetsuInsert(nikkei_code_file_path, stock_loader, stock_db, stock_group=\"nikkei_255\", use_tempfile=True)\n",
    "tosho_kobetsu_insert = CsvKobetsuInsert(tosho_code_file_path, stock_loader, stock_db, stock_group=\"tosho_1\", use_tempfile=True)\n",
    "\n",
    "# func_composer = FunctionComposer([nikkei_kobetsu_insert, tosho_kobetsu_insert])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日経255銘柄の株価データをデータベースにインサート "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T16:13:48.627601Z",
     "start_time": "2020-11-30T16:13:48.530855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-12-01 01:13:48.539837] nikkei_255_kobetsu_insert start\n",
      "[2020-12-01 01:13:48.606652] already 219 item inserted, start from 2413\n",
      "\r",
      "0/0, mean [0.000 sec]\n",
      "[2020-12-01 01:13:48.609645] nikkei_255_kobetsu_insert end\n"
     ]
    }
   ],
   "source": [
    "nikkei_kobetsu_insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 東証一部上場銘柄の取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-05T14:30:24.080760Z",
     "start_time": "2020-11-05T08:45:38.072585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-05 17:45:38.176312] tosho_1_kobetsu_insert start\n",
      "641/4044, [2.101 sec]Not Found: No data found, symbol may be delisted\n",
      "1026/4044, [4.807 sec]Not Found: No data found, symbol may be delisted\n",
      "4044/4044, mean [5.114 sec]\n",
      "[2020-11-05 23:30:24.063812] tosho_1_kobetsu_insert end\n"
     ]
    }
   ],
   "source": [
    "stock_loader = YahooFinanceStockLoaderMin(None, past_day=5, stop_time_span=2.0, is_use_stop=False)  #一つ一つストップする\n",
    "tosho_kobetsu_insert = CsvKobetsuInsert(tosho_code_file_path, stock_loader, stock_db, stock_group=\"tosho_1\")\n",
    "tosho_kobetsu_insert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データベースのバックアップクラス "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:07:17.831921Z",
     "start_time": "2020-11-30T13:07:16.347867Z"
    }
   },
   "outputs": [],
   "source": [
    "class PyBackUp():\n",
    "    \"\"\"\n",
    "    指定したファイル・フォルダをバックアップする．保存形式は元と同じあるいはzip形式．\n",
    "    zip形式にはLZMA形式を利用する\n",
    "    \"\"\"\n",
    "    def __init__(self, source_path, backup_path, back_number=6, is_use_text=True, to_zip=False):\n",
    "        \"\"\"\n",
    "        source_path: str or pathlib.Path\n",
    "            バックアップしたいソースのパス．ファイルでもディレクトリでも良い．\n",
    "        backup_path: str or pathlib.Path\n",
    "            バックアップ先のディレクトリのパス．そのディレクトリにsource_pathに対応したフォルダを作成する．\n",
    "        back_number: int\n",
    "            バックアップファイルの個数．\n",
    "        is_use_text: bool\n",
    "            バックアップファイルの管理にcsvを使うかどうか\n",
    "        to_zip: bool\n",
    "            zip形式で保存するかどうか\n",
    "        \"\"\"\n",
    "        source_path = Path(source_path)\n",
    "        if not source_path.exists():\n",
    "            raise ValueError(\"This path does not exists\")\n",
    "        self.source_path = source_path\n",
    "        self.source_name = source_path.name  # ファイル名\n",
    "        self.source_stem = source_path.stem  # 拡張子を除いたファイル名\n",
    "\n",
    "        backup_path = Path(backup_path)\n",
    "        if not backup_path.exists():\n",
    "            backup_path.mkdir()\n",
    "\n",
    "        self.backup_path = backup_path\n",
    "\n",
    "        self.back_number = back_number\n",
    "        self.backup_counter = -1  # 0からスタートするように\n",
    "        \n",
    "        self.to_zip = to_zip\n",
    "        if is_use_text:\n",
    "            self.read_backup_data()\n",
    "\n",
    "    def back_up(self):\n",
    "        print(\"[{}] backup start.\".format(str(datetime.datetime.now())))\n",
    "        self.backup_counter += 1\n",
    "        \n",
    "        backup_number = int((self.backup_counter)%self.back_number)  # 保存するディレクトリに対応\n",
    "        backup_dir_name = \"back_up_\" + str(backup_number)\n",
    "\n",
    "        backup_dir_path = self.backup_path / Path(backup_dir_name)\n",
    "        backup_dst_path = backup_dir_path / Path(self.source_name)  # 実際に保存するパス\n",
    "\n",
    "        if not backup_dir_path.exists():  # バックアップファイルのディレクトリが存在しない場合\n",
    "            backup_dir_path.mkdir(parents=True)  # ディレクトリを作成\n",
    "            \n",
    "        if backup_dst_path.exists():  # すでにバックアップファイルが存在する場合\n",
    "            if backup_dst_path.is_file():  # ファイルの場合\n",
    "                backup_dst_path.unlink()  # 削除\n",
    "            elif backup_dst_path.is_dir():  # ディレクトリの場合\n",
    "                shutil.rmtree(backup_dst_path)\n",
    "\n",
    "        # バックアップファイルのコピー\n",
    "        if self.to_zip:  # zip\n",
    "            backup_dst_path = backup_dst_path.with_suffix(\".zip\")  # zipとつける\n",
    "            make_zip(source_path=self.source_path, zip_path=backup_dst_path)\n",
    "            \n",
    "        else: #zipでなくコピー\n",
    "            if self.source_path.is_file():\n",
    "                shutil.copyfile(src=self.source_path, dst=backup_dst_path)\n",
    "            elif self.source_path.is_dir():\n",
    "                shutil.copytree(src=self.source_path, dst=backup_dst_path)\n",
    "        \n",
    "        backup_data_text_path = backup_dir_path / Path(\"data.csv\")\n",
    "        if not backup_data_text_path.exists():  # バックアップデータの詳細を書いたテキストファイル\n",
    "            backup_data_text_path.touch(exist_ok=True)\n",
    "\n",
    "        # バックアップデータの書き込み・書き換え\n",
    "        with open(backup_data_text_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            backup_time = datetime.datetime.now()\n",
    "            writer.writerow([\"date\", backup_time.strftime(\"%Y-%m-%d %H:%M:%S\")])\n",
    "            writer.writerow([\"dir_number\", backup_number])\n",
    "            writer.writerow([\"backup_count\", self.backup_counter])\n",
    "\n",
    "\n",
    "        print(\"[{}] back up db_file {}\".format(str(backup_time),str(backup_number)))\n",
    "        print(\"[{}] backup end.\".format(str(datetime.datetime.now())))\n",
    "        return backup_dst_path\n",
    "\n",
    "    def read_backup_data(self):\n",
    "        backup_datetime_list = []\n",
    "        backup_counter_list = []\n",
    "\n",
    "        for backup_dir in self.backup_path.iterdir():\n",
    "            # バックアップファイルの存在確認\n",
    "            if self.to_zip: #Zipの場合\n",
    "                backup_file_path = backup_dir / Path(self.source_stem).with_suffix(\".zip\")  # xz.tarを前提\n",
    "            else:\n",
    "                backup_file_path = backup_dir / Path(self.source_name)  \n",
    "                \n",
    "            if backup_file_path.exists():  # バックアップファイルが存在する場合\n",
    "                backup_data_text_path = backup_dir / Path(\"data.csv\")\n",
    "                if backup_data_text_path.exists():\n",
    "                    # バックアップデータの読み込み\n",
    "                    with open(backup_data_text_path, \"r\") as f:\n",
    "                        reader = csv.reader(f)\n",
    "                        \n",
    "                        datetime_list = next(reader)\n",
    "                        backup_datetime = datetime.datetime.strptime(datetime_list[1],\"%Y-%m-%d %H:%M:%S\")\n",
    "                        \n",
    "                        next(reader)  # この行はいらなかったかも\n",
    "\n",
    "                        counter_list = next(reader)\n",
    "                        backup_counter_list.append(counter_list[1])\n",
    "\n",
    "                        backup_datetime_list.append(backup_datetime)\n",
    "\n",
    "        # バックアップデータが存在する場合\n",
    "        if len(backup_datetime_list) > 0:\n",
    "            # 最近のインデックスを求める, maxカウンターでもいいけど念のため\n",
    "            def get_timestamp(datetime):\n",
    "                return datetime.timestamp()\n",
    "            max_date = max(backup_datetime_list, key=get_timestamp)\n",
    "            max_date_index = backup_datetime_list.index(max_date)\n",
    "            \n",
    "            self.backup_counter = int(backup_counter_list[max_date_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データベースのバックアップ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:49:21.200529Z",
     "start_time": "2020-11-30T13:49:21.164623Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = Path(\"db/big_sample_db\") / Path(\"stock.db\")\n",
    "backup_path = Path(\"db/backup\")\n",
    "db_backup = PyBackUp(source_path=db_path, backup_path=backup_path, back_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T13:49:30.122646Z",
     "start_time": "2020-11-30T13:49:23.104429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-11-30 22:49:23.125374] backup start.\n",
      "[2020-11-30 22:49:29.972103] back up db_file 3\n",
      "[2020-11-30 22:49:30.002994] backup end.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('db/backup/back_up_3/stock.db')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_backup.back_up()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py37",
   "language": "python",
   "name": "torch_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
