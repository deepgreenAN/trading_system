{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ルートディレクトリに移動 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:10:52.358786Z",
     "start_time": "2021-05-15T06:10:52.325873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\システムトレード入門\\trade_system_git_workspace\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:10:56.855762Z",
     "start_time": "2021-05-15T06:10:52.369758Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pytz import timezone\n",
    "import datetime\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from abc import ABCMeta, abstractmethod\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:10:59.124698Z",
     "start_time": "2021-05-15T06:10:56.919591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\": \"T2yuo9Oe71Cz/I4X9Ac5+gpEa5a8PpJCDlqKYO0CfAuEszu1JrXLl8YugMqYe3sM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\": \"98GDGJ0kOMCUMUePhksaQ/GYgB3+NH9h996V88sh3aOiUNX3N+fLXAtry6xctSZ6\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\": \"89bArO+nlbP3sgakeHjCo1JYxYR5wufVgA3IbUvDY+K7w4zyxJqssu7wVnfeKCq8\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting\n",
    "from bokeh.models import Range1d, LinearAxis, Div, HoverTool\n",
    "from bokeh.io import show\n",
    "from bokeh.io import output_notebook, reset_output, output_file\n",
    "from bokeh.palettes import d3\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:00.350425Z",
     "start_time": "2021-05-15T06:10:59.136667Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import StockDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:00.382338Z",
     "start_time": "2021-05-15T06:11:00.360396Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import get_previous_workday_intraday_datetime, get_next_workday_intraday_datetime, get_naive_datetime_from_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:00.443176Z",
     "start_time": "2021-05-15T06:11:00.419241Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import py_restart\n",
    "from utils import py_workdays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データベース "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:00.759330Z",
     "start_time": "2021-05-15T06:11:00.453149Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = Path(\"E:/システムトレード入門/trade_system_git_workspace/db/sub_stock_db/nikkei_255_stock_v2.db\")\n",
    "stock_db = StockDatabase(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.080127Z",
     "start_time": "2021-05-15T06:11:00.777282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([datetime.date(2020, 11, 2), datetime.date(2020, 11, 4),\n",
       "       datetime.date(2020, 11, 5), datetime.date(2020, 11, 6),\n",
       "       datetime.date(2020, 11, 9), datetime.date(2020, 11, 10),\n",
       "       datetime.date(2020, 11, 11), datetime.date(2020, 11, 12),\n",
       "       datetime.date(2020, 11, 13), datetime.date(2020, 11, 16),\n",
       "       datetime.date(2020, 11, 17), datetime.date(2020, 11, 18),\n",
       "       datetime.date(2020, 11, 19), datetime.date(2020, 11, 20),\n",
       "       datetime.date(2020, 11, 24), datetime.date(2020, 11, 25),\n",
       "       datetime.date(2020, 11, 26), datetime.date(2020, 11, 27),\n",
       "       datetime.date(2020, 11, 30)], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jst_timezone = timezone(\"Asia/Tokyo\")\n",
    "all_start_datetime = jst_timezone.localize(datetime.datetime(2020,11,1,0,0,0))\n",
    "all_end_datetime = jst_timezone.localize(datetime.datetime(2020,12,1,0,0,0))\n",
    "py_workdays.get_workdays_jp(all_start_datetime.date(), all_end_datetime.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.112041Z",
     "start_time": "2021-05-15T06:11:03.092094Z"
    }
   },
   "outputs": [],
   "source": [
    "#start_datetime = jst_timezone.localize(datetime.datetime(2020,11,10,9,0,0))\n",
    "#end_datetime = jst_timezone.localize(datetime.datetime(2020,11,20,15,0,0))\n",
    "#stock_list = [\"4755\",\"9984\",\"6701\",\"7203\",\"7267\"]\n",
    "\n",
    "#stock_df = stock_db.search_span(stock_names=stock_list, \n",
    "#                                start_datetime=start_datetime,\n",
    "#                                end_datetime=end_datetime,\n",
    "#                                freq_str=\"5T\",\n",
    "#                                to_tokyo=True\n",
    "#                               )\n",
    "\n",
    "#stock_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 供給データ単位クラス"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "供給されるデータの単位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.159912Z",
     "start_time": "2021-05-15T06:11:03.121017Z"
    }
   },
   "outputs": [],
   "source": [
    "field_list = [\"names\",  # 銘柄名\n",
    "              \"key_currency_index\",  # 基軸通貨のインデックス\n",
    "              \"datetime\",  # データの日時\n",
    "              \"window\",  # データのウィンドウ\n",
    "              \"open_array\",  # [銘柄名, ウィンドウ(時間)]に対応する始値\n",
    "              \"close_array\",  # [銘柄名, ウィンドウ(時間)]に対応する終値\n",
    "              \"high_array\",  # [銘柄名, ウィンドウ(時間)]に対応する高値\n",
    "              \"low_array\",  # [銘柄名, ウィンドウ(時間)]に対応する低値\n",
    "              \"volume_array\"  # [銘柄名, ウィンドウ(時間)]に対応する取引量\n",
    "             ]\n",
    "\n",
    "DataSupplyUnitBase = namedtuple(\"DataSupplyUnitBase\", field_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.207785Z",
     "start_time": "2021-05-15T06:11:03.168890Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataSupplyUnit(DataSupplyUnitBase):\n",
    "    \"\"\"\n",
    "    DataSupplierによって提供されるデータクラス\n",
    "    \"\"\"\n",
    "    def __str__(self):\n",
    "        return_str = \"DataSupplyUnit( \\n\"\n",
    "        for field_str in self._fields:\n",
    "            return_str += field_str + \"=\"\n",
    "            return_str += str(getattr(self, field_str)) + \"\\n\"\n",
    "        return_str += \")\"\n",
    "        return return_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ポートフォリオ状態クラス "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ポートフォリオの状態を表すクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.238703Z",
     "start_time": "2021-05-15T06:11:03.217759Z"
    }
   },
   "outputs": [],
   "source": [
    "field_list = [\"names\",  # 銘柄名\n",
    "              \"key_currency_index\",  # 基軸通貨のインデックス\n",
    "              \"window\",  # データのウィンドウ\n",
    "              \"datetime\",  # データの日時\n",
    "              \"price_array\",  # [銘柄名, ウィンドウ(時間)]に対応する現在価格\n",
    "              \"volume_array\",  # [銘柄名, ウィンドウ(時間)]に対応する取引量\n",
    "              \"now_price_array\",  # 銘柄名に対応する現在価格\n",
    "              \"portfolio_vector\",  # ポートフォリオベクトル\n",
    "              \"mean_cost_price_array\",  # 銘柄名に対応する平均取得価格\n",
    "              \"all_assets\"  # 基軸通貨で換算した全資産\n",
    "             ]\n",
    "\n",
    "PortfolioStateBase = namedtuple(\"PortfolioStateBase\", field_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.350404Z",
     "start_time": "2021-05-15T06:11:03.266628Z"
    }
   },
   "outputs": [],
   "source": [
    "class PortfolioState(PortfolioStateBase):\n",
    "    \"\"\"\n",
    "    バックテスト・強化学習で利用するTransformerが提供するデータクラス．強化学習における状態を内包する．\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def numbers(self):\n",
    "        \"\"\"\n",
    "        保有量のプロパティ\n",
    "        \"\"\"\n",
    "        return self.all_assets*self.portfolio_vector/self.now_price_array\n",
    "    \n",
    "    def __str__(self):\n",
    "        return_str = \"PortfolioState( \\n\"\n",
    "        for field_str in self._fields:\n",
    "            return_str += field_str + \"=\"\n",
    "            return_str += str(getattr(self, field_str)) + \"\\n\"\n",
    "        return_str += \")\"\n",
    "        return return_str\n",
    "    \n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        自身のコビーを返す．ndarrayのプロパティの場合はそのコビーを保持する．\n",
    "        \"\"\"\n",
    "        arg_dict = {}\n",
    "        for field_str in self._fields:\n",
    "            field_value = getattr(self, field_str)\n",
    "            if isinstance(field_value, np.ndarray):\n",
    "                field_value = field_value.copy()\n",
    "            \n",
    "            arg_dict[field_str] = field_value\n",
    "        \n",
    "        return PortfolioState(**arg_dict)\n",
    "    \n",
    "    def partial(self, *args):\n",
    "        \"\"\"\n",
    "        メモリ等の状況によって，自身の部分的なコビーを返す．\n",
    "        引数にを耐えられなかったプロパティはNoneとなる．\n",
    "        \"\"\"\n",
    "        arg_dict = {}\n",
    "        for field_str in self._fields:\n",
    "            if field_str in args:\n",
    "                field_value = getattr(self, field_str)\n",
    "                if isinstance(field_value, np.ndarray):\n",
    "                    field_value = field_value.copy()\n",
    "            else:\n",
    "                field_value = None\n",
    "            \n",
    "            arg_dict[field_str] = field_value\n",
    "            \n",
    "        return PortfolioState(**arg_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの供給クラス "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.398276Z",
     "start_time": "2021-05-15T06:11:03.358381Z"
    }
   },
   "outputs": [],
   "source": [
    "class PriceSuppliier(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def reset(self, start_datetime, window):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def step(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.429192Z",
     "start_time": "2021-05-15T06:11:03.408247Z"
    }
   },
   "outputs": [],
   "source": [
    "class CannotGetAllDataError(Exception):\n",
    "    def __init__(self, strings):\n",
    "        self.strings = strings\n",
    "    def __str__(self):\n",
    "        return self.strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は株価データベースを用いて価格を供給する．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ナイーブな実装 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:03.856054Z",
     "start_time": "2021-05-15T06:11:03.470083Z"
    }
   },
   "outputs": [],
   "source": [
    "class StockDBPriceSupplier(PriceSuppliier):\n",
    "    \"\"\"\n",
    "    StockDatabaseに対応するPriceSupplier\n",
    "    \"\"\"\n",
    "    def __init__(self, stock_db, ticker_names, episode_length, freq_str, interpolate=True):\n",
    "        self.stock_db = stock_db\n",
    "        self.ticker_names = ticker_names\n",
    "        self.episode_length = episode_length\n",
    "        self.freq_str = freq_str        \n",
    "        self.interpolate = interpolate\n",
    "        # column_namesを分かりやすくまとめる\n",
    "        self.column_names_list_dict = {}\n",
    "        for column_type in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "            self.column_names_list_dict[column_type] = [column_type+\"_\"+ticker_name for ticker_name in self.ticker_names]\n",
    "        \n",
    "    def reset(self, start_datetime, window=np.array([0])):\n",
    "        \"\"\"\n",
    "        start_datetime: datetime.datetime \n",
    "            データ供給の開始時刻\n",
    "        window: ndarray\n",
    "            データ供給のウィンドウ\n",
    "        \"\"\"\n",
    "        # 終了時刻を求める\n",
    "        # 全datetimeデータを保持\n",
    "        assert 0 in window\n",
    "        if not isinstance(window, np.ndarray):\n",
    "            self.window = np.array(window)\n",
    "        else:\n",
    "            self.window = window\n",
    "        \n",
    "        min_window = min(self.window)\n",
    "        max_window = max(self.window)\n",
    "        \n",
    "        if min_window <= 0:\n",
    "            episode_start_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(min_window))\n",
    "        else:\n",
    "            episode_start_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, min_window)\n",
    "            \n",
    "        if self.episode_length+max_window <= 0:  # 基本的にあり得ない\n",
    "            episode_end_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(self.episode_length+max_window))\n",
    "        else:\n",
    "            episode_end_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, self.episode_length+max_window)\n",
    "        \n",
    "        episode_df = self.stock_db.search_span(stock_names=self.ticker_names,\n",
    "                                               start_datetime=episode_start_datetime,\n",
    "                                               end_datetime=episode_end_datetime,\n",
    "                                               freq_str=self.freq_str,\n",
    "                                               is_end_include=True,  # 最後の値も含める\n",
    "                                               to_tokyo=True,  #必ずTrueに\n",
    "                                              )\n",
    "        \n",
    "        self.episode_df = py_workdays.extract_workdays_intraday_jp(episode_df)\n",
    "        \n",
    "        all_datetime_index = pd.date_range(start=episode_start_datetime,\n",
    "                                           end=episode_end_datetime,\n",
    "                                           freq=self.freq_str,\n",
    "                                           closed=\"left\"\n",
    "                                          )\n",
    "        self.all_datetime_index = py_workdays.extract_workdays_intraday_jp_index(all_datetime_index)\n",
    "        \n",
    "        # episode_dfの補間\n",
    "        if self.interpolate:\n",
    "            add_datetime_bool = ~self.all_datetime_index.isin(self.episode_df.index)\n",
    "            add_datetime_index = self.all_datetime_index[add_datetime_bool]\n",
    "            # Noneのdfを作成\n",
    "            nan_df = pd.DataFrame(None, index=add_datetime_index)\n",
    "            for one_column in self.episode_df.columns:\n",
    "                  nan_df[one_column] = np.nan\n",
    "                    \n",
    "            # Noneのdfを追加\n",
    "            self.episode_df = self.episode_df.append(nan_df)\n",
    "            self.episode_df.sort_index(inplace=True)\n",
    "            \n",
    "            # np.nanの補間\n",
    "            self.episode_df.interpolate(limit_direction=\"both\",inplace=True)\n",
    "        \n",
    "        # データの取得\n",
    "        self.now_index = abs(min_window)\n",
    "        now_datetime = self.all_datetime_index[self.now_index].to_pydatetime()\n",
    "        \n",
    "        add_window = [self.now_index+one_value for one_value in self.window]\n",
    "        window_index_array = self.all_datetime_index[add_window]\n",
    "        window_data_df = self.episode_df.loc[window_index_array,:]\n",
    "        \n",
    "        open_array = window_data_df.loc[:,self.column_names_list_dict[\"Open\"]].values.T\n",
    "        high_array = window_data_df.loc[:,self.column_names_list_dict[\"High\"]].values.T\n",
    "        low_array = window_data_df.loc[:,self.column_names_list_dict[\"Low\"]].values.T\n",
    "        close_array = window_data_df.loc[:,self.column_names_list_dict[\"Close\"]].values.T\n",
    "        volume_array = window_data_df.loc[:,self.column_names_list_dict[\"Volume\"]].values.T\n",
    "        \n",
    "        open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
    "        high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
    "        low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
    "        close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
    "        volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
    "        \n",
    "        \n",
    "        out_ticker_names = [\"yen\"]\n",
    "        out_ticker_names.extend(self.ticker_names)\n",
    "        \n",
    "        out_unit = DataSupplyUnit(names=out_ticker_names,\n",
    "                                  key_currency_index=0,\n",
    "                                  datetime=now_datetime,\n",
    "                                  window=self.window,\n",
    "                                  open_array=open_array,\n",
    "                                  close_array=close_array,\n",
    "                                  high_array=high_array,\n",
    "                                  low_array=low_array,\n",
    "                                  volume_array=volume_array\n",
    "                                 )\n",
    "        done = False\n",
    "        return out_unit, done\n",
    "    \n",
    "    def step(self):\n",
    "        # indexの更新\n",
    "        self.now_index += 1\n",
    "        now_datetime = self.all_datetime_index[self.now_index].to_pydatetime()\n",
    "        \n",
    "        add_window = [self.now_index+one_value for one_value in self.window]\n",
    "        window_index_array = self.all_datetime_index[add_window]\n",
    "        window_data_df = self.episode_df.loc[window_index_array,:]\n",
    "        \n",
    "        open_array = window_data_df.loc[:,self.column_names_list_dict[\"Open\"]].values.T\n",
    "        high_array = window_data_df.loc[:,self.column_names_list_dict[\"High\"]].values.T\n",
    "        low_array = window_data_df.loc[:,self.column_names_list_dict[\"Low\"]].values.T\n",
    "        close_array = window_data_df.loc[:,self.column_names_list_dict[\"Close\"]].values.T\n",
    "        volume_array = window_data_df.loc[:,self.column_names_list_dict[\"Volume\"]].values.T\n",
    "        \n",
    "        \n",
    "        open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
    "        high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
    "        low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
    "        close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
    "        volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
    "        \n",
    "        out_ticker_names = [\"yen\"]\n",
    "        out_ticker_names.extend(self.ticker_names)\n",
    "        \n",
    "        out_unit = DataSupplyUnit(names=out_ticker_names,\n",
    "                                  key_currency_index=0,\n",
    "                                  datetime=now_datetime,\n",
    "                                  window=self.window,\n",
    "                                  open_array=open_array,\n",
    "                                  close_array=close_array,\n",
    "                                  high_array=high_array,\n",
    "                                  low_array=low_array,\n",
    "                                  volume_array=volume_array\n",
    "                                 )\n",
    "        done = self.now_index >= self.episode_length\n",
    "        \n",
    "        return out_unit, done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:04.109376Z",
     "start_time": "2021-05-15T06:11:03.879989Z"
    }
   },
   "outputs": [],
   "source": [
    "start_datetime = jst_timezone.localize(datetime.datetime(2020,11,10,9,0,0))\n",
    "stock_list = [\"4755\",\"9984\",\"6701\",\"7203\",\"7267\"]\n",
    "episode_length = 50\n",
    "\n",
    "price_supplier = StockDBPriceSupplier(stock_db=stock_db,\n",
    "                                     ticker_names=stock_list,\n",
    "                                     episode_length=episode_length,\n",
    "                                     freq_str=\"5T\",\n",
    "                                     interpolate=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:05.218411Z",
     "start_time": "2021-05-15T06:11:04.119349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSupplyUnit( \n",
      "names=['yen', '4755', '9984', '6701', '7203', '7267']\n",
      "key_currency_index=0\n",
      "datetime=2020-11-10 09:00:00+09:00\n",
      "window=[-3 -2 -1  0  1  2  3]\n",
      "open_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1200e+03 1.1190e+03 1.1190e+03 1.1250e+03 1.1270e+03 1.1080e+03\n",
      "  1.1050e+03]\n",
      " [7.0770e+03 7.0680e+03 7.0730e+03 7.0040e+03 7.0720e+03 7.0190e+03\n",
      "  7.0040e+03]\n",
      " [5.7600e+03 5.7600e+03 5.7600e+03 5.7300e+03 5.7000e+03 5.7300e+03\n",
      "  5.7100e+03]\n",
      " [7.1810e+03 7.1750e+03 7.1770e+03 7.3200e+03 7.3430e+03 7.3380e+03\n",
      "  7.3550e+03]\n",
      " [2.8435e+03 2.8400e+03 2.8395e+03 2.9200e+03 2.9595e+03 2.9420e+03\n",
      "  2.9710e+03]]\n",
      "close_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1200e+03 1.1190e+03 1.1170e+03 1.1280e+03 1.1070e+03 1.1050e+03\n",
      "  1.0620e+03]\n",
      " [7.0690e+03 7.0740e+03 7.0960e+03 7.0720e+03 7.0190e+03 7.0040e+03\n",
      "  6.9880e+03]\n",
      " [5.7600e+03 5.7600e+03 5.7600e+03 5.6800e+03 5.7200e+03 5.7100e+03\n",
      "  5.6900e+03]\n",
      " [7.1750e+03 7.1770e+03 7.1770e+03 7.3420e+03 7.3360e+03 7.3530e+03\n",
      "  7.3280e+03]\n",
      " [2.8400e+03 2.8395e+03 2.8340e+03 2.9595e+03 2.9415e+03 2.9705e+03\n",
      "  2.9310e+03]]\n",
      "high_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1200e+03 1.1190e+03 1.1190e+03 1.1320e+03 1.1290e+03 1.1100e+03\n",
      "  1.1050e+03]\n",
      " [7.0820e+03 7.0740e+03 7.0960e+03 7.0770e+03 7.0770e+03 7.0270e+03\n",
      "  7.0070e+03]\n",
      " [5.7700e+03 5.7600e+03 5.7600e+03 5.7300e+03 5.7300e+03 5.7400e+03\n",
      "  5.7200e+03]\n",
      " [7.1830e+03 7.1770e+03 7.1850e+03 7.3440e+03 7.3550e+03 7.3600e+03\n",
      "  7.3560e+03]\n",
      " [2.8450e+03 2.8420e+03 2.8415e+03 2.9635e+03 2.9690e+03 2.9720e+03\n",
      "  2.9725e+03]]\n",
      "low_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1190e+03 1.1180e+03 1.1170e+03 1.1240e+03 1.1050e+03 1.0990e+03\n",
      "  1.0550e+03]\n",
      " [7.0660e+03 7.0530e+03 7.0730e+03 6.9350e+03 6.9900e+03 6.9640e+03\n",
      "  6.9770e+03]\n",
      " [5.7600e+03 5.7500e+03 5.7500e+03 5.6700e+03 5.6800e+03 5.7000e+03\n",
      "  5.6800e+03]\n",
      " [7.1680e+03 7.1720e+03 7.1720e+03 7.3020e+03 7.3150e+03 7.3210e+03\n",
      "  7.3230e+03]\n",
      " [2.8395e+03 2.8350e+03 2.8340e+03 2.8840e+03 2.9340e+03 2.9235e+03\n",
      "  2.9255e+03]]\n",
      "volume_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [7.1600e+04 9.3300e+04 4.1190e+05 8.7840e+05 5.8380e+05 2.5710e+05\n",
      "  7.9410e+05]\n",
      " [2.3750e+05 3.0980e+05 3.7840e+05 2.5031e+06 8.4220e+05 7.3700e+05\n",
      "  4.2530e+05]\n",
      " [4.8200e+04 1.5600e+04 4.2800e+04 2.6540e+05 7.0900e+04 5.5200e+04\n",
      "  7.5200e+04]\n",
      " [1.3520e+05 1.6710e+05 1.7530e+05 1.3002e+06 4.5750e+05 3.2870e+05\n",
      "  1.7930e+05]\n",
      " [1.4200e+05 1.9780e+05 2.6770e+05 1.0599e+06 4.1260e+05 2.6840e+05\n",
      "  2.4110e+05]]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_unit, _ = price_supplier.reset(start_datetime, window=[-3,-2,-1,0,1,2,3])\n",
    "print(data_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:05.266280Z",
     "start_time": "2021-05-15T06:11:05.227387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '_asdict',\n",
       " '_field_defaults',\n",
       " '_fields',\n",
       " '_fields_defaults',\n",
       " '_make',\n",
       " '_replace',\n",
       " 'close_array',\n",
       " 'count',\n",
       " 'datetime',\n",
       " 'high_array',\n",
       " 'index',\n",
       " 'key_currency_index',\n",
       " 'low_array',\n",
       " 'names',\n",
       " 'open_array',\n",
       " 'volume_array',\n",
       " 'window']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(data_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:05.360029Z",
     "start_time": "2021-05-15T06:11:05.275258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSupplyUnit( \n",
      "names=['yen', '4755', '9984', '6701', '7203', '7267']\n",
      "key_currency_index=0\n",
      "datetime=2020-11-10 09:05:00+09:00\n",
      "window=[-3 -2 -1  0  1  2  3]\n",
      "open_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1190e+03 1.1190e+03 1.1250e+03 1.1270e+03 1.1080e+03 1.1050e+03\n",
      "  1.0630e+03]\n",
      " [7.0680e+03 7.0730e+03 7.0040e+03 7.0720e+03 7.0190e+03 7.0040e+03\n",
      "  6.9890e+03]\n",
      " [5.7600e+03 5.7600e+03 5.7300e+03 5.7000e+03 5.7300e+03 5.7100e+03\n",
      "  5.6800e+03]\n",
      " [7.1750e+03 7.1770e+03 7.3200e+03 7.3430e+03 7.3380e+03 7.3550e+03\n",
      "  7.3280e+03]\n",
      " [2.8400e+03 2.8395e+03 2.9200e+03 2.9595e+03 2.9420e+03 2.9710e+03\n",
      "  2.9325e+03]]\n",
      "close_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1190e+03 1.1170e+03 1.1280e+03 1.1070e+03 1.1050e+03 1.0620e+03\n",
      "  1.0760e+03]\n",
      " [7.0740e+03 7.0960e+03 7.0720e+03 7.0190e+03 7.0040e+03 6.9880e+03\n",
      "  6.9570e+03]\n",
      " [5.7600e+03 5.7600e+03 5.6800e+03 5.7200e+03 5.7100e+03 5.6900e+03\n",
      "  5.6700e+03]\n",
      " [7.1770e+03 7.1770e+03 7.3420e+03 7.3360e+03 7.3530e+03 7.3280e+03\n",
      "  7.3170e+03]\n",
      " [2.8395e+03 2.8340e+03 2.9595e+03 2.9415e+03 2.9705e+03 2.9310e+03\n",
      "  2.9170e+03]]\n",
      "high_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1190e+03 1.1190e+03 1.1320e+03 1.1290e+03 1.1100e+03 1.1050e+03\n",
      "  1.0830e+03]\n",
      " [7.0740e+03 7.0960e+03 7.0770e+03 7.0770e+03 7.0270e+03 7.0070e+03\n",
      "  6.9970e+03]\n",
      " [5.7600e+03 5.7600e+03 5.7300e+03 5.7300e+03 5.7400e+03 5.7200e+03\n",
      "  5.6900e+03]\n",
      " [7.1770e+03 7.1850e+03 7.3440e+03 7.3550e+03 7.3600e+03 7.3560e+03\n",
      "  7.3420e+03]\n",
      " [2.8420e+03 2.8415e+03 2.9635e+03 2.9690e+03 2.9720e+03 2.9725e+03\n",
      "  2.9510e+03]]\n",
      "low_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1180e+03 1.1170e+03 1.1240e+03 1.1050e+03 1.0990e+03 1.0550e+03\n",
      "  1.0630e+03]\n",
      " [7.0530e+03 7.0730e+03 6.9350e+03 6.9900e+03 6.9640e+03 6.9770e+03\n",
      "  6.9570e+03]\n",
      " [5.7500e+03 5.7500e+03 5.6700e+03 5.6800e+03 5.7000e+03 5.6800e+03\n",
      "  5.6700e+03]\n",
      " [7.1720e+03 7.1720e+03 7.3020e+03 7.3150e+03 7.3210e+03 7.3230e+03\n",
      "  7.3150e+03]\n",
      " [2.8350e+03 2.8340e+03 2.8840e+03 2.9340e+03 2.9235e+03 2.9255e+03\n",
      "  2.9105e+03]]\n",
      "volume_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [9.3300e+04 4.1190e+05 8.7840e+05 5.8380e+05 2.5710e+05 7.9410e+05\n",
      "  4.6700e+05]\n",
      " [3.0980e+05 3.7840e+05 2.5031e+06 8.4220e+05 7.3700e+05 4.2530e+05\n",
      "  4.1350e+05]\n",
      " [1.5600e+04 4.2800e+04 2.6540e+05 7.0900e+04 5.5200e+04 7.5200e+04\n",
      "  7.9000e+04]\n",
      " [1.6710e+05 1.7530e+05 1.3002e+06 4.5750e+05 3.2870e+05 1.7930e+05\n",
      "  1.9250e+05]\n",
      " [1.9780e+05 2.6770e+05 1.0599e+06 4.1260e+05 2.6840e+05 2.4110e+05\n",
      "  1.7630e+05]]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_unit, _ = price_supplier.step()\n",
    "print(data_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### プロファイリング "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:08.988332Z",
     "start_time": "2021-05-15T06:11:05.371001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0002149 s\n",
      "File: <ipython-input-16-ef1a042b3c0f>\n",
      "Function: __init__ at line 5\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     5                                               def __init__(self, stock_db, ticker_names, episode_length, freq_str, interpolate=True):\n",
      "     6         1        230.0    230.0     10.7          self.stock_db = stock_db\n",
      "     7         1         70.0     70.0      3.3          self.ticker_names = ticker_names\n",
      "     8         1         59.0     59.0      2.7          self.episode_length = episode_length\n",
      "     9         1         59.0     59.0      2.7          self.freq_str = freq_str        \n",
      "    10         1         59.0     59.0      2.7          self.interpolate = interpolate\n",
      "    11                                                   # column_namesを分かりやすくまとめる\n",
      "    12         1         67.0     67.0      3.1          self.column_names_list_dict = {}\n",
      "    13         6        335.0     55.8     15.6          for column_type in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
      "    14         5       1270.0    254.0     59.1              self.column_names_list_dict[column_type] = [column_type+\"_\"+ticker_name for ticker_name in self.ticker_names]\n",
      "\n",
      "Total time: 1.61109 s\n",
      "File: <ipython-input-16-ef1a042b3c0f>\n",
      "Function: reset at line 16\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    16                                               def reset(self, start_datetime, window=np.array([0])):\n",
      "    17                                                   \"\"\"\n",
      "    18                                                   start_datetime: datetime.datetime \n",
      "    19                                                       データ供給の開始時刻\n",
      "    20                                                   window: ndarray\n",
      "    21                                                       データ供給のウィンドウ\n",
      "    22                                                   \"\"\"\n",
      "    23                                                   # 終了時刻を求める\n",
      "    24                                                   # 全datetimeデータを保持\n",
      "    25         1        141.0    141.0      0.0          assert 0 in window\n",
      "    26         1        183.0    183.0      0.0          if not isinstance(window, np.ndarray):\n",
      "    27         1        457.0    457.0      0.0              self.window = np.array(window)\n",
      "    28                                                   else:\n",
      "    29                                                       self.window = window\n",
      "    30                                                   \n",
      "    31         1        500.0    500.0      0.0          min_window = min(self.window)\n",
      "    32         1        307.0    307.0      0.0          max_window = max(self.window)\n",
      "    33                                                   \n",
      "    34         1        181.0    181.0      0.0          if min_window <= 0:\n",
      "    35         1      34054.0  34054.0      0.2              episode_start_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(min_window))\n",
      "    36                                                   else:\n",
      "    37                                                       episode_start_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, min_window)\n",
      "    38                                                       \n",
      "    39         1        290.0    290.0      0.0          if self.episode_length+max_window <= 0:  # 基本的にあり得ない\n",
      "    40                                                       episode_end_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(self.episode_length+max_window))\n",
      "    41                                                   else:\n",
      "    42         1      26740.0  26740.0      0.2              episode_end_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, self.episode_length+max_window)\n",
      "    43                                                   \n",
      "    44         1        405.0    405.0      0.0          episode_df = self.stock_db.search_span(stock_names=self.ticker_names,\n",
      "    45         1         94.0     94.0      0.0                                                 start_datetime=episode_start_datetime,\n",
      "    46         1         95.0     95.0      0.0                                                 end_datetime=episode_end_datetime,\n",
      "    47         1        219.0    219.0      0.0                                                 freq_str=self.freq_str,\n",
      "    48         1        268.0    268.0      0.0                                                 is_end_include=True,  # 最後の値も含める\n",
      "    49         1   10518828.0 10518828.0     65.3                                                 to_tokyo=True,  #必ずTrueに\n",
      "    50                                                                                         )\n",
      "    51                                                   \n",
      "    52         1     163251.0 163251.0      1.0          self.episode_df = py_workdays.extract_workdays_intraday_jp(episode_df)\n",
      "    53                                                   \n",
      "    54         1        180.0    180.0      0.0          all_datetime_index = pd.date_range(start=episode_start_datetime,\n",
      "    55         1        117.0    117.0      0.0                                             end=episode_end_datetime,\n",
      "    56         1        140.0    140.0      0.0                                             freq=self.freq_str,\n",
      "    57         1     168191.0 168191.0      1.0                                             closed=\"left\"\n",
      "    58                                                                                     )\n",
      "    59         1     222600.0 222600.0      1.4          self.all_datetime_index = py_workdays.extract_workdays_intraday_jp_index(all_datetime_index)\n",
      "    60                                                   \n",
      "    61                                                   # episode_dfの補間\n",
      "    62         1        185.0    185.0      0.0          if self.interpolate:\n",
      "    63         1      20760.0  20760.0      0.1              add_datetime_bool = ~self.all_datetime_index.isin(self.episode_df.index)\n",
      "    64         1      24328.0  24328.0      0.2              add_datetime_index = self.all_datetime_index[add_datetime_bool]\n",
      "    65                                                       # Noneのdfを作成\n",
      "    66         1      40835.0  40835.0      0.3              nan_df = pd.DataFrame(None, index=add_datetime_index)\n",
      "    67        26       5881.0    226.2      0.0              for one_column in self.episode_df.columns:\n",
      "    68        25    3932709.0 157308.4     24.4                    nan_df[one_column] = np.nan\n",
      "    69                                                               \n",
      "    70                                                       # Noneのdfを追加\n",
      "    71         1     129949.0 129949.0      0.8              self.episode_df = self.episode_df.append(nan_df)\n",
      "    72         1       3746.0   3746.0      0.0              self.episode_df.sort_index(inplace=True)\n",
      "    73                                                       \n",
      "    74                                                       # np.nanの補間\n",
      "    75         1     200934.0 200934.0      1.2              self.episode_df.interpolate(limit_direction=\"both\",inplace=True)\n",
      "    76                                                   \n",
      "    77                                                   # データの取得\n",
      "    78         1        229.0    229.0      0.0          self.now_index = abs(min_window)\n",
      "    79         1       3932.0   3932.0      0.0          now_datetime = self.all_datetime_index[self.now_index].to_pydatetime()\n",
      "    80                                                   \n",
      "    81         1        636.0    636.0      0.0          add_window = [self.now_index+one_value for one_value in self.window]\n",
      "    82         1      28534.0  28534.0      0.2          window_index_array = self.all_datetime_index[add_window]\n",
      "    83         1      35026.0  35026.0      0.2          window_data_df = self.episode_df.loc[window_index_array,:]\n",
      "    84                                                   \n",
      "    85         1     125281.0 125281.0      0.8          open_array = window_data_df.loc[:,self.column_names_list_dict[\"Open\"]].values.T\n",
      "    86         1      98313.0  98313.0      0.6          high_array = window_data_df.loc[:,self.column_names_list_dict[\"High\"]].values.T\n",
      "    87         1      84040.0  84040.0      0.5          low_array = window_data_df.loc[:,self.column_names_list_dict[\"Low\"]].values.T\n",
      "    88         1     114150.0 114150.0      0.7          close_array = window_data_df.loc[:,self.column_names_list_dict[\"Close\"]].values.T\n",
      "    89         1     119068.0 119068.0      0.7          volume_array = window_data_df.loc[:,self.column_names_list_dict[\"Volume\"]].values.T\n",
      "    90                                                   \n",
      "    91         1       1015.0   1015.0      0.0          open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
      "    92         1        599.0    599.0      0.0          high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
      "    93         1        548.0    548.0      0.0          low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
      "    94         1        537.0    537.0      0.0          close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
      "    95         1        520.0    520.0      0.0          volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
      "    96                                                   \n",
      "    97                                                   \n",
      "    98         1        123.0    123.0      0.0          out_ticker_names = [\"yen\"]\n",
      "    99         1        197.0    197.0      0.0          out_ticker_names.extend(self.ticker_names)\n",
      "   100                                                   \n",
      "   101         1        137.0    137.0      0.0          out_unit = DataSupplyUnit(names=out_ticker_names,\n",
      "   102         1        123.0    123.0      0.0                                    key_currency_index=0,\n",
      "   103         1        129.0    129.0      0.0                                    datetime=now_datetime,\n",
      "   104         1        147.0    147.0      0.0                                    window=self.window,\n",
      "   105         1        132.0    132.0      0.0                                    open_array=open_array,\n",
      "   106         1        133.0    133.0      0.0                                    close_array=close_array,\n",
      "   107         1        117.0    117.0      0.0                                    high_array=high_array,\n",
      "   108         1        116.0    116.0      0.0                                    low_array=low_array,\n",
      "   109         1        349.0    349.0      0.0                                    volume_array=volume_array\n",
      "   110                                                                            )\n",
      "   111         1        121.0    121.0      0.0          done = False\n",
      "   112         1        125.0    125.0      0.0          return out_unit, done\n",
      "\n",
      "Total time: 1.77241 s\n",
      "File: <ipython-input-16-ef1a042b3c0f>\n",
      "Function: step at line 114\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   114                                               def step(self):\n",
      "   115                                                   # indexの更新\n",
      "   116        30       5610.0    187.0      0.0          self.now_index += 1\n",
      "   117        30     111487.0   3716.2      0.6          now_datetime = self.all_datetime_index[self.now_index].to_pydatetime()\n",
      "   118                                                   \n",
      "   119        30      18695.0    623.2      0.1          add_window = [self.now_index+one_value for one_value in self.window]\n",
      "   120        30    1081674.0  36055.8      6.1          window_index_array = self.all_datetime_index[add_window]\n",
      "   121        30    1195764.0  39858.8      6.7          window_data_df = self.episode_df.loc[window_index_array,:]\n",
      "   122                                                   \n",
      "   123        30    3358784.0 111959.5     19.0          open_array = window_data_df.loc[:,self.column_names_list_dict[\"Open\"]].values.T\n",
      "   124        30    2860154.0  95338.5     16.1          high_array = window_data_df.loc[:,self.column_names_list_dict[\"High\"]].values.T\n",
      "   125        30    3380314.0 112677.1     19.1          low_array = window_data_df.loc[:,self.column_names_list_dict[\"Low\"]].values.T\n",
      "   126        30    2993821.0  99794.0     16.9          close_array = window_data_df.loc[:,self.column_names_list_dict[\"Close\"]].values.T\n",
      "   127        30    2589204.0  86306.8     14.6          volume_array = window_data_df.loc[:,self.column_names_list_dict[\"Volume\"]].values.T\n",
      "   128                                                   \n",
      "   129                                                   \n",
      "   130        30      26387.0    879.6      0.1          open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
      "   131        30      19499.0    650.0      0.1          high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
      "   132        30      14613.0    487.1      0.1          low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
      "   133        30      14083.0    469.4      0.1          close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
      "   134        30      13191.0    439.7      0.1          volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
      "   135                                                   \n",
      "   136        30       2342.0     78.1      0.0          out_ticker_names = [\"yen\"]\n",
      "   137        30       4190.0    139.7      0.0          out_ticker_names.extend(self.ticker_names)\n",
      "   138                                                   \n",
      "   139        30       2379.0     79.3      0.0          out_unit = DataSupplyUnit(names=out_ticker_names,\n",
      "   140        30       1933.0     64.4      0.0                                    key_currency_index=0,\n",
      "   141        30       1956.0     65.2      0.0                                    datetime=now_datetime,\n",
      "   142        30       2270.0     75.7      0.0                                    window=self.window,\n",
      "   143        30       1917.0     63.9      0.0                                    open_array=open_array,\n",
      "   144        30       2059.0     68.6      0.0                                    close_array=close_array,\n",
      "   145        30       2821.0     94.0      0.0                                    high_array=high_array,\n",
      "   146        30       2732.0     91.1      0.0                                    low_array=low_array,\n",
      "   147        30       9392.0    313.1      0.1                                    volume_array=volume_array\n",
      "   148                                                                            )\n",
      "   149        30       4753.0    158.4      0.0          done = self.now_index >= self.episode_length\n",
      "   150                                                   \n",
      "   151        30       2105.0     70.2      0.0          return out_unit, done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def temp_func():\n",
    "    price_supplier = StockDBPriceSupplier(stock_db=stock_db,\n",
    "                                         ticker_names=stock_list,\n",
    "                                         episode_length=episode_length,\n",
    "                                         freq_str=\"5T\",\n",
    "                                         interpolate=True\n",
    "                                        )\n",
    "    data_unit, _ = price_supplier.reset(start_datetime, window=[-3,-2,-1,0,1,2,3])\n",
    "    for i in range(30):\n",
    "        data_unit, _ = price_supplier.step()\n",
    "    \n",
    "from line_profiler import LineProfiler\n",
    "prf = LineProfiler()                                                                                         \n",
    "prf.add_module(StockDBPriceSupplier)                                                                                          \n",
    "#prf.add_function()                                                                                      \n",
    "prf.runcall(temp_func)                         \n",
    "prf.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の部分の処理が2msもかかるのはおかしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:12.957720Z",
     "start_time": "2021-05-15T06:11:08.997309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81 ms ± 1.98 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "window_index_array = price_supplier.all_datetime_index[[1,2,3,4,5]]\n",
    "window_data_df = price_supplier.episode_df.loc[window_index_array,:]\n",
    "%timeit open_array = window_data_df.loc[:,price_supplier.column_names_list_dict[\"Open\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:20.070816Z",
     "start_time": "2021-05-15T06:11:13.011577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.73 ms ± 2.9 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df.loc[:,[\"Open_4755\", \"High_4755\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:24.447103Z",
     "start_time": "2021-05-15T06:11:20.109702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.4 ms ± 1.76 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df[[\"Open_4755\", \"High_4755\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちなみにカラムが一つだけなら100倍近く高速である"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:26.488645Z",
     "start_time": "2021-05-15T06:11:24.457075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.5 µs ± 3.57 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df[\"Open_4755\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:27.911840Z",
     "start_time": "2021-05-15T06:11:26.503605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163 µs ± 18.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df.loc[:,\"Open_4755\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:34.870618Z",
     "start_time": "2021-05-15T06:11:27.921813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.75 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "9.3 ms ± 5.36 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df.loc[:,[\"Open_4755\", \"High_4755\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:37.279179Z",
     "start_time": "2021-05-15T06:11:34.880590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.86 ms ± 353 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "bool_list = [False for _ in window_data_df.columns]\n",
    "bool_list[0] = True\n",
    "bool_list[1] = True\n",
    "%timeit window_data_df.loc[:,bool_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarrayを直接扱う方がずっと高速である．しかし，一つの時はpandasの方が高速なのはなぜ？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:41.993575Z",
     "start_time": "2021-05-15T06:11:37.312089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.9 µs ± 7.94 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df.values[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:50.434016Z",
     "start_time": "2021-05-15T06:11:42.009534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 µs ± 23 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit window_data_df.values[:,[0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:11:52.370838Z",
     "start_time": "2021-05-15T06:11:50.445980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 µs ± 61.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "bool_list = [False for _ in window_data_df.columns]\n",
    "bool_list[0] = True\n",
    "bool_list[1] = True\n",
    "\n",
    "window_data_df.values[:,bool_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "locが遅いので，自分で簡単なクエリを実装する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:01.396711Z",
     "start_time": "2021-05-15T06:11:52.383802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 ms ± 178 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bool_list = window_data_df.columns.str.startswith(\"Open\")\n",
    "window_data_df.values[:,bool_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:05.195556Z",
     "start_time": "2021-05-15T06:12:01.406683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470 µs ± 136 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "bool_array = np.char.startswith(window_data_df.columns.values.astype(str), \"Open\")\n",
    "window_data_df.values[:,bool_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reset時にbool_arrayを求めてしまえば"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:05.226476Z",
     "start_time": "2021-05-15T06:12:05.205528Z"
    }
   },
   "outputs": [],
   "source": [
    "bool_array = np.char.startswith(window_data_df.columns.values.astype(str), \"Open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:12.604750Z",
     "start_time": "2021-05-15T06:12:05.236448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.7 µs ± 22.1 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "window_data_df.values[:,bool_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 速度面で修正"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-11T03:41:14.936625Z",
     "start_time": "2021-05-11T03:41:14.566617Z"
    }
   },
   "source": [
    "dfの保持を止め, ndarrayを直接クエリする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:13.175224Z",
     "start_time": "2021-05-15T06:12:12.639654Z"
    }
   },
   "outputs": [],
   "source": [
    "class StockDBPriceSupplier(PriceSuppliier):\n",
    "    \"\"\"\n",
    "    StockDatabaseに対応するPriceSupplier\n",
    "    \"\"\"\n",
    "    def __init__(self, stock_db, ticker_names, episode_length, freq_str, interpolate=True):\n",
    "        \"\"\"\n",
    "        stock_db: get_stock_price.StockDatabase\n",
    "            利用するStockDatabaseクラス\n",
    "        ticker_names: list of str\n",
    "            利用する銘柄名のリスト\n",
    "        episode_length: int\n",
    "            エピソードの長さ\n",
    "        freq_str: str\n",
    "            利用する周期を表す文字列\n",
    "        interpolate: bool\n",
    "            補間するかどうか\n",
    "        \"\"\"\n",
    "        self.stock_db = stock_db\n",
    "        self.ticker_names = ticker_names\n",
    "        self.episode_length = episode_length\n",
    "        self.freq_str = freq_str        \n",
    "        self.interpolate = interpolate\n",
    "        \n",
    "    def reset(self, start_datetime, window=np.array([0])):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        start_datetime: datetime.datetime \n",
    "            データ供給の開始時刻\n",
    "        window: ndarray\n",
    "            データ供給のウィンドウ\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        DatasupplyUnit\n",
    "            提供する価格データ\n",
    "        bool\n",
    "            エピソードが終了したかどうか\n",
    "        \"\"\"\n",
    "        # 終了時刻を求める\n",
    "        # 全datetimeデータを保持\n",
    "        assert 0 in window\n",
    "        if not isinstance(window, np.ndarray):\n",
    "            self.window = np.array(window)\n",
    "        else:\n",
    "            self.window = window\n",
    "            \n",
    "        if isinstance(self.ticker_names, np.ndarray):\n",
    "            self.ticker_names = self.ticker_names.tolist()\n",
    "        \n",
    "        if len(self.ticker_names)!=len(set(self.ticker_names)):\n",
    "            raise Exception(\"Ticker_names is duplicate\")\n",
    "        \n",
    "        min_window = min(self.window)\n",
    "        max_window = max(self.window)\n",
    "        \n",
    "        if min_window <= 0:\n",
    "            episode_start_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(min_window))\n",
    "        else:\n",
    "            episode_start_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, min_window)\n",
    "            \n",
    "        if self.episode_length+max_window <= 0:  # 基本的にあり得ない\n",
    "            episode_end_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(self.episode_length+max_window))\n",
    "        else:\n",
    "            episode_end_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, self.episode_length+max_window)\n",
    "        \n",
    "        episode_df = self.stock_db.search_span(stock_names=self.ticker_names,\n",
    "                                               start_datetime=episode_start_datetime,\n",
    "                                               end_datetime=episode_end_datetime,\n",
    "                                               freq_str=self.freq_str,\n",
    "                                               is_end_include=True,  # 最後の値も含める\n",
    "                                               to_tokyo=True,  #必ずTrueに\n",
    "                                              )\n",
    "        \n",
    "        self.episode_df = py_workdays.extract_workdays_intraday_jp(episode_df)\n",
    "        \n",
    "        # 各OHLCVに対応するboolを求めておく\n",
    "        column_names_array = self.episode_df.columns.values.astype(str)\n",
    "        self.open_bool_array = np.char.startswith(column_names_array, \"Open\")\n",
    "        self.high_bool_array = np.char.startswith(column_names_array, \"High\")\n",
    "        self.low_bool_array = np.char.startswith(column_names_array, \"Low\")\n",
    "        self.close_bool_array = np.char.startswith(column_names_array, \"Close\")\n",
    "        self.volume_bool_array = np.char.startswith(column_names_array, \"Volume\")\n",
    "        \n",
    "        \n",
    "        all_datetime_index = pd.date_range(start=episode_start_datetime,\n",
    "                                           end=episode_end_datetime,\n",
    "                                           freq=self.freq_str,\n",
    "                                           closed=\"left\"\n",
    "                                          )\n",
    "        self.all_datetime_index = py_workdays.extract_workdays_intraday_jp_index(all_datetime_index)\n",
    "        \n",
    "        # episode_dfの補間\n",
    "        if self.interpolate:\n",
    "            add_datetime_bool = ~self.all_datetime_index.isin(self.episode_df.index)\n",
    "            \n",
    "            # 補間を行う数が20%を越えた場合\n",
    "            if (add_datetime_bool.sum()/len(self.all_datetime_index)) > 0.1:\n",
    "                err_str = \"Interpolate exceeds 10 % about tickers={}, datetimes[{},{}]\".format(self.ticker_names,\n",
    "                                                                                               episode_start_datetime,\n",
    "                                                                                               episode_end_datetime)\n",
    "                raise CannotGetAllDataError(err_str)\n",
    "            \n",
    "            add_datetime_index = self.all_datetime_index[add_datetime_bool]\n",
    "            # Noneのdfを作成\n",
    "            nan_df = pd.DataFrame(index=add_datetime_index, columns=self.episode_df.columns)\n",
    "\n",
    "            # Noneのdfを追加\n",
    "            self.episode_df = self.episode_df.append(nan_df)\n",
    "            self.episode_df.sort_index(inplace=True)\n",
    "            \n",
    "            # np.nanの補間\n",
    "            self.episode_df.interpolate(limit_direction=\"both\",inplace=True)\n",
    "        else:\n",
    "            share_index_bool = self.all_datetime_index.isin(self.episode_df.index)\n",
    "            self.all_datetime_index = self.all_datetime_index[share_index_bool]\n",
    "        \n",
    "        # dfをndarrayに変更\n",
    "        self.episode_df_values = self.episode_df.values\n",
    "        del self.episode_df\n",
    "        \n",
    "        self.all_datetime_index_values = self.all_datetime_index.to_pydatetime()\n",
    "        del self.all_datetime_index\n",
    "        \n",
    "        # データが正しく取得できたかどうか\n",
    "        if np.isnan(self.episode_df_values).sum() > 0:\n",
    "            err_str = \"PriceSupplier cannot get data about tickers={}, datetimes[{},{}]\".format(self.ticker_names,\n",
    "                                                                                           episode_start_datetime,\n",
    "                                                                                           episode_end_datetime)\n",
    "            raise CannotGetAllDataError(err_str)\n",
    "        \n",
    "        \n",
    "        # データの取得\n",
    "        self.now_index = abs(min_window)\n",
    "        now_datetime = self.all_datetime_index_values[self.now_index]\n",
    "        \n",
    "        add_window = self.now_index + self.window\n",
    "        window_data_value = self.episode_df_values[add_window,:]\n",
    "        \n",
    "        open_array = window_data_value[:,self.open_bool_array].T\n",
    "        high_array = window_data_value[:,self.high_bool_array].T\n",
    "        low_array = window_data_value[:,self.low_bool_array].T\n",
    "        close_array = window_data_value[:,self.close_bool_array].T\n",
    "        volume_array = window_data_value[:,self.volume_bool_array].T\n",
    "        \n",
    "        open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
    "        high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
    "        low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
    "        close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
    "        volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
    "        \n",
    "        \n",
    "        out_ticker_names = [\"yen\"]\n",
    "        out_ticker_names.extend(self.ticker_names)\n",
    "        \n",
    "        out_unit = DataSupplyUnit(names=out_ticker_names,\n",
    "                                  key_currency_index=0,\n",
    "                                  datetime=now_datetime,\n",
    "                                  window=self.window,\n",
    "                                  open_array=open_array,\n",
    "                                  close_array=close_array,\n",
    "                                  high_array=high_array,\n",
    "                                  low_array=low_array,\n",
    "                                  volume_array=volume_array\n",
    "                                 )\n",
    "        done = False\n",
    "        return out_unit, done\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        DatasupplyUnit\n",
    "            提供する価格データ\n",
    "        bool\n",
    "            エピソードが終了したかどうか\n",
    "        \"\"\"\n",
    "        # indexの更新\n",
    "        self.now_index += 1\n",
    "        now_datetime = self.all_datetime_index_values[self.now_index]\n",
    "        \n",
    "        add_window = self.now_index + self.window\n",
    "        window_data_value = self.episode_df_values[add_window,:]\n",
    "        \n",
    "        open_array = window_data_value[:,self.open_bool_array].T\n",
    "        high_array = window_data_value[:,self.high_bool_array].T\n",
    "        low_array = window_data_value[:,self.low_bool_array].T\n",
    "        close_array = window_data_value[:,self.close_bool_array].T\n",
    "        volume_array = window_data_value[:,self.volume_bool_array].T\n",
    "         \n",
    "        open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
    "        high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
    "        low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
    "        close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
    "        volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
    "        \n",
    "        out_ticker_names = [\"yen\"]\n",
    "        out_ticker_names.extend(self.ticker_names)\n",
    "        \n",
    "        out_unit = DataSupplyUnit(names=out_ticker_names,\n",
    "                                  key_currency_index=0,\n",
    "                                  datetime=now_datetime,\n",
    "                                  window=self.window,\n",
    "                                  open_array=open_array,\n",
    "                                  close_array=close_array,\n",
    "                                  high_array=high_array,\n",
    "                                  low_array=low_array,\n",
    "                                  volume_array=volume_array\n",
    "                                 )\n",
    "        done = self.now_index >= self.episode_length\n",
    "        \n",
    "        return out_unit, done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:14.649285Z",
     "start_time": "2021-05-15T06:12:13.186194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n",
      "DataSupplyUnit( \n",
      "names=['yen', '4755', '9984', '6701', '7203', '7267']\n",
      "key_currency_index=0\n",
      "datetime=2020-11-10 09:00:00+09:00\n",
      "window=[0 1 2 3]\n",
      "open_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [1.1250e+03 1.1270e+03 1.1080e+03 1.1050e+03]\n",
      " [7.0040e+03 7.0720e+03 7.0190e+03 7.0040e+03]\n",
      " [5.7300e+03 5.7000e+03 5.7300e+03 5.7100e+03]\n",
      " [7.3200e+03 7.3430e+03 7.3380e+03 7.3550e+03]\n",
      " [2.9200e+03 2.9595e+03 2.9420e+03 2.9710e+03]]\n",
      "close_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [1.1280e+03 1.1070e+03 1.1050e+03 1.0620e+03]\n",
      " [7.0720e+03 7.0190e+03 7.0040e+03 6.9880e+03]\n",
      " [5.6800e+03 5.7200e+03 5.7100e+03 5.6900e+03]\n",
      " [7.3420e+03 7.3360e+03 7.3530e+03 7.3280e+03]\n",
      " [2.9595e+03 2.9415e+03 2.9705e+03 2.9310e+03]]\n",
      "high_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [1.1320e+03 1.1290e+03 1.1100e+03 1.1050e+03]\n",
      " [7.0770e+03 7.0770e+03 7.0270e+03 7.0070e+03]\n",
      " [5.7300e+03 5.7300e+03 5.7400e+03 5.7200e+03]\n",
      " [7.3440e+03 7.3550e+03 7.3600e+03 7.3560e+03]\n",
      " [2.9635e+03 2.9690e+03 2.9720e+03 2.9725e+03]]\n",
      "low_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [1.1240e+03 1.1050e+03 1.0990e+03 1.0550e+03]\n",
      " [6.9350e+03 6.9900e+03 6.9640e+03 6.9770e+03]\n",
      " [5.6700e+03 5.6800e+03 5.7000e+03 5.6800e+03]\n",
      " [7.3020e+03 7.3150e+03 7.3210e+03 7.3230e+03]\n",
      " [2.8840e+03 2.9340e+03 2.9235e+03 2.9255e+03]]\n",
      "volume_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [8.7840e+05 5.8380e+05 2.5710e+05 7.9410e+05]\n",
      " [2.5031e+06 8.4220e+05 7.3700e+05 4.2530e+05]\n",
      " [2.6540e+05 7.0900e+04 5.5200e+04 7.5200e+04]\n",
      " [1.3002e+06 4.5750e+05 3.2870e+05 1.7930e+05]\n",
      " [1.0599e+06 4.1260e+05 2.6840e+05 2.4110e+05]]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "start_datetime = jst_timezone.localize(datetime.datetime(2020,11,10,9,0,0))\n",
    "stock_list = [\"4755\",\"9984\",\"6701\",\"7203\",\"7267\"]\n",
    "\n",
    "episode_length = 50\n",
    "\n",
    "price_supplier = StockDBPriceSupplier(stock_db=stock_db,\n",
    "                                     ticker_names=stock_list,\n",
    "                                     episode_length=episode_length,\n",
    "                                     freq_str=\"5T\",\n",
    "                                     interpolate=False\n",
    "                                    )\n",
    "#data_unit, _ = price_supplier.reset(start_datetime, window=[-3,-2,-1,0,1,2,3])\n",
    "data_unit, _ = price_supplier.reset(start_datetime, window=[0,1,2,3])\n",
    "print(data_unit.close_array.shape)\n",
    "print(data_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.369686Z",
     "start_time": "2021-05-15T06:12:14.659254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 2.72e-05 s\n",
      "File: <ipython-input-36-31d912019a98>\n",
      "Function: __init__ at line 5\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     5                                               def __init__(self, stock_db, ticker_names, episode_length, freq_str, interpolate=True):\n",
      "     6                                                   \"\"\"\n",
      "     7                                                   stock_db: get_stock_price.StockDatabase\n",
      "     8                                                       利用するStockDatabaseクラス\n",
      "     9                                                   ticker_names: list of str\n",
      "    10                                                       利用する銘柄名のリスト\n",
      "    11                                                   episode_length: int\n",
      "    12                                                       エピソードの長さ\n",
      "    13                                                   freq_str: str\n",
      "    14                                                       利用する周期を表す文字列\n",
      "    15                                                   interpolate: bool\n",
      "    16                                                       補間するかどうか\n",
      "    17                                                   \"\"\"\n",
      "    18         1        105.0    105.0     38.6          self.stock_db = stock_db\n",
      "    19         1         50.0     50.0     18.4          self.ticker_names = ticker_names\n",
      "    20         1         38.0     38.0     14.0          self.episode_length = episode_length\n",
      "    21         1         39.0     39.0     14.3          self.freq_str = freq_str        \n",
      "    22         1         40.0     40.0     14.7          self.interpolate = interpolate\n",
      "\n",
      "Total time: 1.45259 s\n",
      "File: <ipython-input-36-31d912019a98>\n",
      "Function: reset at line 24\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    24                                               def reset(self, start_datetime, window=np.array([0])):\n",
      "    25                                                   \"\"\"\n",
      "    26                                                   Parameters\n",
      "    27                                                   ----------\n",
      "    28                                                   start_datetime: datetime.datetime \n",
      "    29                                                       データ供給の開始時刻\n",
      "    30                                                   window: ndarray\n",
      "    31                                                       データ供給のウィンドウ\n",
      "    32                                                   \n",
      "    33                                                   Returns\n",
      "    34                                                   -------\n",
      "    35                                                   DatasupplyUnit\n",
      "    36                                                       提供する価格データ\n",
      "    37                                                   bool\n",
      "    38                                                       エピソードが終了したかどうか\n",
      "    39                                                   \"\"\"\n",
      "    40                                                   # 終了時刻を求める\n",
      "    41                                                   # 全datetimeデータを保持\n",
      "    42         1        133.0    133.0      0.0          assert 0 in window\n",
      "    43         1        155.0    155.0      0.0          if not isinstance(window, np.ndarray):\n",
      "    44         1        414.0    414.0      0.0              self.window = np.array(window)\n",
      "    45                                                   else:\n",
      "    46                                                       self.window = window\n",
      "    47                                                       \n",
      "    48         1        141.0    141.0      0.0          if isinstance(self.ticker_names, np.ndarray):\n",
      "    49                                                       self.ticker_names = self.ticker_names.tolist()\n",
      "    50                                                   \n",
      "    51         1        206.0    206.0      0.0          if len(self.ticker_names)!=len(set(self.ticker_names)):\n",
      "    52                                                       raise Exception(\"Ticker_names is duplicate\")\n",
      "    53                                                   \n",
      "    54         1        418.0    418.0      0.0          min_window = min(self.window)\n",
      "    55         1        269.0    269.0      0.0          max_window = max(self.window)\n",
      "    56                                                   \n",
      "    57         1        167.0    167.0      0.0          if min_window <= 0:\n",
      "    58         1      38389.0  38389.0      0.3              episode_start_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(min_window))\n",
      "    59                                                   else:\n",
      "    60                                                       episode_start_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, min_window)\n",
      "    61                                                       \n",
      "    62         1        272.0    272.0      0.0          if self.episode_length+max_window <= 0:  # 基本的にあり得ない\n",
      "    63                                                       episode_end_datetime = get_previous_workday_intraday_datetime(start_datetime, self.freq_str, abs(self.episode_length+max_window))\n",
      "    64                                                   else:\n",
      "    65         1      21970.0  21970.0      0.2              episode_end_datetime = get_next_workday_intraday_datetime(start_datetime, self.freq_str, self.episode_length+max_window)\n",
      "    66                                                   \n",
      "    67         1        208.0    208.0      0.0          episode_df = self.stock_db.search_span(stock_names=self.ticker_names,\n",
      "    68         1        131.0    131.0      0.0                                                 start_datetime=episode_start_datetime,\n",
      "    69         1        121.0    121.0      0.0                                                 end_datetime=episode_end_datetime,\n",
      "    70         1        130.0    130.0      0.0                                                 freq_str=self.freq_str,\n",
      "    71         1        116.0    116.0      0.0                                                 is_end_include=True,  # 最後の値も含める\n",
      "    72         1   13286389.0 13286389.0     91.5                                                 to_tokyo=True,  #必ずTrueに\n",
      "    73                                                                                         )\n",
      "    74                                                   \n",
      "    75         1     204621.0 204621.0      1.4          self.episode_df = py_workdays.extract_workdays_intraday_jp(episode_df)\n",
      "    76                                                   \n",
      "    77                                                   # 各OHLCVに対応するboolを求めておく\n",
      "    78         1       2552.0   2552.0      0.0          column_names_array = self.episode_df.columns.values.astype(str)\n",
      "    79         1       3880.0   3880.0      0.0          self.open_bool_array = np.char.startswith(column_names_array, \"Open\")\n",
      "    80         1       2035.0   2035.0      0.0          self.high_bool_array = np.char.startswith(column_names_array, \"High\")\n",
      "    81         1       1914.0   1914.0      0.0          self.low_bool_array = np.char.startswith(column_names_array, \"Low\")\n",
      "    82         1       2055.0   2055.0      0.0          self.close_bool_array = np.char.startswith(column_names_array, \"Close\")\n",
      "    83         1       1946.0   1946.0      0.0          self.volume_bool_array = np.char.startswith(column_names_array, \"Volume\")\n",
      "    84                                                   \n",
      "    85                                                   \n",
      "    86         1        134.0    134.0      0.0          all_datetime_index = pd.date_range(start=episode_start_datetime,\n",
      "    87         1        107.0    107.0      0.0                                             end=episode_end_datetime,\n",
      "    88         1        122.0    122.0      0.0                                             freq=self.freq_str,\n",
      "    89         1      23998.0  23998.0      0.2                                             closed=\"left\"\n",
      "    90                                                                                     )\n",
      "    91         1     133591.0 133591.0      0.9          self.all_datetime_index = py_workdays.extract_workdays_intraday_jp_index(all_datetime_index)\n",
      "    92                                                   \n",
      "    93                                                   # episode_dfの補間\n",
      "    94         1        309.0    309.0      0.0          if self.interpolate:\n",
      "    95         1      10048.0  10048.0      0.1              add_datetime_bool = ~self.all_datetime_index.isin(self.episode_df.index)\n",
      "    96                                                       \n",
      "    97                                                       # 補間を行う数が20%を越えた場合\n",
      "    98         1       1534.0   1534.0      0.0              if (add_datetime_bool.sum()/len(self.all_datetime_index)) > 0.1:\n",
      "    99                                                           err_str = \"Interpolate exceeds 10 % about tickers={}, datetimes[{},{}]\".format(self.ticker_names,\n",
      "   100                                                                                                                                          episode_start_datetime,\n",
      "   101                                                                                                                                          episode_end_datetime)\n",
      "   102                                                           raise CannotGetAllDataError(err_str)\n",
      "   103                                                       \n",
      "   104         1      13895.0  13895.0      0.1              add_datetime_index = self.all_datetime_index[add_datetime_bool]\n",
      "   105                                                       # Noneのdfを作成\n",
      "   106         1     435321.0 435321.0      3.0              nan_df = pd.DataFrame(index=add_datetime_index, columns=self.episode_df.columns)\n",
      "   107                                           \n",
      "   108                                                       # Noneのdfを追加\n",
      "   109         1     132030.0 132030.0      0.9              self.episode_df = self.episode_df.append(nan_df)\n",
      "   110         1       3375.0   3375.0      0.0              self.episode_df.sort_index(inplace=True)\n",
      "   111                                                       \n",
      "   112                                                       # np.nanの補間\n",
      "   113         1     184126.0 184126.0      1.3              self.episode_df.interpolate(limit_direction=\"both\",inplace=True)\n",
      "   114                                                   else:\n",
      "   115                                                       share_index_bool = self.all_datetime_index.isin(self.episode_df.index)\n",
      "   116                                                       self.all_datetime_index = self.all_datetime_index[share_index_bool]\n",
      "   117                                                   \n",
      "   118                                                   # dfをndarrayに変更\n",
      "   119         1       2824.0   2824.0      0.0          self.episode_df_values = self.episode_df.values\n",
      "   120         1        462.0    462.0      0.0          del self.episode_df\n",
      "   121                                                   \n",
      "   122         1       5760.0   5760.0      0.0          self.all_datetime_index_values = self.all_datetime_index.to_pydatetime()\n",
      "   123         1        199.0    199.0      0.0          del self.all_datetime_index\n",
      "   124                                                   \n",
      "   125                                                   # データが正しく取得できたかどうか\n",
      "   126         1       1318.0   1318.0      0.0          if np.isnan(self.episode_df_values).sum() > 0:\n",
      "   127                                                       err_str = \"PriceSupplier cannot get data about tickers={}, datetimes[{},{}]\".format(self.ticker_names,\n",
      "   128                                                                                                                                      episode_start_datetime,\n",
      "   129                                                                                                                                      episode_end_datetime)\n",
      "   130                                                       raise CannotGetAllDataError(err_str)\n",
      "   131                                                   \n",
      "   132                                                   \n",
      "   133                                                   # データの取得\n",
      "   134         1        178.0    178.0      0.0          self.now_index = abs(min_window)\n",
      "   135         1        201.0    201.0      0.0          now_datetime = self.all_datetime_index_values[self.now_index]\n",
      "   136                                                   \n",
      "   137         1        449.0    449.0      0.0          add_window = self.now_index + self.window\n",
      "   138         1        536.0    536.0      0.0          window_data_value = self.episode_df_values[add_window,:]\n",
      "   139                                                   \n",
      "   140         1        494.0    494.0      0.0          open_array = window_data_value[:,self.open_bool_array].T\n",
      "   141         1        375.0    375.0      0.0          high_array = window_data_value[:,self.high_bool_array].T\n",
      "   142         1        473.0    473.0      0.0          low_array = window_data_value[:,self.low_bool_array].T\n",
      "   143         1        352.0    352.0      0.0          close_array = window_data_value[:,self.close_bool_array].T\n",
      "   144         1        373.0    373.0      0.0          volume_array = window_data_value[:,self.volume_bool_array].T\n",
      "   145                                                   \n",
      "   146         1        957.0    957.0      0.0          open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
      "   147         1        571.0    571.0      0.0          high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
      "   148         1        488.0    488.0      0.0          low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
      "   149         1        468.0    468.0      0.0          close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
      "   150         1        461.0    461.0      0.0          volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
      "   151                                                   \n",
      "   152                                                   \n",
      "   153         1        116.0    116.0      0.0          out_ticker_names = [\"yen\"]\n",
      "   154         1        170.0    170.0      0.0          out_ticker_names.extend(self.ticker_names)\n",
      "   155                                                   \n",
      "   156         1        125.0    125.0      0.0          out_unit = DataSupplyUnit(names=out_ticker_names,\n",
      "   157         1        104.0    104.0      0.0                                    key_currency_index=0,\n",
      "   158         1        128.0    128.0      0.0                                    datetime=now_datetime,\n",
      "   159         1        118.0    118.0      0.0                                    window=self.window,\n",
      "   160         1        128.0    128.0      0.0                                    open_array=open_array,\n",
      "   161         1        109.0    109.0      0.0                                    close_array=close_array,\n",
      "   162         1        133.0    133.0      0.0                                    high_array=high_array,\n",
      "   163         1        105.0    105.0      0.0                                    low_array=low_array,\n",
      "   164         1        322.0    322.0      0.0                                    volume_array=volume_array\n",
      "   165                                                                            )\n",
      "   166         1        114.0    114.0      0.0          done = False\n",
      "   167         1        104.0    104.0      0.0          return out_unit, done\n",
      "\n",
      "Total time: 0.0320096 s\n",
      "File: <ipython-input-36-31d912019a98>\n",
      "Function: step at line 169\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   169                                               def step(self):\n",
      "   170                                                   \"\"\"\n",
      "   171                                                   Returns\n",
      "   172                                                   -------\n",
      "   173                                                   DatasupplyUnit\n",
      "   174                                                       提供する価格データ\n",
      "   175                                                   bool\n",
      "   176                                                       エピソードが終了したかどうか\n",
      "   177                                                   \"\"\"\n",
      "   178                                                   # indexの更新\n",
      "   179        30       3631.0    121.0      1.1          self.now_index += 1\n",
      "   180        30       3481.0    116.0      1.1          now_datetime = self.all_datetime_index_values[self.now_index]\n",
      "   181                                                   \n",
      "   182        30      10066.0    335.5      3.1          add_window = self.now_index + self.window\n",
      "   183        30      11188.0    372.9      3.5          window_data_value = self.episode_df_values[add_window,:]\n",
      "   184                                                   \n",
      "   185        30       9150.0    305.0      2.9          open_array = window_data_value[:,self.open_bool_array].T\n",
      "   186        30       8270.0    275.7      2.6          high_array = window_data_value[:,self.high_bool_array].T\n",
      "   187        30       7873.0    262.4      2.5          low_array = window_data_value[:,self.low_bool_array].T\n",
      "   188        30       7922.0    264.1      2.5          close_array = window_data_value[:,self.close_bool_array].T\n",
      "   189        30       7764.0    258.8      2.4          volume_array = window_data_value[:,self.volume_bool_array].T\n",
      "   190                                                    \n",
      "   191        30      19956.0    665.2      6.2          open_array = np.concatenate([np.ones((1, open_array.shape[1])), open_array], axis=0)\n",
      "   192        30     160864.0   5362.1     50.3          high_array = np.concatenate([np.ones((1, high_array.shape[1])), high_array], axis=0)\n",
      "   193        30      12451.0    415.0      3.9          low_array = np.concatenate([np.ones((1, low_array.shape[1])), low_array], axis=0)\n",
      "   194        30      11453.0    381.8      3.6          close_array = np.concatenate([np.ones((1, close_array.shape[1])), close_array], axis=0)\n",
      "   195        30      11923.0    397.4      3.7          volume_array = np.concatenate([np.ones((1, volume_array.shape[1])), volume_array], axis=0)\n",
      "   196                                                   \n",
      "   197        30       1710.0     57.0      0.5          out_ticker_names = [\"yen\"]\n",
      "   198        30       2692.0     89.7      0.8          out_ticker_names.extend(self.ticker_names)\n",
      "   199                                                   \n",
      "   200        30       3468.0    115.6      1.1          out_unit = DataSupplyUnit(names=out_ticker_names,\n",
      "   201        30       2691.0     89.7      0.8                                    key_currency_index=0,\n",
      "   202        30       1516.0     50.5      0.5                                    datetime=now_datetime,\n",
      "   203        30       1723.0     57.4      0.5                                    window=self.window,\n",
      "   204        30       1432.0     47.7      0.4                                    open_array=open_array,\n",
      "   205        30       1536.0     51.2      0.5                                    close_array=close_array,\n",
      "   206        30       1410.0     47.0      0.4                                    high_array=high_array,\n",
      "   207        30       1448.0     48.3      0.5                                    low_array=low_array,\n",
      "   208        30       6288.0    209.6      2.0                                    volume_array=volume_array\n",
      "   209                                                                            )\n",
      "   210        30       6614.0    220.5      2.1          done = self.now_index >= self.episode_length\n",
      "   211                                                   \n",
      "   212        30       1576.0     52.5      0.5          return out_unit, done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def temp_func():\n",
    "    price_supplier = StockDBPriceSupplier(stock_db=stock_db,\n",
    "                                         ticker_names=stock_list,\n",
    "                                         episode_length=episode_length,\n",
    "                                         freq_str=\"5T\",\n",
    "                                         interpolate=True\n",
    "                                        )\n",
    "    data_unit, _ = price_supplier.reset(start_datetime, window=[-3,-2,-1,0,1,2,3])\n",
    "    for i in range(30):\n",
    "        data_unit, _ = price_supplier.step()\n",
    "    \n",
    "from line_profiler import LineProfiler\n",
    "prf = LineProfiler()                                                                                         \n",
    "prf.add_module(StockDBPriceSupplier)                                                                                          \n",
    "#prf.add_function()                                                                                      \n",
    "prf.runcall(temp_func)                         \n",
    "prf.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ポートフォリオの制限 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習時にはポートフォリオベクトルに制限はもうけない．バックテストや実際の運用時に単元数・基軸通貨換算資産によって制限を設ける．これは強化学習を資産の保有率を求める問題にするためである．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.416561Z",
     "start_time": "2021-05-15T06:12:16.395616Z"
    }
   },
   "outputs": [],
   "source": [
    "class PortfilioRestrictor(metaclass=ABCMeta):\n",
    "    \"\"\"\n",
    "    ポートフォリオの制限を行う抽象基底クラス\n",
    "    restrictメソッドをオーバーライドする必要がある\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def restrict(self, portfolio_state, supplied_data_unit, portfolio_vector):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.493354Z",
     "start_time": "2021-05-15T06:12:16.431520Z"
    }
   },
   "outputs": [],
   "source": [
    "class PortfolioRestrictorSingleKey(PortfilioRestrictor):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, unit_number, key_name):\n",
    "        pass\n",
    "        \n",
    "    def restrict(self, portfolio_state, supplied_data_unit, portfolio_vector):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.541227Z",
     "start_time": "2021-05-15T06:12:16.504348Z"
    }
   },
   "outputs": [],
   "source": [
    "class PortfolioRestrictorIdentity(PortfilioRestrictor):\n",
    "    \"\"\"\n",
    "    portfolioの恒等写像を行うPortfolioRestrictor\n",
    "    \"\"\"\n",
    "    def restrict(self, portfolio_state, supplied_data_unit, portfolio_vector):\n",
    "        return portfolio_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取引手数料の計算クラス "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.604058Z",
     "start_time": "2021-05-15T06:12:16.557184Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeeCalculator(metaclass=ABCMeta):\n",
    "    \"\"\"\n",
    "    手数料を計算する抽象基底クラス\n",
    "    \"\"\"\n",
    "    @abstractmethod\n",
    "    def calculate(self, pre_portfolio_state, new_portfolio_state):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.672876Z",
     "start_time": "2021-05-15T06:12:16.615037Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeeCalculatorPerNumber(FeeCalculator):\n",
    "    \"\"\"\n",
    "    取引個数に応じて手数料を計算するFeeCalculator\n",
    "    \"\"\"\n",
    "    def __init__(self, fee_per_number):\n",
    "        self.fee_per_number = fee_per_number\n",
    "    def calculate(self, pre_portfolio_state, new_portfolio_state):\n",
    "        not_key_currency_indices_list = list(range(len(pre_portfolio_state.names)))\n",
    "        not_key_currency_indices_list.remove(pre_portfolio_state.key_currency_index)\n",
    "        \n",
    "        not_key_currency_indices = np.array(not_key_currency_indices_list) \n",
    "        commition_fee = self.fee_per_number*np.abs((new_portfolio_state.numbers[not_key_currency_indices] - pre_portfolio_state.numbers[not_key_currency_indices])).sum()\n",
    "        return commition_fee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  ポートフォリオの遷移クラス  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "強化学習の環境だけでなく，バックテスト等でも利用できるように汎用的なもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:16.967086Z",
     "start_time": "2021-05-15T06:12:16.687834Z"
    }
   },
   "outputs": [],
   "source": [
    "class PortfolioTransformer:\n",
    "    \"\"\"\n",
    "    price_supplierの提供するデータに応じてPortfolioStateを遷移させるクラス\n",
    "    バックテスト・強化学習のどちらでも使えるようにする．\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 price_supplier, \n",
    "                 portfolio_restrictor=PortfolioRestrictorIdentity(), \n",
    "                 use_ohlc=\"Close\", \n",
    "                 initial_portfolio_vector=None,\n",
    "                 initial_mean_cost_price_array=None,\n",
    "                 initial_all_assets=None, \n",
    "                 fee_calculator=FeeCalculatorPerNumber(fee_per_number=1e-3)):\n",
    "        \"\"\"\n",
    "        price_supplier: PriceSupplier\n",
    "            価格データを供給するクラス\n",
    "        portfolio_restrictor: PortfolioRestrictor\n",
    "            エージェントが渡すportfolio_vectorを制限するクラス\n",
    "        use_ohlc: str, defalt:'Close'\n",
    "            利用する価格データの指定\n",
    "        initial_portfolio_vector: any, defalt:None\n",
    "            初期ポートフォリオベクトル\n",
    "        fee_calculator: FeeCalculator\n",
    "            手数料を計算するクラス\n",
    "        \"\"\"\n",
    "        self.price_supplier = price_supplier\n",
    "        self.portfolio_restrictor = portfolio_restrictor\n",
    "        self.initial_portfolio_vector = initial_portfolio_vector\n",
    "        self.initial_mean_cost_price_array = initial_mean_cost_price_array\n",
    "        self.initial_all_assets = initial_all_assets\n",
    "        self.fee_calculator = fee_calculator\n",
    "    \n",
    "        # 利用するohlcのいずれか\n",
    "        if use_ohlc not in {\"Open\",\"High\",\"Low\",\"Close\"}:\n",
    "            raise Exception(\"use_ohlc must be in {'Open','High','Low','Close'}\")\n",
    "        \n",
    "        field_name_dict = {\"Open\":\"open_array\",\n",
    "                           \"Close\":\"close_array\",\n",
    "                           \"Low\":\"low_array\",\n",
    "                           \"High\":\"high_array\"\n",
    "                          }\n",
    "            \n",
    "        self.use_ohlc_filed = field_name_dict[use_ohlc]\n",
    "        \n",
    "    def reset(self, start_datetime, window=[0]):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        start_datetime: datetime.datetime \n",
    "            データ供給の開始時刻\n",
    "        window: ndarray\n",
    "            データ供給のウィンドウ\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        PortfolioStat\n",
    "             ポートフォリオ状態\n",
    "        bool\n",
    "            エピソードが終了したかどうか\n",
    "        \"\"\"\n",
    "        initial_data_unit, done = self.price_supplier.reset(start_datetime, window)\n",
    "    \n",
    "        now_price_bool = initial_data_unit.window==0 \n",
    "        now_price_array = getattr(initial_data_unit, self.use_ohlc_filed)[:,now_price_bool].squeeze()\n",
    "    \n",
    "        # 初期パラメータ―のデフォルト値\n",
    "        if self.initial_portfolio_vector is None:\n",
    "            self.initial_portfolio_vector = np.zeros(len(initial_data_unit.names))\n",
    "            self.initial_portfolio_vector[initial_data_unit.key_currency_index] = 1.0\n",
    "            \n",
    "        else:\n",
    "            assert len(initial_data_unit.names) == len(self.initial_portfolio_vector)\n",
    "            if abs(self.initial_portfolio_vector.sum() - 1.0) > 1.e-5:  # 大体1ならOK\n",
    "                raise Exception(\"initial portfolio vector sum must be 1. This portfolio vector is {}.\\n This sum is {}\".format(self.initial_portfolio_vector,\n",
    "                                                                                                                               self.initial_portfolio_vector.sum()))\n",
    "            \n",
    "        if self.initial_mean_cost_price_array is None:\n",
    "            self.initial_mean_cost_price_array = now_price_array\n",
    "        else:\n",
    "            assert self.initial_mean_cost_price_array.shape[0] == now_price_array.shape[0]\n",
    "            \n",
    "        if self.initial_all_assets is None:\n",
    "            self.initial_all_assets = 1.e6            \n",
    "        \n",
    "        # PortfoliioStateの作成\n",
    "        self.portfolio_state = PortfolioState(names=initial_data_unit.names,\n",
    "                                              key_currency_index=initial_data_unit.key_currency_index,\n",
    "                                              window=initial_data_unit.window,\n",
    "                                              datetime=initial_data_unit.datetime,\n",
    "                                              price_array=getattr(initial_data_unit, self.use_ohlc_filed),\n",
    "                                              volume_array=initial_data_unit.volume_array,\n",
    "                                              now_price_array=now_price_array,\n",
    "                                              portfolio_vector=self.initial_portfolio_vector,\n",
    "                                              mean_cost_price_array=now_price_array,\n",
    "                                              all_assets=self.initial_all_assets\n",
    "                                             )\n",
    "        \n",
    "        \n",
    "        return self.portfolio_state.copy(), done\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        action: ndarray\n",
    "            エージェントが渡すポートフォリオベクトル\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        PortfolioStat\n",
    "             ポートフォリオ状態\n",
    "        bool\n",
    "            エピソードが終了したかどうか\n",
    "        \"\"\"\n",
    "        \n",
    "        if not isinstance(action, np.ndarray):\n",
    "            action = np.array(action)\n",
    "        assert (action<0).sum() == 0 and (action>1).sum() == 0\n",
    "        if abs(action.sum() - 1.0) > 1.e-5:  # 大体1ならOK\n",
    "            raise Exception(\"action sum must be 1. This action is {}.\\n This sum is {}\".format(action, action.sum()))\n",
    "            \n",
    "        \n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        \n",
    "        previous_portfolio_state = self.portfolio_state\n",
    "        supplied_data_unit, done = self.price_supplier.step()\n",
    "        \n",
    "        assert len(action)==len(supplied_data_unit.names)\n",
    "        \n",
    "        restricted_portfolio_vector = self.portfolio_restrictor.restrict(previous_portfolio_state, supplied_data_unit, action)\n",
    "        \n",
    "        # 全資産の変化率を求める\n",
    "        now_price_bool = supplied_data_unit.window==0\n",
    "        now_price_array = getattr(supplied_data_unit, self.use_ohlc_filed)[:,now_price_bool].squeeze()\n",
    "        \n",
    "        price_change_ratio = now_price_array / previous_portfolio_state.now_price_array\n",
    "        \n",
    "        all_assets_change_ratio = np.dot(restricted_portfolio_vector, price_change_ratio)\n",
    "        all_assets = previous_portfolio_state.all_assets * all_assets_change_ratio\n",
    "        \n",
    "        # 平均取得価格を設ける\n",
    "        new_numbers = all_assets*restricted_portfolio_vector/now_price_array\n",
    "        pre_numbers = previous_portfolio_state.numbers\n",
    "        mean_num = pre_numbers*previous_portfolio_state.now_price_array + (new_numbers - pre_numbers) * now_price_array\n",
    "        mean_den = new_numbers\n",
    "        \n",
    "        new_numbers_near_zero_bool = new_numbers < 1  # 取り合えず1以下の場合\n",
    "        mean_num[new_numbers_near_zero_bool] = 1  # 適当に1にしておく\n",
    "        mean_den[new_numbers_near_zero_bool] = 1  # 適当に1にしておく\n",
    "        \n",
    "        mean_cost_price_array = mean_num / mean_den\n",
    "        mean_cost_price_array[new_numbers_near_zero_bool] = now_price_array[new_numbers_near_zero_bool]\n",
    "        \n",
    "        self.portfolio_state = PortfolioState(names=supplied_data_unit.names,\n",
    "                                              key_currency_index=supplied_data_unit.key_currency_index,\n",
    "                                              window=supplied_data_unit.window,\n",
    "                                              datetime=supplied_data_unit.datetime,\n",
    "                                              price_array=getattr(supplied_data_unit, self.use_ohlc_filed),\n",
    "                                              volume_array=supplied_data_unit.volume_array,\n",
    "                                              now_price_array=now_price_array,\n",
    "                                              portfolio_vector=restricted_portfolio_vector,\n",
    "                                              mean_cost_price_array=mean_cost_price_array,\n",
    "                                              all_assets=all_assets\n",
    "                                             )\n",
    "                 \n",
    "        # 手数料の計算と更新\n",
    "        all_fee = self.fee_calculator.calculate(previous_portfolio_state, self.portfolio_state)\n",
    "        self.portfolio_state = self.portfolio_state._replace(all_assets=all_assets-all_fee)   \n",
    "        \n",
    "        return self.portfolio_state.copy(), done\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:18.109036Z",
     "start_time": "2021-05-15T06:12:16.978059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PortfolioState( \n",
      "names=['yen', '4755', '9984', '6701', '7203', '7267']\n",
      "key_currency_index=0\n",
      "window=[-3 -2 -1  0  1  2  3]\n",
      "datetime=2020-11-10 09:00:00+09:00\n",
      "price_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1200e+03 1.1190e+03 1.1170e+03 1.1280e+03 1.1070e+03 1.1050e+03\n",
      "  1.0620e+03]\n",
      " [7.0690e+03 7.0740e+03 7.0960e+03 7.0720e+03 7.0190e+03 7.0040e+03\n",
      "  6.9880e+03]\n",
      " [5.7600e+03 5.7600e+03 5.7600e+03 5.6800e+03 5.7200e+03 5.7100e+03\n",
      "  5.6900e+03]\n",
      " [7.1750e+03 7.1770e+03 7.1770e+03 7.3420e+03 7.3360e+03 7.3530e+03\n",
      "  7.3280e+03]\n",
      " [2.8400e+03 2.8395e+03 2.8340e+03 2.9595e+03 2.9415e+03 2.9705e+03\n",
      "  2.9310e+03]]\n",
      "volume_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [7.1600e+04 9.3300e+04 4.1190e+05 8.7840e+05 5.8380e+05 2.5710e+05\n",
      "  7.9410e+05]\n",
      " [2.3750e+05 3.0980e+05 3.7840e+05 2.5031e+06 8.4220e+05 7.3700e+05\n",
      "  4.2530e+05]\n",
      " [4.8200e+04 1.5600e+04 4.2800e+04 2.6540e+05 7.0900e+04 5.5200e+04\n",
      "  7.5200e+04]\n",
      " [1.3520e+05 1.6710e+05 1.7530e+05 1.3002e+06 4.5750e+05 3.2870e+05\n",
      "  1.7930e+05]\n",
      " [1.4200e+05 1.9780e+05 2.6770e+05 1.0599e+06 4.1260e+05 2.6840e+05\n",
      "  2.4110e+05]]\n",
      "now_price_array=[1.0000e+00 1.1280e+03 7.0720e+03 5.6800e+03 7.3420e+03 2.9595e+03]\n",
      "portfolio_vector=[1. 0. 0. 0. 0. 0.]\n",
      "mean_cost_price_array=[1.0000e+00 1.1280e+03 7.0720e+03 5.6800e+03 7.3420e+03 2.9595e+03]\n",
      "all_assets=1000000.0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer = PortfolioTransformer(price_supplier=price_supplier,\n",
    "                                   portfolio_restrictor=PortfolioRestrictorIdentity(),\n",
    "                                   use_ohlc=\"Close\",\n",
    "                                   initial_portfolio_vector=None,\n",
    "                                   initial_all_assets=1e6,\n",
    "                                   fee_calculator=FeeCalculatorPerNumber(0.01)\n",
    "                                  )\n",
    "\n",
    "portfolio_state, _ = transformer.reset(start_datetime, window=[-3,-2,-1,0,1,2,3])\n",
    "print(portfolio_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:18.187827Z",
     "start_time": "2021-05-15T06:12:18.120004Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PortfolioState( \n",
      "names=['yen', '4755', '9984', '6701', '7203', '7267']\n",
      "key_currency_index=0\n",
      "window=[-3 -2 -1  0  1  2  3]\n",
      "datetime=2020-11-10 09:05:00+09:00\n",
      "price_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [1.1190e+03 1.1170e+03 1.1280e+03 1.1070e+03 1.1050e+03 1.0620e+03\n",
      "  1.0760e+03]\n",
      " [7.0740e+03 7.0960e+03 7.0720e+03 7.0190e+03 7.0040e+03 6.9880e+03\n",
      "  6.9570e+03]\n",
      " [5.7600e+03 5.7600e+03 5.6800e+03 5.7200e+03 5.7100e+03 5.6900e+03\n",
      "  5.6700e+03]\n",
      " [7.1770e+03 7.1770e+03 7.3420e+03 7.3360e+03 7.3530e+03 7.3280e+03\n",
      "  7.3170e+03]\n",
      " [2.8395e+03 2.8340e+03 2.9595e+03 2.9415e+03 2.9705e+03 2.9310e+03\n",
      "  2.9170e+03]]\n",
      "volume_array=[[1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00 1.0000e+00\n",
      "  1.0000e+00]\n",
      " [9.3300e+04 4.1190e+05 8.7840e+05 5.8380e+05 2.5710e+05 7.9410e+05\n",
      "  4.6700e+05]\n",
      " [3.0980e+05 3.7840e+05 2.5031e+06 8.4220e+05 7.3700e+05 4.2530e+05\n",
      "  4.1350e+05]\n",
      " [1.5600e+04 4.2800e+04 2.6540e+05 7.0900e+04 5.5200e+04 7.5200e+04\n",
      "  7.9000e+04]\n",
      " [1.6710e+05 1.7530e+05 1.3002e+06 4.5750e+05 3.2870e+05 1.7930e+05\n",
      "  1.9250e+05]\n",
      " [1.9780e+05 2.6770e+05 1.0599e+06 4.1260e+05 2.6840e+05 2.4110e+05\n",
      "  1.7630e+05]]\n",
      "now_price_array=[1.0000e+00 1.1070e+03 7.0190e+03 5.7200e+03 7.3360e+03 2.9415e+03]\n",
      "portfolio_vector=[0 1 0 0 0 0]\n",
      "mean_cost_price_array=[1.0000e+00 1.1070e+03 7.0190e+03 5.7200e+03 7.3360e+03 2.9415e+03]\n",
      "all_assets=981374.1134751774\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "new_portfolio_vector = [0,1,0,0,0,0]\n",
    "portfolio_state, _ = transformer.step(new_portfolio_vector)\n",
    "print(portfolio_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:19.785554Z",
     "start_time": "2021-05-15T06:12:18.205778Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 7.28e-05 s\n",
      "File: <ipython-input-44-856aca8c5e22>\n",
      "Function: __init__ at line 6\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     6                                               def __init__(self, \n",
      "     7                                                            price_supplier, \n",
      "     8                                                            portfolio_restrictor=PortfolioRestrictorIdentity(), \n",
      "     9                                                            use_ohlc=\"Close\", \n",
      "    10                                                            initial_portfolio_vector=None,\n",
      "    11                                                            initial_mean_cost_price_array=None,\n",
      "    12                                                            initial_all_assets=None, \n",
      "    13                                                            fee_calculator=FeeCalculatorPerNumber(fee_per_number=1e-3)):\n",
      "    14                                                   \"\"\"\n",
      "    15                                                   price_supplier: PriceSupplier\n",
      "    16                                                       価格データを供給するクラス\n",
      "    17                                                   portfolio_restrictor: PortfolioRestrictor\n",
      "    18                                                       エージェントが渡すportfolio_vectorを制限するクラス\n",
      "    19                                                   use_ohlc: str, defalt:'Close'\n",
      "    20                                                       利用する価格データの指定\n",
      "    21                                                   initial_portfolio_vector: any, defalt:None\n",
      "    22                                                       初期ポートフォリオベクトル\n",
      "    23                                                   fee_calculator: FeeCalculator\n",
      "    24                                                       手数料を計算するクラス\n",
      "    25                                                   \"\"\"\n",
      "    26         1         99.0     99.0     13.6          self.price_supplier = price_supplier\n",
      "    27         1         65.0     65.0      8.9          self.portfolio_restrictor = portfolio_restrictor\n",
      "    28         1         58.0     58.0      8.0          self.initial_portfolio_vector = initial_portfolio_vector\n",
      "    29         1         55.0     55.0      7.6          self.initial_mean_cost_price_array = initial_mean_cost_price_array\n",
      "    30         1         55.0     55.0      7.6          self.initial_all_assets = initial_all_assets\n",
      "    31         1         49.0     49.0      6.7          self.fee_calculator = fee_calculator\n",
      "    32                                               \n",
      "    33                                                   # 利用するohlcのいずれか\n",
      "    34         1         60.0     60.0      8.2          if use_ohlc not in {\"Open\",\"High\",\"Low\",\"Close\"}:\n",
      "    35                                                       raise Exception(\"use_ohlc must be in {'Open','High','Low','Close'}\")\n",
      "    36                                                   \n",
      "    37         1         46.0     46.0      6.3          field_name_dict = {\"Open\":\"open_array\",\n",
      "    38         1         49.0     49.0      6.7                             \"Close\":\"close_array\",\n",
      "    39         1         49.0     49.0      6.7                             \"Low\":\"low_array\",\n",
      "    40         1         72.0     72.0      9.9                             \"High\":\"high_array\"\n",
      "    41                                                                     }\n",
      "    42                                                       \n",
      "    43         1         71.0     71.0      9.8          self.use_ohlc_filed = field_name_dict[use_ohlc]\n",
      "\n",
      "Total time: 1.30531 s\n",
      "File: <ipython-input-44-856aca8c5e22>\n",
      "Function: reset at line 45\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    45                                               def reset(self, start_datetime, window=[0]):\n",
      "    46                                                   \"\"\"\n",
      "    47                                                   Parameters\n",
      "    48                                                   ----------\n",
      "    49                                                   start_datetime: datetime.datetime \n",
      "    50                                                       データ供給の開始時刻\n",
      "    51                                                   window: ndarray\n",
      "    52                                                       データ供給のウィンドウ\n",
      "    53                                                       \n",
      "    54                                                   Returns\n",
      "    55                                                   -------\n",
      "    56                                                   PortfolioStat\n",
      "    57                                                        ポートフォリオ状態\n",
      "    58                                                   bool\n",
      "    59                                                       エピソードが終了したかどうか\n",
      "    60                                                   \"\"\"\n",
      "    61         1   13048533.0 13048533.0    100.0          initial_data_unit, done = self.price_supplier.reset(start_datetime, window)\n",
      "    62                                               \n",
      "    63         1        319.0    319.0      0.0          now_price_bool = initial_data_unit.window==0 \n",
      "    64         1        426.0    426.0      0.0          now_price_array = getattr(initial_data_unit, self.use_ohlc_filed)[:,now_price_bool].squeeze()\n",
      "    65                                               \n",
      "    66                                                   # 初期パラメータ―のデフォルト値\n",
      "    67         1        115.0    115.0      0.0          if self.initial_portfolio_vector is None:\n",
      "    68         1        264.0    264.0      0.0              self.initial_portfolio_vector = np.zeros(len(initial_data_unit.names))\n",
      "    69         1        116.0    116.0      0.0              self.initial_portfolio_vector[initial_data_unit.key_currency_index] = 1.0\n",
      "    70                                                       \n",
      "    71                                                   else:\n",
      "    72                                                       assert len(initial_data_unit.names) == len(self.initial_portfolio_vector)\n",
      "    73                                                       if abs(self.initial_portfolio_vector.sum() - 1.0) > 1.e-5:  # 大体1ならOK\n",
      "    74                                                           raise Exception(\"initial portfolio vector sum must be 1. This portfolio vector is {}.\\n This sum is {}\".format(self.initial_portfolio_vector,\n",
      "    75                                                                                                                                                                          self.initial_portfolio_vector.sum()))\n",
      "    76                                                       \n",
      "    77         1         76.0     76.0      0.0          if self.initial_mean_cost_price_array is None:\n",
      "    78         1         75.0     75.0      0.0              self.initial_mean_cost_price_array = now_price_array\n",
      "    79                                                   else:\n",
      "    80                                                       assert self.initial_mean_cost_price_array.shape[0] == now_price_array.shape[0]\n",
      "    81                                                       \n",
      "    82         1         81.0     81.0      0.0          if self.initial_all_assets is None:\n",
      "    83                                                       self.initial_all_assets = 1.e6            \n",
      "    84                                                   \n",
      "    85                                                   # PortfoliioStateの作成\n",
      "    86         1        299.0    299.0      0.0          self.portfolio_state = PortfolioState(names=initial_data_unit.names,\n",
      "    87         1         82.0     82.0      0.0                                                key_currency_index=initial_data_unit.key_currency_index,\n",
      "    88         1         81.0     81.0      0.0                                                window=initial_data_unit.window,\n",
      "    89         1         75.0     75.0      0.0                                                datetime=initial_data_unit.datetime,\n",
      "    90         1        126.0    126.0      0.0                                                price_array=getattr(initial_data_unit, self.use_ohlc_filed),\n",
      "    91         1         76.0     76.0      0.0                                                volume_array=initial_data_unit.volume_array,\n",
      "    92         1         69.0     69.0      0.0                                                now_price_array=now_price_array,\n",
      "    93         1         75.0     75.0      0.0                                                portfolio_vector=self.initial_portfolio_vector,\n",
      "    94         1         69.0     69.0      0.0                                                mean_cost_price_array=now_price_array,\n",
      "    95         1        373.0    373.0      0.0                                                all_assets=self.initial_all_assets\n",
      "    96                                                                                        )\n",
      "    97                                                   \n",
      "    98                                                   \n",
      "    99         1       1793.0   1793.0      0.0          return self.portfolio_state.copy(), done\n",
      "\n",
      "Total time: 0.0591603 s\n",
      "File: <ipython-input-44-856aca8c5e22>\n",
      "Function: step at line 101\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   101                                               def step(self, action):\n",
      "   102                                                   \"\"\"\n",
      "   103                                                   Parameters\n",
      "   104                                                   ----------\n",
      "   105                                                   action: ndarray\n",
      "   106                                                       エージェントが渡すポートフォリオベクトル\n",
      "   107                                                       \n",
      "   108                                                   Returns\n",
      "   109                                                   -------\n",
      "   110                                                   PortfolioStat\n",
      "   111                                                        ポートフォリオ状態\n",
      "   112                                                   bool\n",
      "   113                                                       エピソードが終了したかどうか\n",
      "   114                                                   \"\"\"\n",
      "   115                                                   \n",
      "   116        30       3469.0    115.6      0.6          if not isinstance(action, np.ndarray):\n",
      "   117        30       7306.0    243.5      1.2              action = np.array(action)\n",
      "   118        30      31708.0   1056.9      5.4          assert (action<0).sum() == 0 and (action>1).sum() == 0\n",
      "   119        30      37098.0   1236.6      6.3          if abs(action.sum() - 1.0) > 1.e-5:  # 大体1ならOK\n",
      "   120                                                       raise Exception(\"action sum must be 1. This action is {}.\\n This sum is {}\".format(action, action.sum()))\n",
      "   121                                                       \n",
      "   122                                                   \n",
      "   123                                                   #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
      "   124                                                   \n",
      "   125        30       3041.0    101.4      0.5          previous_portfolio_state = self.portfolio_state\n",
      "   126        30     183590.0   6119.7     31.0          supplied_data_unit, done = self.price_supplier.step()\n",
      "   127                                                   \n",
      "   128        30       4483.0    149.4      0.8          assert len(action)==len(supplied_data_unit.names)\n",
      "   129                                                   \n",
      "   130        30       4350.0    145.0      0.7          restricted_portfolio_vector = self.portfolio_restrictor.restrict(previous_portfolio_state, supplied_data_unit, action)\n",
      "   131                                                   \n",
      "   132                                                   # 全資産の変化率を求める\n",
      "   133        30       8219.0    274.0      1.4          now_price_bool = supplied_data_unit.window==0\n",
      "   134        30      14065.0    468.8      2.4          now_price_array = getattr(supplied_data_unit, self.use_ohlc_filed)[:,now_price_bool].squeeze()\n",
      "   135                                                   \n",
      "   136        30       6423.0    214.1      1.1          price_change_ratio = now_price_array / previous_portfolio_state.now_price_array\n",
      "   137                                                   \n",
      "   138        30       9158.0    305.3      1.5          all_assets_change_ratio = np.dot(restricted_portfolio_vector, price_change_ratio)\n",
      "   139        30       3463.0    115.4      0.6          all_assets = previous_portfolio_state.all_assets * all_assets_change_ratio\n",
      "   140                                                   \n",
      "   141                                                   # 平均取得価格を設ける\n",
      "   142        30      13503.0    450.1      2.3          new_numbers = all_assets*restricted_portfolio_vector/now_price_array\n",
      "   143        30      13015.0    433.8      2.2          pre_numbers = previous_portfolio_state.numbers\n",
      "   144        30       9592.0    319.7      1.6          mean_num = pre_numbers*previous_portfolio_state.now_price_array + (new_numbers - pre_numbers) * now_price_array\n",
      "   145        30       2625.0     87.5      0.4          mean_den = new_numbers\n",
      "   146                                                   \n",
      "   147        30       7416.0    247.2      1.3          new_numbers_near_zero_bool = new_numbers < 1  # 取り合えず1以下の場合\n",
      "   148        30       6411.0    213.7      1.1          mean_num[new_numbers_near_zero_bool] = 1  # 適当に1にしておく\n",
      "   149        30       4598.0    153.3      0.8          mean_den[new_numbers_near_zero_bool] = 1  # 適当に1にしておく\n",
      "   150                                                   \n",
      "   151        30       4631.0    154.4      0.8          mean_cost_price_array = mean_num / mean_den\n",
      "   152        30       6027.0    200.9      1.0          mean_cost_price_array[new_numbers_near_zero_bool] = now_price_array[new_numbers_near_zero_bool]\n",
      "   153                                                   \n",
      "   154        30       3182.0    106.1      0.5          self.portfolio_state = PortfolioState(names=supplied_data_unit.names,\n",
      "   155        30       2927.0     97.6      0.5                                                key_currency_index=supplied_data_unit.key_currency_index,\n",
      "   156        30       2881.0     96.0      0.5                                                window=supplied_data_unit.window,\n",
      "   157        30       2599.0     86.6      0.4                                                datetime=supplied_data_unit.datetime,\n",
      "   158        30       3184.0    106.1      0.5                                                price_array=getattr(supplied_data_unit, self.use_ohlc_filed),\n",
      "   159        30       2654.0     88.5      0.4                                                volume_array=supplied_data_unit.volume_array,\n",
      "   160        30       2521.0     84.0      0.4                                                now_price_array=now_price_array,\n",
      "   161        30      44966.0   1498.9      7.6                                                portfolio_vector=restricted_portfolio_vector,\n",
      "   162        30       2495.0     83.2      0.4                                                mean_cost_price_array=mean_cost_price_array,\n",
      "   163        30       8546.0    284.9      1.4                                                all_assets=all_assets\n",
      "   164                                                                                        )\n",
      "   165                                                            \n",
      "   166                                                   # 手数料の計算と更新\n",
      "   167        30      67592.0   2253.1     11.4          all_fee = self.fee_calculator.calculate(previous_portfolio_state, self.portfolio_state)\n",
      "   168        30      16023.0    534.1      2.7          self.portfolio_state = self.portfolio_state._replace(all_assets=all_assets-all_fee)   \n",
      "   169                                                   \n",
      "   170        30      47842.0   1594.7      8.1          return self.portfolio_state.copy(), done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def temp_func():\n",
    "    price_supplier = StockDBPriceSupplier(stock_db=stock_db,\n",
    "                                     ticker_names=stock_list,\n",
    "                                     episode_length=episode_length,\n",
    "                                     freq_str=\"5T\",\n",
    "                                     interpolate=True\n",
    "                                    )\n",
    "    transformer = PortfolioTransformer(price_supplier=price_supplier,\n",
    "                                       portfolio_restrictor=PortfolioRestrictorIdentity(),\n",
    "                                       use_ohlc=\"Close\",\n",
    "                                       initial_portfolio_vector=None,\n",
    "                                       initial_all_assets=1e6,\n",
    "                                       fee_calculator=FeeCalculatorPerNumber(0.01)\n",
    "                                      )\n",
    "    portfolio_state, _ = transformer.reset(start_datetime, window=[-3,-2,-1,0,1,2,3])\n",
    "    for _ in range(30):\n",
    "        new_portfolio_vector = [0,1,0,0,0,0]\n",
    "        portfolio_state, _ = transformer.step(new_portfolio_vector)\n",
    "    \n",
    "from line_profiler import LineProfiler\n",
    "prf = LineProfiler()                                                                                         \n",
    "prf.add_module(PortfolioTransformer)                                                                                          \n",
    "#prf.add_function()                                                                                      \n",
    "prf.runcall(temp_func)                                                                                          \n",
    "prf.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "高速化できる部分は無い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ポートフォリオの遷移を可視化 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.273901Z",
     "start_time": "2021-05-15T06:12:19.802509Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (7,) and (6,) not aligned: 7 (dim 0) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5ed964e05bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mportfolio_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mportfolio_state_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mportfolio_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"names\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"now_price_array\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean_cost_price_array\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"portfolio_vector\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"all_assets\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"datetime\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-856aca8c5e22>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mprice_change_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnow_price_array\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mprevious_portfolio_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow_price_array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mall_assets_change_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrestricted_portfolio_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprice_change_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[0mall_assets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_portfolio_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_assets\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mall_assets_change_ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (7,) and (6,) not aligned: 7 (dim 0) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "start_datetime = jst_timezone.localize(datetime.datetime(2020,11,10,9,0,0))\n",
    "stock_list = [\"4755\",\"9984\",\"6701\",\"7203\",\"7267\", \"6502\"]\n",
    "episode_length = 100\n",
    "\n",
    "price_supplier = StockDBPriceSupplier(stock_db=stock_db,\n",
    "                                     ticker_names=stock_list,\n",
    "                                     episode_length=episode_length,\n",
    "                                     freq_str=\"5T\",\n",
    "                                     interpolate=False\n",
    "                                    )\n",
    "\n",
    "transformer = PortfolioTransformer(price_supplier=price_supplier,\n",
    "                                   portfolio_restrictor=PortfolioRestrictorIdentity(),\n",
    "                                   use_ohlc=\"Close\",\n",
    "                                   initial_portfolio_vector=None,\n",
    "                                   initial_all_assets=1e6,\n",
    "                                   fee_calculator=FeeCalculatorPerNumber(0)\n",
    "                                  )\n",
    "\n",
    "\n",
    "portfolio_state_list = []\n",
    "initial_state, _ = transformer.reset(start_datetime, window=[-1,0,1])\n",
    "portfolio_state_list.append(initial_state.partial(\"names\", \"now_price_array\", \"mean_cost_price_array\", \"portfolio_vector\", \"all_assets\", \"datetime\"))\n",
    "\n",
    "while True:\n",
    "    action = softmax(np.abs(np.random.randn(1+len(stock_list))))\n",
    "    portfolio_state, done = transformer.step(action)\n",
    "    portfolio_state_list.append(portfolio_state.partial(\"names\", \"now_price_array\", \"mean_cost_price_array\", \"portfolio_vector\", \"all_assets\", \"datetime\"))\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.285868Z",
     "start_time": "2021-05-15T06:10:53.326Z"
    }
   },
   "outputs": [],
   "source": [
    "portfolio_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.293850Z",
     "start_time": "2021-05-15T06:10:53.342Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_y_limit(y_array, upper_ratio=0.1, lowwer_ratio=0.1):\n",
    "    min_value = np.amin(y_array)\n",
    "    max_value = np.amax(y_array)\n",
    "    diff = max_value - min_value\n",
    "    return min_value-lowwer_ratio*diff, max_value+upper_ratio*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.299831Z",
     "start_time": "2021-05-15T06:10:53.362Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_y_limit_multi(y_arrays, upper_ratio=0.1, lowwer_ratio=0.1):\n",
    "    min_values = []\n",
    "    max_values = []\n",
    "    for y_array in y_arrays:\n",
    "        min_values.append(np.amin(y_array))\n",
    "        max_values.append(np.amax(y_array))\n",
    "        \n",
    "    min_value = min(min_values)\n",
    "    max_value = max(max_values)\n",
    "    diff = max_value - min_value\n",
    "    \n",
    "    return min_value-lowwer_ratio*diff, max_value+upper_ratio*diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.326763Z",
     "start_time": "2021-05-15T06:10:53.382Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_ticker_text(ticker_value_array, ticker_names):\n",
    "    div_text = \"\"\n",
    "    text_sum_line = 150\n",
    "    text_sum_count = 0\n",
    "\n",
    "    for i, ticker_name in enumerate(ticker_names):\n",
    "        div_text += ticker_name + \"=\"\n",
    "        text_sum_count += len(ticker_name)\n",
    "        ticke_value_str = str(ticker_value_array[i])\n",
    "        div_text += ticke_value_str\n",
    "        text_sum_count += len(ticke_value_str)\n",
    "\n",
    "        div_text += \", \"\n",
    "        text_sum_count += 2\n",
    "\n",
    "        if text_sum_count > text_sum_line:\n",
    "            div_text += \"\\n\"\n",
    "            text_sum_count = 0\n",
    "            \n",
    "    return div_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここはメインの開発場所ではない，プロトタイプ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.333743Z",
     "start_time": "2021-05-15T06:10:53.412Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_portfolio_transform_bokeh(portfolio_state_list, save_path=None, is_save=False, is_show=True, is_jupyter=True):\n",
    "    # テータの取り出し\n",
    "    ticker_names = portfolio_state_list[0].names\n",
    "    colors = d3[\"Category20\"][len(ticker_names)]\n",
    "\n",
    "    all_price_array = np.stack([one_state.now_price_array for one_state in portfolio_state_list], axis=1)\n",
    "    all_portfolio_vector = np.stack([one_state.portfolio_vector for one_state in portfolio_state_list], axis=1)\n",
    "    all_mean_cost_price_array = np.stack([one_state.mean_cost_price_array for one_state in portfolio_state_list], axis=1)\n",
    "    all_assets_array = np.array([one_state.all_assets for one_state in portfolio_state_list])\n",
    "    all_datetime_array = np.array([get_naive_datetime_from_datetime(one_state.datetime) for one_state in portfolio_state_list])\n",
    "    x = np.arange(0, len(portfolio_state_list))\n",
    "\n",
    "\n",
    "    # sorceの作成\n",
    "    portfolio_vector_source = {\"x\":x, \"datetime\":all_datetime_array}\n",
    "    price_source_x = []\n",
    "    price_source_y = []\n",
    "\n",
    "    mean_cost_price_source_x = []\n",
    "    mean_cost_price_source_y = []\n",
    "\n",
    "    for i, ticker_name in enumerate(ticker_names):\n",
    "        portfolio_vector_source[ticker_name] = all_portfolio_vector[i,:]\n",
    "\n",
    "        price_source_x.append(x)\n",
    "        price_source_y.append(all_price_array[i,:]/all_price_array[i,0])\n",
    "\n",
    "        mean_cost_price_source_x.append(x)\n",
    "        mean_cost_price_source_y.append(all_mean_cost_price_array[i,:]/all_mean_cost_price_array[i,0])\n",
    "\n",
    "    # ホバーツールの設定\n",
    "    #tool_tips = [(\"x\", \"@x\")]\n",
    "    tool_tips = [(\"datetime\", \"@datetime{%F %H:%M:%S}\")]\n",
    "    tool_tips.extend([(ticker_name, \"@\"+ticker_name+\"{0.000}\") for ticker_name in ticker_names])\n",
    "\n",
    "    hover_tool = HoverTool(\n",
    "        tooltips=tool_tips,\n",
    "        formatters={'@datetime' : 'datetime'}\n",
    "    )\n",
    "\n",
    "    # 描画\n",
    "\n",
    "    p1_text = Div(text=make_ticker_text(all_price_array[:,0], ticker_names))\n",
    "\n",
    "    p1 = bokeh.plotting.figure(plot_width=1200,plot_height=500,title=\"正規化価格・ポートフォリオ\")\n",
    "    p1.add_tools(hover_tool)\n",
    "\n",
    "    p1.extra_y_ranges = {\"portfolio_vector\": Range1d(start=0, end=3)}\n",
    "    p1.add_layout(LinearAxis(y_range_name=\"portfolio_vector\"), 'right')\n",
    "    p1.vbar_stack(ticker_names, x='x', width=1, color=colors,y_range_name=\"portfolio_vector\", source=portfolio_vector_source, legend_label=ticker_names, alpha=0.8)\n",
    "\n",
    "    p1.multi_line(xs=price_source_x, ys=price_source_y, line_color=colors, line_width=2)\n",
    "    y_min, y_max = make_y_limit_multi(price_source_y, lowwer_ratio=0.1, upper_ratio=0.1)\n",
    "    y_min -= (y_max - y_min) * 0.66  #  ポートフォリオ割合のためのオフセット\n",
    "    p1.y_range = Range1d(start=y_min, end=y_max)\n",
    "\n",
    "    p1.yaxis[0].axis_label = \"正規化価格\"\n",
    "    p1.yaxis[1].axis_label = \"保有割合\"\n",
    "\n",
    "    p1.xaxis.major_label_overrides = {str(one_x) : str(all_datetime_array[i]) for i, one_x in enumerate(x)}\n",
    "\n",
    "    p2_text = Div(text=make_ticker_text(all_mean_cost_price_array[:,0], ticker_names))\n",
    "\n",
    "    p2 = bokeh.plotting.figure(plot_width=1200,plot_height=300,title=\"正規化平均取得価格・全資産\")\n",
    "    p2.multi_line(xs=mean_cost_price_source_x, ys=mean_cost_price_source_y, line_color=colors, line_width=2)\n",
    "    y_min, y_max = make_y_limit_multi(mean_cost_price_source_y, lowwer_ratio=0.1, upper_ratio=0.1)\n",
    "    p2.y_range = Range1d(start=y_min, end=y_max)\n",
    "\n",
    "    y_max, y_min = make_y_limit(all_assets_array, upper_ratio=0.1, lowwer_ratio=0.1)\n",
    "    p2.extra_y_ranges = {\"all_assets\": Range1d(start=y_max, end=y_min)}\n",
    "    p2.add_layout(LinearAxis(y_range_name=\"all_assets\"), 'right')\n",
    "    p2.line(x, all_assets_array, color=\"red\", legend_label=\"all_assets\", line_width=4, y_range_name=\"all_assets\")\n",
    "\n",
    "    # 疑似的なレジェンドをつける\n",
    "    for ticker_name, color in zip(ticker_names, colors):\n",
    "        p2.line([], [], legend_label=ticker_name, color=color, line_width=2)\n",
    "\n",
    "    p2.yaxis[0].axis_label = \"正規化平均取得価格\"\n",
    "    p2.yaxis[1].axis_label = \"全資産 [円]\"\n",
    "\n",
    "    p2.xaxis.major_label_overrides = {str(one_x) : str(all_datetime_array[i]) for i, one_x in enumerate(x)}\n",
    "\n",
    "    created_figure = bokeh.layouts.column(p1_text, p1, p2_text, p2)\n",
    "\n",
    "    if is_save:\n",
    "            if save_path.suffix == \".png\":\n",
    "                bokeh.io.export_png(created_figure, filename=save_path)\n",
    "            elif save_path.suffix == \".html\":\n",
    "                output_file(save_path)\n",
    "                bokeh.io.save(created_figure, filename=save_path, title=\"trading process\")    \n",
    "            else:\n",
    "                raise Exception(\"The suffix of save_path is must be '.png' or '.html'.\")\n",
    "    if is_show:\n",
    "        try:\n",
    "            reset_output()\n",
    "            if is_jupyter:\n",
    "                output_notebook()\n",
    "            show(created_figure)\n",
    "        except:\n",
    "            if is_jupyter:\n",
    "                output_notebook()\n",
    "            show(created_figure)\n",
    "        \n",
    "    if not is_save and not is_show:\n",
    "        raise Exception(\"is_save and is_show is False. This function do nothing\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T06:12:22.340726Z",
     "start_time": "2021-05-15T06:10:53.428Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_portfolio_transform_bokeh(portfolio_state_list, save_path=Path(\"visualization/trade_transform.png\"), is_save=True, is_show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py37",
   "language": "python",
   "name": "torch_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
