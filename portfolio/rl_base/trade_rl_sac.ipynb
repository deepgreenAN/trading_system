{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:36.136218Z",
     "start_time": "2021-05-16T06:16:36.102309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\システムトレード入門\\trade_system_git_workspace\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:36.515202Z",
     "start_time": "2021-05-16T06:16:36.146192Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:43.604704Z",
     "start_time": "2021-05-16T06:16:36.530164Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytz import timezone\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pfrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:44.440474Z",
     "start_time": "2021-05-16T06:16:43.617673Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:44.520257Z",
     "start_time": "2021-05-16T06:16:44.455432Z"
    }
   },
   "outputs": [],
   "source": [
    "import py_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:45.787255Z",
     "start_time": "2021-05-16T06:16:44.533224Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import StockDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:45.898952Z",
     "start_time": "2021-05-16T06:16:45.804204Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.trade_transformer import PortfolioTransformer, PortfolioRestrictorIdentity, FeeCalculatorFree\n",
    "from portfolio.price_supply import StockDBPriceSupplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:45.977741Z",
     "start_time": "2021-05-16T06:16:45.912912Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.rl_base.envs import TradeEnv, TickerSampler, DatetimeSampler, SamplerManager, PortfolioVectorSampler, ConstSamper\n",
    "from portfolio.rl_base.basis_func import ComposeFunction, PriceNormalizeConst, MeanCostPriceNormalizeConst, State2Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:48.922005Z",
     "start_time": "2021-05-16T06:16:45.987714Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.rl_base.make_env import make_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:54.189665Z",
     "start_time": "2021-05-16T06:16:48.951925Z"
    }
   },
   "outputs": [],
   "source": [
    "from visualization import visualize_portfolio_rl_bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 並列環境の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:16:54.710270Z",
     "start_time": "2021-05-16T06:16:54.200634Z"
    }
   },
   "outputs": [],
   "source": [
    "one_trade_env = make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:02.978302Z",
     "start_time": "2021-05-16T06:16:54.720241Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portfolio_state, _,_,_ = one_trade_env.reset()\n",
    "#print(portfolio_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:03.058091Z",
     "start_time": "2021-05-16T06:17:02.998249Z"
    }
   },
   "outputs": [],
   "source": [
    "class VectorEnv():\n",
    "    def __init__(self,remote_envs):\n",
    "        self._remote_envs = remote_envs \n",
    "\n",
    "    @property\n",
    "    def remote_envs(self):\n",
    "        return self._remote_envs\n",
    "\n",
    "    def reset(self, *args, **kwargs):\n",
    "        out_list = [remote_env.reset(*args, **kwargs) for remote_env in self._remote_envs]\n",
    "        # それぞれの返り値の長さが複数かどうか\n",
    "        if len(out_list) > 0:\n",
    "            if isinstance(out_list[0], tuple):  # 一つの返り値が複数の場合\n",
    "                return zip(*out_list)  # それぞれの出力のリストに変換(unzip)\n",
    "            else:\n",
    "                return out_list  # そのまま出力\n",
    "        return None\n",
    "\n",
    "    def step(self, actions, *args, **kwargs):\n",
    "        assert len(self._remote_envs) == len(actions)\n",
    "        out_list = [remote_env.step(action, *args, **kwargs) for remote_env, action in zip(self.remote_envs, actions)]\n",
    "        if len(out_list) > 0:\n",
    "            if isinstance(out_list[0], tuple):  # 一つの返り値が複数の場合\n",
    "                return zip(*out_list)  # それぞれの出力のリストに変換(unzip)\n",
    "            else:\n",
    "                return out_list  # そのまま出力\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:04.265860Z",
     "start_time": "2021-05-16T06:17:03.071057Z"
    }
   },
   "outputs": [],
   "source": [
    "env_number = 4\n",
    "env_list = [make_env() for _ in range(env_number)]\n",
    "batch_trade_env = VectorEnv(env_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:27.992734Z",
     "start_time": "2021-05-16T06:17:04.274839Z"
    }
   },
   "outputs": [],
   "source": [
    "states, rewards, dones, infos = batch_trade_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:28.023660Z",
     "start_time": "2021-05-16T06:17:27.999729Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の設定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:28.324867Z",
     "start_time": "2021-05-16T06:17:28.033632Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_transform():\n",
    "    return ComposeFunction({\"price_normalizer\":PriceNormalizeConst(None),\n",
    "                                   \"mca_normalizer\":MeanCostPriceNormalizeConst(None),\n",
    "                                   \"state2feature\":State2Feature()\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:28.373734Z",
     "start_time": "2021-05-16T06:17:28.341811Z"
    }
   },
   "outputs": [],
   "source": [
    "one_state_transform = make_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:28.593136Z",
     "start_time": "2021-05-16T06:17:28.412624Z"
    }
   },
   "outputs": [],
   "source": [
    "class VectorTransform():\n",
    "    def __init__(self, transform_list):\n",
    "        self.transforms = transform_list\n",
    "        \n",
    "    def __call__(self, states):\n",
    "        return [one_transform(state) for one_transform, state in zip(self.transforms, states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:28.925252Z",
     "start_time": "2021-05-16T06:17:28.607099Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_list = [make_transform() for _ in range(env_number)]\n",
    "batch_state_transform = VectorTransform(transform_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  モデルの定義 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は決定論的な方策を利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:29.323209Z",
     "start_time": "2021-05-16T06:17:28.947193Z"
    }
   },
   "outputs": [],
   "source": [
    "class DirichletHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DirichletHead, self).__init__()\n",
    "        \n",
    "    def forward(self, alpha):\n",
    "        return torch.distributions.Dirichlet(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:29.605435Z",
     "start_time": "2021-05-16T06:17:29.343140Z"
    }
   },
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_number=20):\n",
    "        super(Policy, self).__init__()\n",
    "        self.out_number = out_number\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 12, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(12, self.out_number, kernel_size=5, padding=2, stride=(2,3))\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_number)\n",
    "        self.conv3 = nn.Conv2d(self.out_number, self.out_number, kernel_size=(4,3), padding=(2,1), stride=(2,3))\n",
    "        #self.bn3 = nn.BatchNorm2d(self.out_number)\n",
    "\n",
    "        #self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3)\n",
    "        self.head = DirichletHead()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        if x.shape[1:]!=torch.Size([3, 20, 50]):\n",
    "            print(x)\n",
    "            raise Exception(\"invalid shape policy\")\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        #x = self.bn3(self.conv3(x))\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        #x = self.avgpool(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = torch.reshape(x, (-1, self.out_number))\n",
    "        \n",
    "        #x = F.softmax(x, dim=-1)\n",
    "        x = F.relu(x)\n",
    "        x = torch.clamp(x, 1.e-5)\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:29.718147Z",
     "start_time": "2021-05-16T06:17:29.633359Z"
    }
   },
   "outputs": [],
   "source": [
    "#random_x = torch.randn((30, 3, 20, 50))\n",
    "random_x = 100*torch.ones((1,3,20,50))\n",
    "policy = Policy(3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:29.858755Z",
     "start_time": "2021-05-16T06:17:29.728105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) torch.Size([20])\n",
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "out = policy(random_x)\n",
    "print(out.batch_shape, out.event_shape)\n",
    "print(out.rsample(torch.Size([])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:29.968459Z",
     "start_time": "2021-05-16T06:17:29.871721Z"
    }
   },
   "outputs": [],
   "source": [
    "class QFunc(nn.Module):\n",
    "    def __init__(self, in_channels=3, action_size=20):\n",
    "        super(QFunc, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 12, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(12, 24, kernel_size=5, padding=2, stride=(2,3))\n",
    "        self.bn2 = nn.BatchNorm2d(24)\n",
    "        self.conv3 = nn.Conv2d(24, 64, kernel_size=(4,3), padding=(2,1), stride=(2,3))\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "\n",
    "        self.fc1 = nn.Linear(action_size, 64)\n",
    "        self.fcbn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.concat = pfrl.nn.ConcatObsAndAction()\n",
    "        self.fc2 = nn.Linear(64*2, 256)\n",
    "        self.fcbn2 = nn.BatchNorm1d(256)\n",
    "        self.head = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, obs_and_action):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        obs, action = obs_and_action\n",
    "        x = F.relu(self.bn1(self.conv1(obs)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.reshape(x, (-1, 64))\n",
    "\n",
    "        y = F.relu(self.fcbn1(self.fc1(action)))\n",
    "\n",
    "        x = self.concat((x, y))\n",
    "        x = F.relu(self.fcbn2(self.fc2(x)))\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.188880Z",
     "start_time": "2021-05-16T06:17:29.977435Z"
    }
   },
   "outputs": [],
   "source": [
    "random_obs = torch.randn(30, 3, 20, 50)\n",
    "random_action = torch.randn(30, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.379364Z",
     "start_time": "2021-05-16T06:17:30.207822Z"
    }
   },
   "outputs": [],
   "source": [
    "qfunc = QFunc(3, 20)\n",
    "out = qfunc((random_obs, random_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.458155Z",
     "start_time": "2021-05-16T06:17:30.400304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T05:38:57.699872Z",
     "start_time": "2021-05-13T05:38:57.670897Z"
    }
   },
   "source": [
    "## エージェントの作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.632734Z",
     "start_time": "2021-05-16T06:17:30.469124Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = Policy(in_channels=3, out_number=20)\n",
    "q_func1 = QFunc(in_channels=3, action_size=20)\n",
    "q_func2 = QFunc(in_channels=3, action_size=20)\n",
    "\n",
    "opt_p = torch.optim.Adam(policy.parameters())\n",
    "opt_q1 = torch.optim.Adam(q_func1.parameters())\n",
    "opt_q2 = torch.optim.Adam(q_func2.parameters())\n",
    "\n",
    "rbuf = pfrl.replay_buffers.ReplayBuffer(1.e2)\n",
    "\n",
    "def burnin_action_func():\n",
    "    \"\"\"Select random actions until model is updated one or more times.\"\"\"\n",
    "    random_x = np.random.uniform(np.array([0]*20), np.array([1]*20))\n",
    "    out = softmax(random_x).astype(np.float32)\n",
    "    return out\n",
    "        \n",
    "gpu = -1\n",
    "\n",
    "gamma = 0.99 \n",
    "\n",
    "replay_start_size =100\n",
    "\n",
    "#batch_size = 256\n",
    "batch_size = 16  # 環境の数と異なることに注意\n",
    "    \n",
    "phi = lambda x: x.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "sac_agent = pfrl.agents.SoftActorCritic(\n",
    "    policy,\n",
    "    q_func1,\n",
    "    q_func2,\n",
    "    opt_p,\n",
    "    opt_q1,\n",
    "    opt_q2,\n",
    "    rbuf,\n",
    "    phi=phi,\n",
    "    gamma=gamma,\n",
    "    replay_start_size=replay_start_size,\n",
    "    gpu=gpu,\n",
    "    minibatch_size=batch_size,\n",
    "    burnin_action_func=burnin_action_func,\n",
    "    entropy_target=-20,\n",
    "    temperature_optimizer_lr=3e-4,\n",
    "    act_deterministically=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のための関数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.742432Z",
     "start_time": "2021-05-16T06:17:30.642660Z"
    }
   },
   "outputs": [],
   "source": [
    "def episode(env,\n",
    "            agent,\n",
    "            state_transform,\n",
    "            return_state_reward=True,\n",
    "            field_list=[\"now_price_array\", \"portfoilo_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "            seed=None,\n",
    "            print_span=None,\n",
    "            is_observe=True):\n",
    "    \n",
    "    state_list = []\n",
    "    reward_list = []\n",
    "    \n",
    "    portfolio_state,reward,_,_ = env.reset(seed)\n",
    "    \n",
    "    #state_transformの設定\n",
    "    state_transform.price_normalizer.const_array = portfolio_state.now_price_array\n",
    "    state_transform.mca_normalizer.const_array = portfolio_state.now_price_array\n",
    "    \n",
    "    \n",
    "    state_list.append(portfolio_state.partial(*field_list))\n",
    "    reward_list.append(reward)\n",
    "    \n",
    "\n",
    "    R = 0\n",
    "    t = 1\n",
    "    \n",
    "    obs = state_transform(portfolio_state)\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"initial:, all_assets:{}\".format(portfolio_state.all_assets))\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(obs)\n",
    "        portfolio_state, reward, done, info = env.step(action)\n",
    "\n",
    "        state_list.append(portfolio_state.partial(*field_list))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = False\n",
    "        \n",
    "        # state前処理\n",
    "        obs = state_transform(portfolio_state)\n",
    "\n",
    "        if is_observe:  # 観測(学習)する場合\n",
    "            agent.observe(obs, reward, done, reset)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "        if print_span is not None:\n",
    "            if t%print_span==0:\n",
    "                print(\"\\tt={}:, all_assets:{}\".format(t,portfolio_state.all_assets))\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"finished(t={}):, all_assets:{}\".format(t, portfolio_state.all_assets))\n",
    "    \n",
    "    out_dict = {}\n",
    "    out_dict[\"R\"] = R \n",
    "    \n",
    "    if return_state_reward:\n",
    "        out_dict[\"state_list\"] = state_list\n",
    "        out_dict[\"reward_list\"] = reward_list\n",
    "            \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.820228Z",
     "start_time": "2021-05-16T06:17:30.752366Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_episode(batch_env,\n",
    "            agent,\n",
    "            batch_state_transform,\n",
    "            seed=None,\n",
    "            print_span=None,\n",
    "            is_observe=True):\n",
    "        \n",
    "    portfolio_states, rewards,_,_ = batch_env.reset(seed)\n",
    "    \n",
    "    #state_transformの設定\n",
    "    for one_portfolio_state, one_state_transform in zip(portfolio_states, batch_state_transform.transforms):\n",
    "        one_state_transform.price_normalizer.const_array = one_portfolio_state.now_price_array\n",
    "        one_state_transform.mca_normalizer.const_array = one_portfolio_state.now_price_array\n",
    "    \n",
    "    R = np.zeros(len(portfolio_states))\n",
    "    t = 1\n",
    "    \n",
    "    obss = batch_state_transform(portfolio_states)\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"initial:, all_assets:{}\".format(portfolio_states[0].all_assets))\n",
    "\n",
    "    while True:\n",
    "        actions = agent.batch_act(obss)\n",
    "        portfolio_states, rewards, dones, _ = batch_env.step(actions)\n",
    "\n",
    "        R += rewards\n",
    "        t += 1\n",
    "        resets = [False] * len(portfolio_states)\n",
    "        \n",
    "        # state前処理\n",
    "        obss = batch_state_transform(portfolio_states)\n",
    "\n",
    "        if is_observe:  # 観測(学習)する場合\n",
    "            agent.batch_observe(obss, rewards, dones, resets)\n",
    "\n",
    "        if any(dones):\n",
    "            break\n",
    "        if print_span is not None:\n",
    "            if t%print_span==0:\n",
    "                print(\"\\tt={}:, all_assets:{}\".format(t,portfolio_states[0].all_assets))\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"finished(t={}):, all_assets:{}\".format(t, portfolio_states[0].all_assets))\n",
    "        \n",
    "    return {\"R\":R}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  エージェント名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.868055Z",
     "start_time": "2021-05-16T06:17:30.829162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sac_2021_05_16__15_17_30\n"
     ]
    }
   ],
   "source": [
    "now_datetime = datetime.datetime.now()\n",
    "now_str = now_datetime.strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "agent_name = \"sac_\"+now_str\n",
    "print(agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一時保存用のオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.898976Z",
     "start_time": "2021-05-16T06:17:30.880043Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_save_dict = {\"agent_name\":agent_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一時保存用の設定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:30.929894Z",
     "start_time": "2021-05-16T06:17:30.908948Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_filepath = Path(\"portfolio/rl_base/training_temp.tmp\")\n",
    "\n",
    "object_temp_filepath = Path(\"portfolio/rl_base/temp_save_dict.pickle\")\n",
    "\n",
    "save_funcs = [sac_agent.save]\n",
    "load_funcs = [sac_agent.load]\n",
    "func_paths = [Path(\"portfolio/rl_base/temp_agent\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オブジェクトの登録とロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:31.969051Z",
     "start_time": "2021-05-16T06:17:30.944852Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = py_restart.enable_counter(temp_filepath, each_save=True, save_span=100, use_tempfile=True)\n",
    "\n",
    "temp_save_dict = counter.save_load_object(temp_save_dict, object_temp_filepath)\n",
    "\n",
    "counter.save_load_funcs(save_funcs=save_funcs,\n",
    "                        load_funcs=load_funcs,\n",
    "                        func_paths=func_paths\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を保存するディレクトリ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:32.222381Z",
     "start_time": "2021-05-16T06:17:31.976044Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fig_dir_path = Path(\"portfolio/rl_base/trading_process_figures\") / Path(agent_name)\n",
    "if not save_fig_dir_path.exists():\n",
    "    save_fig_dir_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のパラメータ― "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:17:32.428893Z",
     "start_time": "2021-05-16T06:17:32.231414Z"
    }
   },
   "outputs": [],
   "source": [
    "n_episodes = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のイテレーション "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:28:34.577637Z",
     "start_time": "2021-05-16T06:17:32.450840Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cde799d4e6c4d608ac51c92125bdea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c3e649bc0ba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         out_dict = batch_episode(batch_trade_env,\n\u001b[0;32m      4\u001b[0m                       \u001b[0msac_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                       \u001b[0mbatch_state_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                      )        \n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-0cc300c8c79f>\u001b[0m in \u001b[0;36mbatch_episode\u001b[1;34m(batch_env, agent, batch_state_transform, seed, print_span, is_observe)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_observe\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 観測(学習)する場合\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_observe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\soft_actor_critic.py\u001b[0m in \u001b[0;36mbatch_observe\u001b[1;34m(self, batch_obs, batch_reward, batch_done, batch_reset)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbatch_observe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_observe_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_act_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\soft_actor_critic.py\u001b[0m in \u001b[0;36m_batch_observe_train\u001b[1;34m(self, batch_obs, batch_reward, batch_done, batch_reset)\u001b[0m\n\u001b[0;32m    373\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_last_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_current_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_updater\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_if_necessary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\replay_buffer.py\u001b[0m in \u001b[0;36mupdate_if_necessary\u001b[1;34m(self, iteration)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0mtransitions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\soft_actor_critic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, experiences, errors_out)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;34m\"\"\"Update the model from experiences\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_experiences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_q_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_policy_and_temperature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_target_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\soft_actor_critic.py\u001b[0m in \u001b[0;36mupdate_q_func\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_func2_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mloss2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mclip_l2_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mq_func2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with counter:\n",
    "    for i in counter(tqdm(range(1, n_episodes + 1))):\n",
    "        out_dict = batch_episode(batch_trade_env,\n",
    "                      sac_agent,\n",
    "                      batch_state_transform,\n",
    "                     )        \n",
    "\n",
    "        if i%50 == 0:\n",
    "            print(\"episode:{}, return:{}\".format(i, out_dict[\"R\"]))\n",
    "        if i%100 == 0:\n",
    "            print(\"statistics:\", sac_agent.get_statistics())\n",
    "\n",
    "        if i%50 == 0:\n",
    "            with sac_agent.eval_mode():\n",
    "                out_dict = episode(one_trade_env, \n",
    "                                   sac_agent,\n",
    "                                   one_state_transform,\n",
    "                                   return_state_reward=True,\n",
    "                                   field_list=[\"names\", \"now_price_array\", \"portfolio_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "                                   is_observe=False\n",
    "                                   )\n",
    "                \n",
    "                save_fig_path = save_fig_dir_path / Path(\"trading_process_i_{}.png\".format(i))\n",
    "                visualize_portfolio_rl_bokeh(out_dict[\"state_list\"], out_dict[\"reward_list\"], save_path=save_fig_path, is_show=False, is_save=True, is_jupyter=True)\n",
    "            \n",
    "print(\"Finshed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:28:34.594589Z",
     "start_time": "2021-05-16T06:16:38.634Z"
    }
   },
   "outputs": [],
   "source": [
    "with sac_agent.eval_mode():\n",
    "    out_dict = episode(trade_env, \n",
    "                       ddpg_agent,\n",
    "                       state_transform,\n",
    "                       return_state_reward=True,\n",
    "                       field_list=[\"names\", \"now_price_array\", \"portfolio_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "                       is_observe=False\n",
    "                       )\n",
    "    \n",
    "visualize_portfolio_rl_bokeh(out_dict[\"state_list\"], out_dict[\"reward_list\"], is_show=False, is_jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-16T06:28:34.601567Z",
     "start_time": "2021-05-16T06:16:38.653Z"
    }
   },
   "outputs": [],
   "source": [
    "save_agent_path = Path(\"portfolio/rl_base/saved_agents\") / Path(agent_name)\n",
    "sac_agent.save(save_agent_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py37",
   "language": "python",
   "name": "torch_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
