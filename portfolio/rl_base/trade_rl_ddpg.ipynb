{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:04.883060Z",
     "start_time": "2021-05-14T06:53:04.842171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\システムトレード入門\\trade_system_git_workspace\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:05.407656Z",
     "start_time": "2021-05-14T06:53:04.894031Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:13.536926Z",
     "start_time": "2021-05-14T06:53:05.418628Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytz import timezone\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pfrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:14.600087Z",
     "start_time": "2021-05-14T06:53:13.548893Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:14.679873Z",
     "start_time": "2021-05-14T06:53:14.610058Z"
    }
   },
   "outputs": [],
   "source": [
    "import py_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:16.203796Z",
     "start_time": "2021-05-14T06:53:14.693834Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import StockDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:16.379328Z",
     "start_time": "2021-05-14T06:53:16.219757Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.trade_transformer import PortfolioTransformer, PortfolioRestrictorIdentity, FeeCalculatorFree\n",
    "from portfolio.price_supply import StockDBPriceSupplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:16.505992Z",
     "start_time": "2021-05-14T06:53:16.414239Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.rl_base.envs import TradeEnv, TickerSampler, DatetimeSampler, SamplerManager, PortfolioVectorSampler\n",
    "from portfolio.rl_base.basis_func import ComposeFunction, PriceNormalizeConst, MeanCostPriceNormalizeConst, State2Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:19.251649Z",
     "start_time": "2021-05-14T06:53:16.518954Z"
    }
   },
   "outputs": [],
   "source": [
    "from visualization import visualize_portfolio_rl_bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グローバルパラメータ―"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:21.155563Z",
     "start_time": "2021-05-14T06:53:19.261622Z"
    }
   },
   "outputs": [],
   "source": [
    "jst = timezone(\"Asia/Tokyo\")\n",
    "start_datetime = jst.localize(datetime.datetime(2020,11,10,0,0,0))\n",
    "end_datetime = jst.localize(datetime.datetime(2020,11,20,0,0,0))\n",
    "ticker_number = 9\n",
    "window = np.arange(0,20)\n",
    "episode_length = 300\n",
    "freq_str = \"5T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境の作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:21.218394Z",
     "start_time": "2021-05-14T06:53:21.165535Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = Path(\"db/sub_stock_db/nikkei_255_stock.db\")\n",
    "\n",
    "ticker_codes_df = pd.read_csv(Path(\"portfolio/rl_base/nikkei225_modified.csv\"), header=0)  # 自分で作成\n",
    "ticker_codes = ticker_codes_df[\"code\"].values.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:21.883613Z",
     "start_time": "2021-05-14T06:53:21.230363Z"
    }
   },
   "outputs": [],
   "source": [
    "# stock_db\n",
    "stock_db = StockDatabase(db_path)\n",
    "\n",
    "# sampler\n",
    "ticker_names_sampler = TickerSampler(all_ticker_names=ticker_codes,\n",
    "                                     sampling_ticker_number=ticker_number)\n",
    "\n",
    "\n",
    "\n",
    "start_datetime_sampler = DatetimeSampler(start_datetime=start_datetime,\n",
    "                                         end_datetime=end_datetime,\n",
    "                                         episode_length=episode_length,\n",
    "                                         freq_str=freq_str\n",
    "                                        )\n",
    "\n",
    "portfolio_sampler = PortfolioVectorSampler(ticker_number+1)\n",
    "\n",
    "\n",
    "sampler_manager = SamplerManager(ticker_names_sampler=ticker_names_sampler,\n",
    "                                 datetime_sampler=start_datetime_sampler,\n",
    "                                 portfolio_vector_sampler=portfolio_sampler,\n",
    "                                )\n",
    "\n",
    "\n",
    "# PriceSupplierの設定\n",
    "price_supplier = StockDBPriceSupplier(stock_db,\n",
    "                                      [],  # 最初は何の銘柄コードも指定しない\n",
    "                                      episode_length,\n",
    "                                      freq_str,\n",
    "                                      interpolate=True\n",
    "                                     )\n",
    "\n",
    "# PortfolioTransformerの設定\n",
    "portfolio_transformer = PortfolioTransformer(price_supplier,\n",
    "                                             portfolio_restrictor=PortfolioRestrictorIdentity(),\n",
    "                                             use_ohlc=\"Close\",\n",
    "                                             initial_all_assets=1e6,  # 学習には関係ない\n",
    "                                             fee_calculator=FeeCalculatorFree()\n",
    "                                            )\n",
    "\n",
    "# TradeEnvの設定\n",
    "trade_env = TradeEnv(portfolio_transformer,\n",
    "                     sampler_manager,\n",
    "                     window=window,\n",
    "                     fee_const=0.0025\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:26.617500Z",
     "start_time": "2021-05-14T06:53:21.899573Z"
    }
   },
   "outputs": [],
   "source": [
    "portfolio_state, _,_,_ = trade_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:26.727232Z",
     "start_time": "2021-05-14T06:53:26.626476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_state.price_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の設定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:26.774082Z",
     "start_time": "2021-05-14T06:53:26.741170Z"
    }
   },
   "outputs": [],
   "source": [
    "state_transform = ComposeFunction({\"price_normalizer\":PriceNormalizeConst(None),\n",
    "                                   \"mca_normalizer\":MeanCostPriceNormalizeConst(None),\n",
    "                                   \"state2feature\":State2Feature()\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  モデルの定義 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は決定論的な方策を利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.263776Z",
     "start_time": "2021-05-14T06:53:26.784056Z"
    }
   },
   "outputs": [],
   "source": [
    "class DPolicy(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_number=10):\n",
    "        super(DPolicy, self).__init__()\n",
    "        self.out_number = out_number\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, self.out_number, kernel_size=(4,6), padding=2, stride=(2,3))\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        self.head = pfrl.policies.DeterministicHead()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.conv2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.reshape(x, (-1, self.out_number))\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.388443Z",
     "start_time": "2021-05-14T06:53:27.283722Z"
    }
   },
   "outputs": [],
   "source": [
    "random_x = torch.randn((30, 3, 10, 20))\n",
    "policy = DPolicy(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.578933Z",
     "start_time": "2021-05-14T06:53:27.400411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30]) torch.Size([10])\n",
      "torch.Size([30, 10])\n"
     ]
    }
   ],
   "source": [
    "out = policy(random_x)\n",
    "print(out.batch_shape, out.event_shape)\n",
    "print(out.rsample(torch.Size([])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.754461Z",
     "start_time": "2021-05-14T06:53:27.621815Z"
    }
   },
   "outputs": [],
   "source": [
    "class QFunc(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_number=10):\n",
    "        super(QFunc, self).__init__()\n",
    "        self.out_number = out_number\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 6, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.conv2 = nn.Conv2d(6, self.out_number, kernel_size=(4,6), padding=2, stride=(2,3))\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_number)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        \n",
    "        self.concat = pfrl.nn.ConcatObsAndAction()\n",
    "        self.fc1 = nn.Linear(self.out_number*2, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.head = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, obs_and_action):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        obs, action = obs_and_action\n",
    "        x = F.relu(self.bn1(self.conv1(obs)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.reshape(x, (-1, self.out_number))\n",
    "        x = self.concat((x, action))\n",
    "        x = F.relu(self.bn3(self.fc1(x)))\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.801336Z",
     "start_time": "2021-05-14T06:53:27.766429Z"
    }
   },
   "outputs": [],
   "source": [
    "random_obs = torch.randn(30, 3, 10, 20)\n",
    "random_action = torch.randn(30, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.911042Z",
     "start_time": "2021-05-14T06:53:27.811309Z"
    }
   },
   "outputs": [],
   "source": [
    "qfunc = QFunc(3, 10)\n",
    "out = qfunc((random_obs, random_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.941963Z",
     "start_time": "2021-05-14T06:53:27.922013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T05:38:57.699872Z",
     "start_time": "2021-05-13T05:38:57.670897Z"
    }
   },
   "source": [
    "## エージェントの作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:27.989833Z",
     "start_time": "2021-05-14T06:53:27.951935Z"
    }
   },
   "outputs": [],
   "source": [
    "a = PortfolioVectorSampler(ticker_number+1).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:28.370813Z",
     "start_time": "2021-05-14T06:53:27.999808Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = DPolicy(in_channels=3, out_number=ticker_number+1)\n",
    "q_func = QFunc(in_channels=3, out_number=ticker_number+1)\n",
    "\n",
    "opt_p = torch.optim.Adam(policy.parameters())\n",
    "opt_q = torch.optim.Adam(q_func.parameters())\n",
    "\n",
    "rbuf = pfrl.replay_buffers.ReplayBuffer(10 ** 6)\n",
    "\n",
    "#explorer = pfrl.explorers.AdditiveGaussian(\n",
    "#    scale=np.array([0.1]*(ticker_number+1)), low=np.array([0]*(ticker_number+1)), high=np.array([1]*(ticker_number+1))\n",
    "#)\n",
    "\n",
    "def action_sample():\n",
    "    portfolio_vector = PortfolioVectorSampler(ticker_number+1).sample()\n",
    "    return portfolio_vector.astype(np.float32)\n",
    "    \n",
    "\n",
    "explorer = pfrl.explorers.ConstantEpsilonGreedy(epsilon=0.3,\n",
    "                                                random_action_func=action_sample\n",
    "                                               )\n",
    "\n",
    "def burnin_action_func():\n",
    "    \"\"\"Select random actions until model is updated one or more times.\"\"\"\n",
    "    random_x = np.random.uniform(np.array([0]*(ticker_number+1)), np.array([1]*(ticker_number+1)))\n",
    "    out = softmax(random_x).astype(np.float32)\n",
    "    return out\n",
    "    #return np.random.uniform(np.array([0]), np.array([1])).astype(np.float32)\n",
    "    \n",
    "gpu = -1\n",
    "\n",
    "phi = lambda x: x.astype(np.float32, copy=False)\n",
    "\n",
    "ddpg_agent = pfrl.agents.DDPG(\n",
    "    policy,\n",
    "    q_func,\n",
    "    opt_p,\n",
    "    opt_q,\n",
    "    rbuf,\n",
    "    phi=phi,\n",
    "    gamma=0.99,\n",
    "    explorer=explorer,\n",
    "    replay_start_size=10000,\n",
    "    target_update_method=\"soft\",\n",
    "    target_update_interval=1,\n",
    "    update_interval=1,\n",
    "    soft_update_tau=5e-3,\n",
    "    n_times_update=1,\n",
    "    gpu=gpu,\n",
    "    minibatch_size=16,\n",
    "    burnin_action_func=burnin_action_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のための関数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:28.670017Z",
     "start_time": "2021-05-14T06:53:28.391767Z"
    }
   },
   "outputs": [],
   "source": [
    "def episode(env,\n",
    "            agent,\n",
    "            state_transform,\n",
    "            return_state_reward=True,\n",
    "            field_list=[\"now_price_array\", \"portfoilo_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "            seed=None,\n",
    "            print_span=None,\n",
    "            is_observe=True):\n",
    "    \n",
    "    state_list = []\n",
    "    reward_list = []\n",
    "    \n",
    "    portfolio_state,reward,_,_ = env.reset(seed)\n",
    "    \n",
    "    #state_transformの設定\n",
    "    state_transform.price_normalizer.const_array = portfolio_state.now_price_array\n",
    "    state_transform.mca_normalizer.const_array = portfolio_state.now_price_array\n",
    "    \n",
    "    \n",
    "    state_list.append(portfolio_state.partial(*field_list))\n",
    "    reward_list.append(reward)\n",
    "    \n",
    "\n",
    "    R = 0\n",
    "    t = 1\n",
    "    \n",
    "    obs = state_transform(portfolio_state)\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"initial:, all_assets:{}\".format(portfolio_state.all_assets))\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(obs)\n",
    "        portfolio_state, reward, done, info = env.step(action)\n",
    "\n",
    "        state_list.append(portfolio_state.partial(*field_list))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = False\n",
    "        \n",
    "        # state前処理\n",
    "        obs = state_transform(portfolio_state)\n",
    "\n",
    "        if is_observe:  # 観測(学習)する場合\n",
    "            agent.observe(obs, reward, done, reset)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "        if print_span is not None:\n",
    "            if t%print_span==0:\n",
    "                print(\"\\tt={}:, all_assets:{}\".format(t,portfolio_state.all_assets))\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"finished(t={}):, all_assets:{}\".format(t, portfolio_state.all_assets))\n",
    "    \n",
    "    out_dict = {}\n",
    "    out_dict[\"R\"] = R \n",
    "    \n",
    "    if return_state_reward:\n",
    "        out_dict[\"state_list\"] = state_list\n",
    "        out_dict[\"reward_list\"] = reward_list\n",
    "            \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  エージェント名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:29.602549Z",
     "start_time": "2021-05-14T06:53:28.681986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_05_14__15_53_29\n"
     ]
    }
   ],
   "source": [
    "now_datetime = datetime.datetime.now()\n",
    "now_str = now_datetime.strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "agent_name = now_str\n",
    "print(agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一時保存用のオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:29.635463Z",
     "start_time": "2021-05-14T06:53:29.618499Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_save_dict = {\"agent_name\":agent_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一時保存用の設定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:29.712228Z",
     "start_time": "2021-05-14T06:53:29.675330Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_filepath = Path(\"portfolio/rl_base/training_temp.tmp\")\n",
    "\n",
    "object_temp_filepath = Path(\"portfolio/rl_base/temp_save_dict.pickle\")\n",
    "\n",
    "save_funcs = [ddpg_agent.save]\n",
    "load_funcs = [ddpg_agent.load]\n",
    "func_paths = [Path(\"portfolio/rl_base/temp_agent\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オブジェクトの登録とロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:29.869810Z",
     "start_time": "2021-05-14T06:53:29.778053Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = py_restart.enable_counter(temp_filepath, each_save=True, save_span=100, use_tempfile=True)\n",
    "\n",
    "temp_save_dict = counter.save_load_object(temp_save_dict, object_temp_filepath)\n",
    "\n",
    "counter.save_load_funcs(save_funcs=save_funcs,\n",
    "                        load_funcs=load_funcs,\n",
    "                        func_paths=func_paths\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を保存するディレクトリ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:30.428314Z",
     "start_time": "2021-05-14T06:53:29.886764Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fig_dir_path = Path(\"portfolio/rl_base/trading_process_figures\") / Path(agent_name)\n",
    "if not save_fig_dir_path.exists():\n",
    "    save_fig_dir_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のパラメータ― "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:30.459235Z",
     "start_time": "2021-05-14T06:53:30.438290Z"
    }
   },
   "outputs": [],
   "source": [
    "n_episodes = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のイテレーション "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:44.535603Z",
     "start_time": "2021-05-14T06:53:30.484165Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4464defd0f4b41cbbda8abeb87f1c01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-80507d53e8ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         out_dict = episode(trade_env,\n\u001b[0;32m      4\u001b[0m                            \u001b[0mddpg_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                            \u001b[0mstate_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                           )        \n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-6bb1ce2cfe7a>\u001b[0m in \u001b[0;36mepisode\u001b[1;34m(env, agent, state_transform, return_state_reward, field_list, seed, print_span, is_observe)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_observe\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 観測(学習)する場合\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agent.py\u001b[0m in \u001b[0;36mobserve\u001b[1;34m(self, obs, reward, done, reset)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_observe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\ddpg.py\u001b[0m in \u001b[0;36mbatch_observe\u001b[1;34m(self, batch_obs, batch_reward, batch_done, batch_reset)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbatch_observe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_observe_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_select_greedy_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\ddpg.py\u001b[0m in \u001b[0;36m_batch_observe_train\u001b[1;34m(self, batch_obs, batch_reward, batch_done, batch_reset)\u001b[0m\n\u001b[0;32m    288\u001b[0m             \u001b[1;31m# Update the target network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_update_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_target_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_last_obs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_last_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\ddpg.py\u001b[0m in \u001b[0;36msync_target_network\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mdst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_update_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mtau\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoft_update_tau\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m         )\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\utils\\copy_param.py\u001b[0m in \u001b[0;36msynchronize_parameters\u001b[1;34m(src, dst, method, tau)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;34m\"hard\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcopy_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;34m\"soft\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msoft_copy_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     }[method]()\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\utils\\copy_param.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     {\n\u001b[0;32m     39\u001b[0m         \u001b[1;34m\"hard\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcopy_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;34m\"soft\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msoft_copy_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     }[method]()\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\utils\\copy_param.py\u001b[0m in \u001b[0;36msoft_copy_param\u001b[1;34m(target_link, source_link, tau)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msource_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mtarget_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msource_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mtarget_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mtarget_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtau\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msource_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with counter:\n",
    "    for i in counter(tqdm(range(1, n_episodes + 1))):\n",
    "        out_dict = episode(trade_env,\n",
    "                           ddpg_agent,\n",
    "                           state_transform,\n",
    "                          )        \n",
    "\n",
    "        if i%50 == 0:\n",
    "            print(\"episode:{}, return:{}\".format(i, out_dict[\"R\"]))\n",
    "        if i%100 == 0:\n",
    "            print(\"statistics:\", ddpg_agent.get_statistics())\n",
    "\n",
    "        if i%100 == 0:\n",
    "            with ddpg_agent.eval_mode():\n",
    "                out_dict = episode(trade_env, \n",
    "                                   ddpg_agent,\n",
    "                                   state_transform,\n",
    "                                   return_state_reward=True,\n",
    "                                   field_list=[\"names\", \"now_price_array\", \"portfolio_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "                                   is_observe=False\n",
    "                                   )\n",
    "                \n",
    "                save_fig_path = save_fig_dir_path / Path(\"trading_process_i_{}.png\".format(i))\n",
    "                visualize_portfolio_rl_bokeh(out_dict[\"state_list\"], out_dict[\"reward_list\"], save_path=save_fig_path, is_show=False, is_save=True, is_jupyter=True)\n",
    "            \n",
    "print(\"Finshed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T06:53:44.550565Z",
     "start_time": "2021-05-14T06:53:05.724Z"
    }
   },
   "outputs": [],
   "source": [
    "with ddpg_agent.eval_mode():\n",
    "    out_dict = episode(trade_env, \n",
    "                       ddpg_agent,\n",
    "                       state_transform,\n",
    "                       return_state_reward=True,\n",
    "                       field_list=[\"names\", \"now_price_array\", \"portfolio_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "                       is_observe=False\n",
    "                       )\n",
    "    \n",
    "visualize_portfolio_rl_bokeh(out_dict[\"state_list\"], out_dict[\"reward_list\"], is_show=False, is_jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py37",
   "language": "python",
   "name": "torch_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
