{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:17.212217Z",
     "start_time": "2021-05-15T09:52:17.172325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\システムトレード入門\\trade_system_git_workspace\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:17.749778Z",
     "start_time": "2021-05-15T09:52:17.222189Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:24.859257Z",
     "start_time": "2021-05-15T09:52:17.762748Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytz import timezone\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pfrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:25.808712Z",
     "start_time": "2021-05-15T09:52:24.869226Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:25.903461Z",
     "start_time": "2021-05-15T09:52:25.818687Z"
    }
   },
   "outputs": [],
   "source": [
    "import py_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:27.204984Z",
     "start_time": "2021-05-15T09:52:25.914432Z"
    }
   },
   "outputs": [],
   "source": [
    "from get_stock_price import StockDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:27.316682Z",
     "start_time": "2021-05-15T09:52:27.213956Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.trade_transformer import PortfolioTransformer, PortfolioRestrictorIdentity, FeeCalculatorFree\n",
    "from portfolio.price_supply import StockDBPriceSupplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:27.428386Z",
     "start_time": "2021-05-15T09:52:27.344609Z"
    }
   },
   "outputs": [],
   "source": [
    "from portfolio.rl_base.envs import TradeEnv, TickerSampler, DatetimeSampler, SamplerManager, PortfolioVectorSampler, ConstSamper\n",
    "from portfolio.rl_base.basis_func import ComposeFunction, PriceNormalizeConst, MeanCostPriceNormalizeConst, State2Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:31.054327Z",
     "start_time": "2021-05-15T09:52:27.441351Z"
    }
   },
   "outputs": [],
   "source": [
    "from visualization import visualize_portfolio_rl_bokeh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グローバルパラメータ―"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:33.177654Z",
     "start_time": "2021-05-15T09:52:31.062310Z"
    }
   },
   "outputs": [],
   "source": [
    "jst = timezone(\"Asia/Tokyo\")\n",
    "start_datetime = jst.localize(datetime.datetime(2020,11,10,0,0,0))\n",
    "end_datetime = jst.localize(datetime.datetime(2020,11,20,0,0,0))\n",
    "ticker_number = 19\n",
    "window = np.arange(0,50)\n",
    "episode_length = 300\n",
    "freq_str = \"5T\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境の作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:33.327253Z",
     "start_time": "2021-05-15T09:52:33.191615Z"
    }
   },
   "outputs": [],
   "source": [
    "db_path = Path(\"db/sub_stock_db/nikkei_255_stock_v2.db\")\n",
    "\n",
    "ticker_codes_df = pd.read_csv(Path(\"portfolio/rl_base/nikkei225_modified_v2.csv\"), header=0)  # 自分で作成\n",
    "ticker_codes = ticker_codes_df[\"code\"].values.astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:34.173985Z",
     "start_time": "2021-05-15T09:52:33.358173Z"
    }
   },
   "outputs": [],
   "source": [
    "# stock_db\n",
    "stock_db = StockDatabase(db_path)\n",
    "\n",
    "# sampler\n",
    "ticker_names_sampler = TickerSampler(all_ticker_names=ticker_codes,\n",
    "                                     sampling_ticker_number=ticker_number)\n",
    "\n",
    "\n",
    "#ticker_names_sampler = ConstSamper(np.random.choice(ticker_codes, ticker_number))  # 固定する\n",
    "\n",
    "\n",
    "\n",
    "start_datetime_sampler = DatetimeSampler(start_datetime=start_datetime,\n",
    "                                         end_datetime=end_datetime,\n",
    "                                         episode_length=episode_length,\n",
    "                                         freq_str=freq_str\n",
    "                                        )\n",
    "\n",
    "portfolio_sampler = PortfolioVectorSampler(ticker_number+1)\n",
    "\n",
    "\n",
    "sampler_manager = SamplerManager(ticker_names_sampler=ticker_names_sampler,\n",
    "                                 datetime_sampler=start_datetime_sampler,\n",
    "                                 portfolio_vector_sampler=portfolio_sampler,\n",
    "                                )\n",
    "\n",
    "\n",
    "# PriceSupplierの設定\n",
    "price_supplier = StockDBPriceSupplier(stock_db,\n",
    "                                      [],  # 最初は何の銘柄コードも指定しない\n",
    "                                      episode_length,\n",
    "                                      freq_str,\n",
    "                                      interpolate=True\n",
    "                                     )\n",
    "\n",
    "# PortfolioTransformerの設定\n",
    "portfolio_transformer = PortfolioTransformer(price_supplier,\n",
    "                                             portfolio_restrictor=PortfolioRestrictorIdentity(),\n",
    "                                             use_ohlc=\"Close\",\n",
    "                                             initial_all_assets=1e6,  # 学習には関係ない\n",
    "                                             fee_calculator=FeeCalculatorFree()\n",
    "                                            )\n",
    "\n",
    "# TradeEnvの設定\n",
    "trade_env = TradeEnv(portfolio_transformer,\n",
    "                     sampler_manager,\n",
    "                     window=window,\n",
    "                     fee_const=0.0025\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:41.986103Z",
     "start_time": "2021-05-15T09:52:34.183960Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portfolio_state, _,_,_ = trade_env.reset()\n",
    "#print(portfolio_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:42.096807Z",
     "start_time": "2021-05-15T09:52:42.022012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_state.price_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:42.176594Z",
     "start_time": "2021-05-15T09:52:42.119749Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_state.now_price_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理の設定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:42.240429Z",
     "start_time": "2021-05-15T09:52:42.186569Z"
    }
   },
   "outputs": [],
   "source": [
    "state_transform = ComposeFunction({\"price_normalizer\":PriceNormalizeConst(None),\n",
    "                                   \"mca_normalizer\":MeanCostPriceNormalizeConst(None),\n",
    "                                   \"state2feature\":State2Feature()\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  モデルの定義 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回は決定論的な方策を利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:42.398999Z",
     "start_time": "2021-05-15T09:52:42.252392Z"
    }
   },
   "outputs": [],
   "source": [
    "class DPolicy(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_number=20):\n",
    "        super(DPolicy, self).__init__()\n",
    "        self.out_number = out_number\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 12, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(12, self.out_number, kernel_size=5, padding=2, stride=(2,3))\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_number)\n",
    "        self.conv3 = nn.Conv2d(self.out_number, self.out_number, kernel_size=(4,3), padding=(2,1), stride=(2,3))\n",
    "        self.bn3 = nn.BatchNorm2d(self.out_number)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "        self.head = pfrl.policies.DeterministicHead()\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.reshape(x, (-1, self.out_number))\n",
    "        x = F.softmax(x, dim=-1)\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:43.126059Z",
     "start_time": "2021-05-15T09:52:42.408976Z"
    }
   },
   "outputs": [],
   "source": [
    "random_x = torch.randn((30, 3, 20, 50))\n",
    "policy = DPolicy(3, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:43.378383Z",
     "start_time": "2021-05-15T09:52:43.137029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30]) torch.Size([20])\n",
      "torch.Size([30, 20])\n"
     ]
    }
   ],
   "source": [
    "out = policy(random_x)\n",
    "print(out.batch_shape, out.event_shape)\n",
    "print(out.rsample(torch.Size([])).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:43.489086Z",
     "start_time": "2021-05-15T09:52:43.394342Z"
    }
   },
   "outputs": [],
   "source": [
    "class QFunc(nn.Module):\n",
    "    def __init__(self, in_channels=3, action_size=20):\n",
    "        super(QFunc, self).__init__()        \n",
    "        self.conv1 = nn.Conv2d(in_channels, 12, kernel_size=5, padding=2, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(12)\n",
    "        self.conv2 = nn.Conv2d(12, 24, kernel_size=5, padding=2, stride=(2,3))\n",
    "        self.bn2 = nn.BatchNorm2d(24)\n",
    "        self.conv3 = nn.Conv2d(24, 64, kernel_size=(4,3), padding=(2,1), stride=(2,3))\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=3)\n",
    "\n",
    "        self.fc1 = nn.Linear(action_size, 64)\n",
    "        self.fcbn1 = nn.BatchNorm1d(64)\n",
    "\n",
    "        self.concat = pfrl.nn.ConcatObsAndAction()\n",
    "        self.fc2 = nn.Linear(64*2, 256)\n",
    "        self.fcbn2 = nn.BatchNorm1d(256)\n",
    "        self.head = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, obs_and_action):\n",
    "        #from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "        obs, action = obs_and_action\n",
    "        x = F.relu(self.bn1(self.conv1(obs)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.reshape(x, (-1, 64))\n",
    "\n",
    "        y = F.relu(self.fcbn1(self.fc1(action)))\n",
    "\n",
    "        x = self.concat((x, y))\n",
    "        x = F.relu(self.fcbn2(self.fc2(x)))\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:43.540949Z",
     "start_time": "2021-05-15T09:52:43.500057Z"
    }
   },
   "outputs": [],
   "source": [
    "random_obs = torch.randn(30, 3, 20, 50)\n",
    "random_action = torch.randn(30, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:43.757370Z",
     "start_time": "2021-05-15T09:52:43.568873Z"
    }
   },
   "outputs": [],
   "source": [
    "qfunc = QFunc(3, 20)\n",
    "out = qfunc((random_obs, random_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:43.837156Z",
     "start_time": "2021-05-15T09:52:43.794273Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-13T05:38:57.699872Z",
     "start_time": "2021-05-13T05:38:57.670897Z"
    }
   },
   "source": [
    "## エージェントの作成 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.024654Z",
     "start_time": "2021-05-15T09:52:43.850122Z"
    }
   },
   "outputs": [],
   "source": [
    "policy = DPolicy(in_channels=3, out_number=ticker_number+1)\n",
    "q_func = QFunc(in_channels=3, action_size=ticker_number+1)\n",
    "\n",
    "opt_p = torch.optim.Adam(policy.parameters())\n",
    "opt_q = torch.optim.Adam(q_func.parameters())\n",
    "\n",
    "rbuf = pfrl.replay_buffers.ReplayBuffer(10 ** 6)\n",
    "\n",
    "#explorer = pfrl.explorers.AdditiveGaussian(\n",
    "#    scale=np.array([0.1]*(ticker_number+1)), low=np.array([0]*(ticker_number+1)), high=np.array([1]*(ticker_number+1))\n",
    "#)\n",
    "\n",
    "def action_sample():\n",
    "    portfolio_vector = PortfolioVectorSampler(ticker_number+1).sample()\n",
    "    return portfolio_vector.astype(np.float32)\n",
    "    \n",
    "\n",
    "explorer = pfrl.explorers.ConstantEpsilonGreedy(epsilon=0.3,\n",
    "                                                random_action_func=action_sample\n",
    "                                               )\n",
    "\n",
    "def burnin_action_func():\n",
    "    \"\"\"Select random actions until model is updated one or more times.\"\"\"\n",
    "    random_x = np.random.uniform(np.array([0]*(ticker_number+1)), np.array([1]*(ticker_number+1)))\n",
    "    out = softmax(random_x).astype(np.float32)\n",
    "    return out\n",
    "    #return np.random.uniform(np.array([0]), np.array([1])).astype(np.float32)\n",
    "    \n",
    "gpu = -1\n",
    "\n",
    "phi = lambda x: x.astype(np.float32, copy=False)\n",
    "\n",
    "ddpg_agent = pfrl.agents.DDPG(\n",
    "    policy,\n",
    "    q_func,\n",
    "    opt_p,\n",
    "    opt_q,\n",
    "    rbuf,\n",
    "    phi=phi,\n",
    "    gamma=0.99,\n",
    "    explorer=explorer,\n",
    "    replay_start_size=10000,\n",
    "    target_update_method=\"soft\",\n",
    "    target_update_interval=1,\n",
    "    update_interval=1,\n",
    "    soft_update_tau=5e-3,\n",
    "    n_times_update=1,\n",
    "    gpu=gpu,\n",
    "    minibatch_size=16,\n",
    "    burnin_action_func=burnin_action_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のための関数 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.149322Z",
     "start_time": "2021-05-15T09:52:44.033632Z"
    }
   },
   "outputs": [],
   "source": [
    "def episode(env,\n",
    "            agent,\n",
    "            state_transform,\n",
    "            return_state_reward=True,\n",
    "            field_list=[\"now_price_array\", \"portfoilo_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "            seed=None,\n",
    "            print_span=None,\n",
    "            is_observe=True):\n",
    "    \n",
    "    state_list = []\n",
    "    reward_list = []\n",
    "    \n",
    "    portfolio_state,reward,_,_ = env.reset(seed)\n",
    "    \n",
    "    #state_transformの設定\n",
    "    state_transform.price_normalizer.const_array = portfolio_state.now_price_array\n",
    "    state_transform.mca_normalizer.const_array = portfolio_state.now_price_array\n",
    "    \n",
    "    \n",
    "    state_list.append(portfolio_state.partial(*field_list))\n",
    "    reward_list.append(reward)\n",
    "    \n",
    "\n",
    "    R = 0\n",
    "    t = 1\n",
    "    \n",
    "    obs = state_transform(portfolio_state)\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"initial:, all_assets:{}\".format(portfolio_state.all_assets))\n",
    "\n",
    "    while True:\n",
    "        action = agent.act(obs)\n",
    "        portfolio_state, reward, done, info = env.step(action)\n",
    "\n",
    "        state_list.append(portfolio_state.partial(*field_list))\n",
    "        reward_list.append(reward)\n",
    "\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = False\n",
    "        \n",
    "        # state前処理\n",
    "        obs = state_transform(portfolio_state)\n",
    "\n",
    "        if is_observe:  # 観測(学習)する場合\n",
    "            agent.observe(obs, reward, done, reset)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "        if print_span is not None:\n",
    "            if t%print_span==0:\n",
    "                print(\"\\tt={}:, all_assets:{}\".format(t,portfolio_state.all_assets))\n",
    "    \n",
    "    if print_span is not None:\n",
    "        print(\"finished(t={}):, all_assets:{}\".format(t, portfolio_state.all_assets))\n",
    "    \n",
    "    out_dict = {}\n",
    "    out_dict[\"R\"] = R \n",
    "    \n",
    "    if return_state_reward:\n",
    "        out_dict[\"state_list\"] = state_list\n",
    "        out_dict[\"reward_list\"] = reward_list\n",
    "            \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  エージェント名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.197193Z",
     "start_time": "2021-05-15T09:52:44.162289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021_05_15__18_52_44\n"
     ]
    }
   ],
   "source": [
    "now_datetime = datetime.datetime.now()\n",
    "now_str = now_datetime.strftime(\"%Y_%m_%d__%H_%M_%S\")\n",
    "agent_name = now_str\n",
    "print(agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一時保存用のオブジェクト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.245065Z",
     "start_time": "2021-05-15T09:52:44.209164Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_save_dict = {\"agent_name\":agent_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一時保存用の設定 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.276981Z",
     "start_time": "2021-05-15T09:52:44.256038Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_filepath = Path(\"portfolio/rl_base/training_temp.tmp\")\n",
    "\n",
    "object_temp_filepath = Path(\"portfolio/rl_base/temp_save_dict.pickle\")\n",
    "\n",
    "save_funcs = [ddpg_agent.save]\n",
    "load_funcs = [ddpg_agent.load]\n",
    "func_paths = [Path(\"portfolio/rl_base/temp_agent\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オブジェクトの登録とロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.324852Z",
     "start_time": "2021-05-15T09:52:44.288949Z"
    }
   },
   "outputs": [],
   "source": [
    "counter = py_restart.enable_counter(temp_filepath, each_save=True, save_span=100, use_tempfile=True)\n",
    "\n",
    "temp_save_dict = counter.save_load_object(temp_save_dict, object_temp_filepath)\n",
    "\n",
    "counter.save_load_funcs(save_funcs=save_funcs,\n",
    "                        load_funcs=load_funcs,\n",
    "                        func_paths=func_paths\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像を保存するディレクトリ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.688882Z",
     "start_time": "2021-05-15T09:52:44.333830Z"
    }
   },
   "outputs": [],
   "source": [
    "save_fig_dir_path = Path(\"portfolio/rl_base/trading_process_figures\") / Path(agent_name)\n",
    "if not save_fig_dir_path.exists():\n",
    "    save_fig_dir_path.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のパラメータ― "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T09:52:44.720795Z",
     "start_time": "2021-05-15T09:52:44.702844Z"
    }
   },
   "outputs": [],
   "source": [
    "n_episodes = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習のイテレーション "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T12:32:05.832854Z",
     "start_time": "2021-05-15T09:52:44.739746Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0399d200f92490a8b490b4f1336139a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:50, return:0.8524706200300625\n",
      "episode:100, return:-0.8709747566855807\n",
      "statistics: [('average_q', -229.31631), ('average_actor_loss', 229.78707382202148), ('average_critic_loss', 276390.81959869387), ('n_updates', 20001)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ed700a74c5d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         out_dict = episode(trade_env,\n\u001b[0;32m      4\u001b[0m                            \u001b[0mddpg_agent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                            \u001b[0mstate_transform\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m                           )        \n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-6bb1ce2cfe7a>\u001b[0m in \u001b[0;36mepisode\u001b[1;34m(env, agent, state_transform, return_state_reward, field_list, seed, print_span, is_observe)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_observe\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 観測(学習)する場合\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agent.py\u001b[0m in \u001b[0;36mobserve\u001b[1;34m(self, obs, reward, done, reset)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mobserve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_observe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\ddpg.py\u001b[0m in \u001b[0;36mbatch_observe\u001b[1;34m(self, batch_obs, batch_reward, batch_done, batch_reset)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbatch_observe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_observe_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_reset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_batch_select_greedy_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\ddpg.py\u001b[0m in \u001b[0;36m_batch_observe_train\u001b[1;34m(self, batch_obs, batch_reward, batch_done, batch_reset)\u001b[0m\n\u001b[0;32m    305\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_last_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_current_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_updater\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_if_necessary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\replay_buffer.py\u001b[0m in \u001b[0;36mupdate_if_necessary\u001b[1;34m(self, iteration)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m                 \u001b[0mtransitions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\agents\\ddpg.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, experiences, errors_out)\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[1;34m\"\"\"Update the model from experiences\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_experiences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\replay_buffer.py\u001b[0m in \u001b[0;36mbatch_experiences\u001b[1;34m(experiences, device, phi, gamma, batch_states)\u001b[0m\n\u001b[0;32m    190\u001b[0m         ),\n\u001b[0;32m    191\u001b[0m         \"next_state\": batch_states(\n\u001b[1;32m--> 192\u001b[1;33m             \u001b[1;33m[\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_state\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexperiences\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mphi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m         ),\n\u001b[0;32m    194\u001b[0m         \"is_state_terminal\": torch.as_tensor(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\utils\\batch_states.py\u001b[0m in \u001b[0;36mbatch_states\u001b[1;34m(states, device, phi)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;31m# return concat_examples(features, device=device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_to_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torch_py37\\lib\\site-packages\\pfrl\\utils\\batch_states.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mphi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[1;31m# return concat_examples(features, device=device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_to_recursive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-4cadd4235397>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mgpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mphi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m ddpg_agent = pfrl.agents.DDPG(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with counter:\n",
    "    for i in counter(tqdm(range(1, n_episodes + 1))):\n",
    "        out_dict = episode(trade_env,\n",
    "                           ddpg_agent,\n",
    "                           state_transform,\n",
    "                          )        \n",
    "\n",
    "        if i%50 == 0:\n",
    "            print(\"episode:{}, return:{}\".format(i, out_dict[\"R\"]))\n",
    "        if i%100 == 0:\n",
    "            print(\"statistics:\", ddpg_agent.get_statistics())\n",
    "\n",
    "        if i%50 == 0:\n",
    "            with ddpg_agent.eval_mode():\n",
    "                out_dict = episode(trade_env, \n",
    "                                   ddpg_agent,\n",
    "                                   state_transform,\n",
    "                                   return_state_reward=True,\n",
    "                                   field_list=[\"names\", \"now_price_array\", \"portfolio_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "                                   is_observe=False\n",
    "                                   )\n",
    "                \n",
    "                save_fig_path = save_fig_dir_path / Path(\"trading_process_i_{}.png\".format(i))\n",
    "                visualize_portfolio_rl_bokeh(out_dict[\"state_list\"], out_dict[\"reward_list\"], save_path=save_fig_path, is_show=False, is_save=True, is_jupyter=True)\n",
    "            \n",
    "print(\"Finshed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T12:32:05.880736Z",
     "start_time": "2021-05-15T09:52:17.762Z"
    }
   },
   "outputs": [],
   "source": [
    "with ddpg_agent.eval_mode():\n",
    "    out_dict = episode(trade_env, \n",
    "                       ddpg_agent,\n",
    "                       state_transform,\n",
    "                       return_state_reward=True,\n",
    "                       field_list=[\"names\", \"now_price_array\", \"portfolio_vector\", \"mean_cost_price_array\", \"all_assets\", \"datetime\"],\n",
    "                       is_observe=False\n",
    "                       )\n",
    "    \n",
    "visualize_portfolio_rl_bokeh(out_dict[\"state_list\"], out_dict[\"reward_list\"], is_show=False, is_jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  エージェントの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-15T12:32:05.892694Z",
     "start_time": "2021-05-15T09:52:17.796Z"
    }
   },
   "outputs": [],
   "source": [
    "save_agent_path = Path(\"portfolio/rl_base/saved_agents\") / Path(agent_name)\n",
    "ddpg_agent.save(save_agent_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py37",
   "language": "python",
   "name": "torch_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "183.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
